{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b2150a1e4fe49208a9e3ae5d9f3e903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e6b12cce39745c3ab79c785dec2794c",
              "IPY_MODEL_40da33c8fd7f48c3b3adf60c503babbe",
              "IPY_MODEL_a59af4859a3c42bc83dc7a7f0bfa6d6a"
            ],
            "layout": "IPY_MODEL_ef7ea0367d2849729fc660c800f27fc7"
          }
        },
        "9e6b12cce39745c3ab79c785dec2794c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74ebe053ffdc417a8f43c502609a2e6f",
            "placeholder": "​",
            "style": "IPY_MODEL_9fc0c090160f4c75ab2ea379b5d2b11d",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "40da33c8fd7f48c3b3adf60c503babbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a95fa4ab90ea477f98c320539e3a4b5c",
            "max": 463,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0906cad9b8ec41ca98417512de55e043",
            "value": 463
          }
        },
        "a59af4859a3c42bc83dc7a7f0bfa6d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5048b20fb8349ce83e1222eabb421ea",
            "placeholder": "​",
            "style": "IPY_MODEL_e092bb7a50894f23ba8821ff7ee5d4cb",
            "value": " 463/463 [00:00&lt;00:00, 40.0kB/s]"
          }
        },
        "ef7ea0367d2849729fc660c800f27fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ebe053ffdc417a8f43c502609a2e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc0c090160f4c75ab2ea379b5d2b11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a95fa4ab90ea477f98c320539e3a4b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0906cad9b8ec41ca98417512de55e043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5048b20fb8349ce83e1222eabb421ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e092bb7a50894f23ba8821ff7ee5d4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8117ed4a0de143c1a881f02100c80498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5a2e4ba38f34d3da0a53369e8896dd2",
              "IPY_MODEL_840de95dfd9a4d5d8438162e4af03df9",
              "IPY_MODEL_4aa85419f05e45a598b7ad8f365bd329"
            ],
            "layout": "IPY_MODEL_6efecc7158aa4fb5b848d77fe6212461"
          }
        },
        "c5a2e4ba38f34d3da0a53369e8896dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_439296badcc1446282150f957e589b1d",
            "placeholder": "​",
            "style": "IPY_MODEL_80bb9b8308af4b48828e880664a7b324",
            "value": "Downloading spm.model: 100%"
          }
        },
        "840de95dfd9a4d5d8438162e4af03df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee80d63f6e5f46c585228cefc012c820",
            "max": 4305025,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4de9acd3747c41bc9172b80c88cf00e0",
            "value": 4305025
          }
        },
        "4aa85419f05e45a598b7ad8f365bd329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0daf0f9067ce454aa872df3b626eacf2",
            "placeholder": "​",
            "style": "IPY_MODEL_a81586ed6c2745e7bf095cd1bced4ca9",
            "value": " 4.31M/4.31M [00:00&lt;00:00, 33.1MB/s]"
          }
        },
        "6efecc7158aa4fb5b848d77fe6212461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439296badcc1446282150f957e589b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80bb9b8308af4b48828e880664a7b324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee80d63f6e5f46c585228cefc012c820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de9acd3747c41bc9172b80c88cf00e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0daf0f9067ce454aa872df3b626eacf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a81586ed6c2745e7bf095cd1bced4ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb2f915d608d4c82a120251f50ca7579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65c1f2dbcc3743ce991c73fbf5d1ae2d",
              "IPY_MODEL_7674a4fee9df48d5ab81fe165276ffae",
              "IPY_MODEL_89593896eb014baa88d1e54d71457156"
            ],
            "layout": "IPY_MODEL_6eb261cd242a4d0286f5b0bd119333e3"
          }
        },
        "65c1f2dbcc3743ce991c73fbf5d1ae2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c9540034309408d89f9322344f493fe",
            "placeholder": "​",
            "style": "IPY_MODEL_5a5bcffce371464696e4293bb5026438",
            "value": "Downloading (…)in/added_tokens.json: 100%"
          }
        },
        "7674a4fee9df48d5ab81fe165276ffae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b97de8936645c2816cfae71bdcd25a",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22f24815c65b44fcaec7398232616867",
            "value": 18
          }
        },
        "89593896eb014baa88d1e54d71457156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a5ca883d8da4eb8bb777ede50387d19",
            "placeholder": "​",
            "style": "IPY_MODEL_dbf4e17529714e858a3674b15643dc72",
            "value": " 18.0/18.0 [00:00&lt;00:00, 1.41kB/s]"
          }
        },
        "6eb261cd242a4d0286f5b0bd119333e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9540034309408d89f9322344f493fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5bcffce371464696e4293bb5026438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8b97de8936645c2816cfae71bdcd25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f24815c65b44fcaec7398232616867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a5ca883d8da4eb8bb777ede50387d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf4e17529714e858a3674b15643dc72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13b3fe78a3b0497893036ead3db0cac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15d617cd233446d7b4592b157c07523b",
              "IPY_MODEL_d4cb05ca527e40f1b3673c256af84e6a",
              "IPY_MODEL_d988c8f9749c43c8bcbee254e8d1d962"
            ],
            "layout": "IPY_MODEL_cf3bb4d589f24a408680768945c6aceb"
          }
        },
        "15d617cd233446d7b4592b157c07523b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_395fa3d64d3149da87589a30b8b11a4d",
            "placeholder": "​",
            "style": "IPY_MODEL_a3b6c9e5c57544d5a9f3c9c30c318e6d",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "d4cb05ca527e40f1b3673c256af84e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8c5333f3e54032962e8e3e5afb21c6",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef989c1358d345139c9f32852025f6e5",
            "value": 156
          }
        },
        "d988c8f9749c43c8bcbee254e8d1d962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_956d1aa43a5c44a9a0cbc099325a2bad",
            "placeholder": "​",
            "style": "IPY_MODEL_ed6a9c2fa9e240c39cba903ae361e6d6",
            "value": " 156/156 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "cf3bb4d589f24a408680768945c6aceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "395fa3d64d3149da87589a30b8b11a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b6c9e5c57544d5a9f3c9c30c318e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe8c5333f3e54032962e8e3e5afb21c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef989c1358d345139c9f32852025f6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "956d1aa43a5c44a9a0cbc099325a2bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed6a9c2fa9e240c39cba903ae361e6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee29d93b739346228b71f88a3284197d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_537352f806bd4e16ab272f7d6bfdbbbd",
              "IPY_MODEL_7b96441618584bca9fa7c030adcde74b",
              "IPY_MODEL_5b0cff1f57624cb294588b5b9ed7d758"
            ],
            "layout": "IPY_MODEL_959b6f824a32408b86264c5e12cd6cbd"
          }
        },
        "537352f806bd4e16ab272f7d6bfdbbbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fc65e05b364c1f9defdcda1190e435",
            "placeholder": "​",
            "style": "IPY_MODEL_16cdc0911cde4534892b1d839faf8616",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7b96441618584bca9fa7c030adcde74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc391e0a182d40078efa11624418ba27",
            "max": 1066,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d25e0b70567447e94c8ecdaf6e6baa0",
            "value": 1066
          }
        },
        "5b0cff1f57624cb294588b5b9ed7d758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2543c67c8004e46ac6bf3fd03278e60",
            "placeholder": "​",
            "style": "IPY_MODEL_650a80ba9bd94c538453a749a059d30f",
            "value": " 1.07k/1.07k [00:00&lt;00:00, 76.9kB/s]"
          }
        },
        "959b6f824a32408b86264c5e12cd6cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fc65e05b364c1f9defdcda1190e435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16cdc0911cde4534892b1d839faf8616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc391e0a182d40078efa11624418ba27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d25e0b70567447e94c8ecdaf6e6baa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2543c67c8004e46ac6bf3fd03278e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650a80ba9bd94c538453a749a059d30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30708f1c7bcf40fab99e04b2875cbd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3afa92d7a8c04a199e1868d0e227e96c",
              "IPY_MODEL_c95690a027ff4d289d1b9687b897a351",
              "IPY_MODEL_a17901feebc941cbb5d8afeaa7445f8f"
            ],
            "layout": "IPY_MODEL_240affdb432f4de1a98a82a57269f62c"
          }
        },
        "3afa92d7a8c04a199e1868d0e227e96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b936649e2ef47c8bfc226c1a4d8fa84",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f20c8eb51c4ac38f7b5dec2b9dac45",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "c95690a027ff4d289d1b9687b897a351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bb2f7653db04f8f8c22d4f4dc8406a9",
            "max": 557652046,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0384e37e05ea4a939a84cbac4eb52da9",
            "value": 557652046
          }
        },
        "a17901feebc941cbb5d8afeaa7445f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a90464361ed49b481e2e24f8426f290",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d4c9ff1a9442d991a8ce70b85c3865",
            "value": " 558M/558M [00:01&lt;00:00, 484MB/s]"
          }
        },
        "240affdb432f4de1a98a82a57269f62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b936649e2ef47c8bfc226c1a4d8fa84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f20c8eb51c4ac38f7b5dec2b9dac45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bb2f7653db04f8f8c22d4f4dc8406a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0384e37e05ea4a939a84cbac4eb52da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a90464361ed49b481e2e24f8426f290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d4c9ff1a9442d991a8ce70b85c3865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db7c0552c40b4a13a7fd00a4b5ce090a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3f031b1ea63454e810afdc8b7c3cddf",
              "IPY_MODEL_6cce25ca5b634d2ea808141a6a8e8019",
              "IPY_MODEL_d77fc4e125af4210a1f6c94884e3eb3f"
            ],
            "layout": "IPY_MODEL_11858c75e21c41d3881016186479f783"
          }
        },
        "a3f031b1ea63454e810afdc8b7c3cddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0e31c551f8455d904d9f397d819c47",
            "placeholder": "​",
            "style": "IPY_MODEL_8692845abacf489b9a962c80155f39d8",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "6cce25ca5b634d2ea808141a6a8e8019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f543192d3c01446faf06935f785de2cd",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24b07ceb90c74328870bf279012e540a",
            "value": 1000
          }
        },
        "d77fc4e125af4210a1f6c94884e3eb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aefe18664fc04eda836b9ec1e0cdcbb7",
            "placeholder": "​",
            "style": "IPY_MODEL_2c9d04c4574444efa6150edd42f9b9ce",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 84.0kB/s]"
          }
        },
        "11858c75e21c41d3881016186479f783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0e31c551f8455d904d9f397d819c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8692845abacf489b9a962c80155f39d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f543192d3c01446faf06935f785de2cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b07ceb90c74328870bf279012e540a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aefe18664fc04eda836b9ec1e0cdcbb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9d04c4574444efa6150edd42f9b9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b94c4d88a474677ae0609ff3d007e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9da8f8916753466b84757f536b33bc59",
              "IPY_MODEL_e6fda341097943aa9c5fc9f75d8dc8ab",
              "IPY_MODEL_6daa12eceae94ae3a5fdbe8fc78710bf"
            ],
            "layout": "IPY_MODEL_fff7e151954f4af7a2bc46ba173154a1"
          }
        },
        "9da8f8916753466b84757f536b33bc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee798466bd943ea8d608d7e01156019",
            "placeholder": "​",
            "style": "IPY_MODEL_e0eef7f564c048f7be5cfd788b2ba3a1",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "e6fda341097943aa9c5fc9f75d8dc8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df313e7b66eb4bdc97d28225a8f43eaf",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4de4c10fd4954df2a608f90ed017dd47",
            "value": 2825034
          }
        },
        "6daa12eceae94ae3a5fdbe8fc78710bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96e567a4ef364d7a85879b4ee8244ace",
            "placeholder": "​",
            "style": "IPY_MODEL_93eaea74952c4c8c81fc5202b77109e5",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 4.93MB/s]"
          }
        },
        "fff7e151954f4af7a2bc46ba173154a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aee798466bd943ea8d608d7e01156019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0eef7f564c048f7be5cfd788b2ba3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df313e7b66eb4bdc97d28225a8f43eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de4c10fd4954df2a608f90ed017dd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96e567a4ef364d7a85879b4ee8244ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93eaea74952c4c8c81fc5202b77109e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swoo-nam/project_final_team1/blob/main/05_Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYmsmShTIc0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1rK4_sDAYGxG",
        "outputId": "922889ca-b220-4c1e-e8f2-1db16a8f417f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def reset_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "SEED = 42\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n",
        "\n",
        "# df = pd.read_csv(f\"{DATA_PATH}yogiyo_reviews_0905_clean.csv\")\n",
        "# df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtfVkODe5yFb",
        "outputId": "dd44454d-b738-4e29-e75e-af544b344c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 1s (9,622 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 120879 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kExxxHu5YI4_",
        "outputId": "84f7b1ef-7250-48d9-b90b-0474e656bd6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMiWe8MfaXcK"
      },
      "source": [
        "# 제로샷 \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\" 토크나이저 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "6b2150a1e4fe49208a9e3ae5d9f3e903",
            "9e6b12cce39745c3ab79c785dec2794c",
            "40da33c8fd7f48c3b3adf60c503babbe",
            "a59af4859a3c42bc83dc7a7f0bfa6d6a",
            "ef7ea0367d2849729fc660c800f27fc7",
            "74ebe053ffdc417a8f43c502609a2e6f",
            "9fc0c090160f4c75ab2ea379b5d2b11d",
            "a95fa4ab90ea477f98c320539e3a4b5c",
            "0906cad9b8ec41ca98417512de55e043",
            "c5048b20fb8349ce83e1222eabb421ea",
            "e092bb7a50894f23ba8821ff7ee5d4cb",
            "8117ed4a0de143c1a881f02100c80498",
            "c5a2e4ba38f34d3da0a53369e8896dd2",
            "840de95dfd9a4d5d8438162e4af03df9",
            "4aa85419f05e45a598b7ad8f365bd329",
            "6efecc7158aa4fb5b848d77fe6212461",
            "439296badcc1446282150f957e589b1d",
            "80bb9b8308af4b48828e880664a7b324",
            "ee80d63f6e5f46c585228cefc012c820",
            "4de9acd3747c41bc9172b80c88cf00e0",
            "0daf0f9067ce454aa872df3b626eacf2",
            "a81586ed6c2745e7bf095cd1bced4ca9",
            "fb2f915d608d4c82a120251f50ca7579",
            "65c1f2dbcc3743ce991c73fbf5d1ae2d",
            "7674a4fee9df48d5ab81fe165276ffae",
            "89593896eb014baa88d1e54d71457156",
            "6eb261cd242a4d0286f5b0bd119333e3",
            "3c9540034309408d89f9322344f493fe",
            "5a5bcffce371464696e4293bb5026438",
            "d8b97de8936645c2816cfae71bdcd25a",
            "22f24815c65b44fcaec7398232616867",
            "1a5ca883d8da4eb8bb777ede50387d19",
            "dbf4e17529714e858a3674b15643dc72",
            "13b3fe78a3b0497893036ead3db0cac6",
            "15d617cd233446d7b4592b157c07523b",
            "d4cb05ca527e40f1b3673c256af84e6a",
            "d988c8f9749c43c8bcbee254e8d1d962",
            "cf3bb4d589f24a408680768945c6aceb",
            "395fa3d64d3149da87589a30b8b11a4d",
            "a3b6c9e5c57544d5a9f3c9c30c318e6d",
            "fe8c5333f3e54032962e8e3e5afb21c6",
            "ef989c1358d345139c9f32852025f6e5",
            "956d1aa43a5c44a9a0cbc099325a2bad",
            "ed6a9c2fa9e240c39cba903ae361e6d6",
            "ee29d93b739346228b71f88a3284197d",
            "537352f806bd4e16ab272f7d6bfdbbbd",
            "7b96441618584bca9fa7c030adcde74b",
            "5b0cff1f57624cb294588b5b9ed7d758",
            "959b6f824a32408b86264c5e12cd6cbd",
            "b5fc65e05b364c1f9defdcda1190e435",
            "16cdc0911cde4534892b1d839faf8616",
            "bc391e0a182d40078efa11624418ba27",
            "1d25e0b70567447e94c8ecdaf6e6baa0",
            "f2543c67c8004e46ac6bf3fd03278e60",
            "650a80ba9bd94c538453a749a059d30f",
            "30708f1c7bcf40fab99e04b2875cbd43",
            "3afa92d7a8c04a199e1868d0e227e96c",
            "c95690a027ff4d289d1b9687b897a351",
            "a17901feebc941cbb5d8afeaa7445f8f",
            "240affdb432f4de1a98a82a57269f62c",
            "2b936649e2ef47c8bfc226c1a4d8fa84",
            "a1f20c8eb51c4ac38f7b5dec2b9dac45",
            "2bb2f7653db04f8f8c22d4f4dc8406a9",
            "0384e37e05ea4a939a84cbac4eb52da9",
            "1a90464361ed49b481e2e24f8426f290",
            "b9d4c9ff1a9442d991a8ce70b85c3865"
          ]
        },
        "id": "RVI0xts-Ya7l",
        "outputId": "50ad789e-a1f2-4063-8e80-a75c3878837f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/463 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b2150a1e4fe49208a9e3ae5d9f3e903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8117ed4a0de143c1a881f02100c80498"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)in/added_tokens.json:   0%|          | 0.00/18.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb2f915d608d4c82a120251f50ca7579"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13b3fe78a3b0497893036ead3db0cac6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee29d93b739346228b71f88a3284197d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30708f1c7bcf40fab99e04b2875cbd43"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "# 토크나이저 초기화\n",
        "model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=tokenizer, device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqu60Qa5bB2y"
      },
      "source": [
        "# fine-tuning한 제로샷 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpBulX8RYkeL"
      },
      "outputs": [],
      "source": [
        "model_zeroshot = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/프로젝트/final project/data/42000_5라벨_3\").to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FPurwQ--ux6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhalYGl-JG5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f181565d-f082-4bdf-9f00-c6d764a8554b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.27.2-py2.py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.1)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.37 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.27.2 validators-0.22.0 watchdog-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t9KLOrWJCry"
      },
      "outputs": [],
      "source": [
        "model_name = \"skt/kogpt2-base-v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfmnJIx6JIhh"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Leaqh2X6JL1M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "db7c0552c40b4a13a7fd00a4b5ce090a",
            "a3f031b1ea63454e810afdc8b7c3cddf",
            "6cce25ca5b634d2ea808141a6a8e8019",
            "d77fc4e125af4210a1f6c94884e3eb3f",
            "11858c75e21c41d3881016186479f783",
            "ee0e31c551f8455d904d9f397d819c47",
            "8692845abacf489b9a962c80155f39d8",
            "f543192d3c01446faf06935f785de2cd",
            "24b07ceb90c74328870bf279012e540a",
            "aefe18664fc04eda836b9ec1e0cdcbb7",
            "2c9d04c4574444efa6150edd42f9b9ce",
            "8b94c4d88a474677ae0609ff3d007e50",
            "9da8f8916753466b84757f536b33bc59",
            "e6fda341097943aa9c5fc9f75d8dc8ab",
            "6daa12eceae94ae3a5fdbe8fc78710bf",
            "fff7e151954f4af7a2bc46ba173154a1",
            "aee798466bd943ea8d608d7e01156019",
            "e0eef7f564c048f7be5cfd788b2ba3a1",
            "df313e7b66eb4bdc97d28225a8f43eaf",
            "4de4c10fd4954df2a608f90ed017dd47",
            "96e567a4ef364d7a85879b4ee8244ace",
            "93eaea74952c4c8c81fc5202b77109e5"
          ]
        },
        "outputId": "5e1f0f25-6ed4-4b6c-9dd2-f4e703f97fdb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db7c0552c40b4a13a7fd00a4b5ce090a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b94c4d88a474677ae0609ff3d007e50"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          bos_token='</s>',\n",
        "                                          eos_token='</s>',\n",
        "                                          unk_token='<unk>',\n",
        "                                          pad_token='<pad>',\n",
        "                                          mask_token='<mask>',\n",
        "                                          max_len=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ7EMG5xMtvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38caf056-b410-4702-96b6-0b9d965a2ac7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/프로젝트/final project/data/tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/vocab.json',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/merges.txt',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/added_tokens.json',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tokenizer.save_pretrained(f'{DATA_PATH}tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boUvQqzpJCCm"
      },
      "outputs": [],
      "source": [
        "loaded_model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5iUzcPiSJfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea11f95-34aa-4ddf-907d-8ac7e98115eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m141.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.34.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (17.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=bf000ebb1f60af2fedb929c9e365e16dd351f24fb8261ff0e465e1000df6ddbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYNce24Bb-2X"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opTB8HZirVwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5f425d-7c2d-482e-f304-ad981f85db10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit-option-menu\n",
            "  Downloading streamlit_option_menu-0.3.6-py3-none-any.whl (799 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.2/799.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit-option-menu) (1.27.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (5.0.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (3.1.37)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-option-menu) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit-option-menu) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-option-menu) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit-option-menu) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-option-menu) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-option-menu) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-option-menu) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-option-menu) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-option-menu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-option-menu) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-option-menu) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (0.10.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-option-menu) (0.1.2)\n",
            "Installing collected packages: streamlit-option-menu\n",
            "Successfully installed streamlit-option-menu-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit-option-menu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYXbmstnmEHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0fbb86-dbd4-416d-94dd-8b0d87909d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)  # 변수명을 new_tokenizer로 변경\n",
        "classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "# import matplotlib.pyplot as plt\n",
        "# import streamlit as st\n",
        "# from streamlit_option_menu import option_menu\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import re\n",
        "# import time\n",
        "# from PIL import Image\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# from sklearn.metrics.pairwise import pairwise_distances\n",
        "# from sklearn.metrics import jaccard_score\n",
        "# import seaborn as sns\n",
        "# from scipy.interpolate import make_interp_spline\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "# bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "# model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# # 유사도 평가 함수\n",
        "# def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "#     input_embedding = bert_model.encode(input_text)\n",
        "#     generated_embedding = bert_model.encode(generated_text)\n",
        "\n",
        "#     # 코사인 유사도\n",
        "#     cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "\n",
        "#     # 자카드 유사도\n",
        "#     input_tokens = set(input_text.split())\n",
        "#     generated_tokens = set(generated_text.split())\n",
        "#     jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "#     # jaccard_sim = jaccard_score(input_tokens, generated_tokens)\n",
        "\n",
        "#     # 가중 평균 내보기\n",
        "#     weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "\n",
        "#     return weighted_sim\n",
        "\n",
        "# # 모델 로드\n",
        "# def loaded_model(DATA_PATH):\n",
        "#     model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_33_loss_0.2015\", local_files_only=True)\n",
        "#     return model\n",
        "\n",
        "# def load_zero_model(DATA_PATH):\n",
        "#     model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "#     return model_zeroshot\n",
        "\n",
        "# def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "#     new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "#     return new_tokenizer\n",
        "\n",
        "\n",
        "# def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "#     classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "#     return classifier\n",
        "\n",
        "# # 토크나이저 로드\n",
        "# def loaded_tokenizer(DATA_PATH):\n",
        "#     model_name = \"skt/kogpt2-base-v2\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "#                                           bos_token='</s>',\n",
        "#                                           eos_token='</s>',\n",
        "#                                           unk_token='<unk>',\n",
        "#                                           pad_token='<pad>',\n",
        "#                                           mask_token='<mask>',\n",
        "#                                           max_len=1024)\n",
        "#     return tokenizer\n",
        "\n",
        "# # 답변 생성 함수\n",
        "# def generate_response(model, tokenizer, input_text, num_samples):\n",
        "#     text = \"<q>\" + input_text + \"</s><a>\"\n",
        "#     x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "#     q_len = len(text) + 1\n",
        "\n",
        "#     best_generated_text = None\n",
        "#     best_similarity_score = -1.0\n",
        "#     generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "#     for i in range(num_samples):\n",
        "#         result_ids = model.generate(x,\n",
        "#                                         max_length=max_len,\n",
        "#                                         repetition_penalty=2.0,\n",
        "#                                         num_beams=1,\n",
        "#                                         num_return_sequences=1,\n",
        "#                                         no_repeat_ngram_size=4,\n",
        "#                                         use_cache=True,\n",
        "#                                         do_sample=True,\n",
        "#                                         temperature=0.8,\n",
        "#                                         top_k=90,\n",
        "#                                         top_p=0.95,\n",
        "#                                         early_stopping=True\n",
        "#                                         )\n",
        "\n",
        "\n",
        "#         generated_text = tokenizer.decode(result_ids[0])\n",
        "#         generated_text = generated_text[q_len:-4]\n",
        "#         generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "\n",
        "#         similarity_score = evaluate_similarity(text, generated_text)\n",
        "#         generated_texts.append((similarity_score,generated_text))\n",
        "#         print(generated_texts[i])\n",
        "\n",
        "#         if similarity_score > best_similarity_score:\n",
        "#             best_similarity_score = similarity_score\n",
        "#             best_generated_text = generated_text\n",
        "\n",
        "#     print(\"Best_similarity_score:\", best_similarity_score)\n",
        "\n",
        "#     return best_generated_text\n",
        "\n",
        "# # 그래프\n",
        "# def plot_review_analysis(merged_df, merged_df_3y):\n",
        "#     # 2개월 그래프\n",
        "#     fig1, ax1 = plt.subplots(figsize=(10, 4))\n",
        "#     sns.set(style=\"whitegrid\")\n",
        "#     sns.lineplot(data=merged_df, x='date', y='pos_7D_score', label='긍정 지수', marker='o', linestyle='-', color='b')\n",
        "#     sns.lineplot(data=merged_df, x='date', y='neg_7D_score', label='부정 지수', marker='s', linestyle='--', color='r')\n",
        "#     plt.title('긍부정 지수 변화 (2개월)')\n",
        "#     plt.xlabel('일자')\n",
        "#     plt.ylabel('리뷰 긍부정 지수')\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig1)\n",
        "\n",
        "#     st.markdown(\"---\")\n",
        "\n",
        "#     # 3개년 그래프 보간 부분\n",
        "#     x = merged_df_3y['DATE']\n",
        "#     y_pos = merged_df_3y['pos_7D_score']\n",
        "#     y_neg = merged_df_3y['neg_7D_score']\n",
        "\n",
        "#     mask = ~np.isnan(y_pos) & ~np.isnan(y_neg) & ~np.isinf(y_pos) & ~np.isinf(y_neg)\n",
        "#     x = x[mask]\n",
        "#     y_pos = y_pos[mask]\n",
        "#     y_neg = y_neg[mask]\n",
        "\n",
        "#     x_numeric = pd.to_datetime(x).astype(int)\n",
        "\n",
        "#     spline_pos = make_interp_spline(x_numeric, y_pos, k=3)\n",
        "#     spline_neg = make_interp_spline(x_numeric, y_neg, k=3)\n",
        "#     x_new = np.linspace(x_numeric.min(), x_numeric.max(), 300)\n",
        "#     y_pos_smooth = spline_pos(x_new)\n",
        "#     y_neg_smooth = spline_neg(x_new)\n",
        "\n",
        "#     fig2, ax2 = plt.subplots(figsize=(12, 6))\n",
        "#     plt.plot(pd.to_datetime(x_new), y_pos_smooth, label='긍정 지수', color='b')\n",
        "#     plt.plot(pd.to_datetime(x_new), y_neg_smooth, label='부정 지수', color='r')\n",
        "#     plt.title('긍부정 지수 변화 (3개년)')\n",
        "#     plt.xlabel('일자')\n",
        "#     plt.ylabel('리뷰 긍부정 지수')\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig2)\n",
        "\n",
        "\n",
        "# def plot_temperature_analysis(df2, input_id):\n",
        "#     review_count = len(df2[df2['ID'] == input_id])\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     if not id_df.empty:\n",
        "#         # 평균 점수 계산\n",
        "#         mean_score = id_df['NEW_SCORE'].mean()\n",
        "\n",
        "#         # 스케일링 함수 정의\n",
        "#         def scale_temperature(score):\n",
        "#             base_temp = 36.5\n",
        "#             ratio = 30\n",
        "#             scaled_temp = base_temp + (score * ratio)\n",
        "#             return scaled_temp\n",
        "\n",
        "#         # 스케일링된 온도값 계산\n",
        "#         scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "\n",
        "#         # 평균 온도 계산\n",
        "#         mean_temperature = scaled_scores.mean()\n",
        "\n",
        "#         # 그래프 선의 색깔을 조건에 따라 지정\n",
        "#         line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "#         line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "#         ax.set_xlabel('일자')\n",
        "#         ax.set_ylabel('온도 (°C)')\n",
        "#         ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "#         plt.xticks(id_df['DATE'], rotation=45)\n",
        "#         plt.tight_layout()\n",
        "#         plt.ylim(0, 70)\n",
        "#         y_ticks = np.arange(0, 71, 10)\n",
        "#         plt.yticks(y_ticks)\n",
        "#         plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "#         ax.legend()\n",
        "#         st.pyplot(fig)\n",
        "\n",
        "#         st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "#         st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "#         st.write(f'리뷰 횟수: {review_count}')\n",
        "#     else:\n",
        "#         st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def main():\n",
        "#     # 이미지 추가\n",
        "#     url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "#     st.image(url)\n",
        "\n",
        "#     DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "#     # 사이드바(옵션)\n",
        "#     with st.sidebar:\n",
        "#         choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\", \"기타\"],\n",
        "#                              icons=['house', 'kanban', 'bi bi-robot'],\n",
        "#                              menu_icon=\"app-indicator\", default_index=0,\n",
        "#                              styles={\n",
        "#                                  \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "#                                  \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "#                                  \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "#                                  \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "#                              }\n",
        "#         )\n",
        "\n",
        "#     # 사장님 답글 페이지\n",
        "#     if choice == \"사장님 답글 남기기\":\n",
        "\n",
        "#         candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "\n",
        "#         st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "#         user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "#         submit_button = st.button(\"Submit\")\n",
        "\n",
        "#         if submit_button:\n",
        "#             if user_input:\n",
        "#                 model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "#                 model_zeroshot = load_zero_model(DATA_PATH)\n",
        "#                 new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "#                 classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "\n",
        "#                 # 모델 1 예측\n",
        "#                 inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "#                 input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "#                 with torch.no_grad():\n",
        "#                     outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#                     logits = outputs.logits\n",
        "#                     probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "#                 scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "\n",
        "#                 # 모델 2 예측\n",
        "#                 output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "#                 scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "#                 # 두 모델의 점수 평균내기\n",
        "#                 new_labels = []\n",
        "#                 new_scores = {}\n",
        "#                 service_scores = []\n",
        "\n",
        "#                 for label in scores_from_model1.keys():\n",
        "#                     averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "\n",
        "#                     if label == '맛':\n",
        "#                         new_scores['Quality'] = averaged_score\n",
        "#                         if averaged_score >= 0.35:\n",
        "#                             new_labels.append('quality')\n",
        "\n",
        "#                     elif label == '양':\n",
        "#                         new_scores['Quantity'] = averaged_score\n",
        "#                         if averaged_score >= 0.35:\n",
        "#                             new_labels.append('quantity')\n",
        "\n",
        "#                     elif label in ['서비스', '배달', '가격']:\n",
        "#                         service_scores.append(averaged_score)\n",
        "\n",
        "#                 if service_scores:\n",
        "#                     avg_service_score = sum(service_scores) / len(service_scores)\n",
        "#                     new_scores['Service'] = avg_service_score\n",
        "#                     if avg_service_score >= 0.35:\n",
        "#                         new_labels.append('service')\n",
        "\n",
        "#                 new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "#                 new_predicted_labels = \", \".join(new_labels)\n",
        "\n",
        "#                 st.write(f\"Label Scores: {new_label_scores}\")\n",
        "#                 st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "\n",
        "#                 # 답변 생성 부분\n",
        "#                 model = loaded_model(DATA_PATH)\n",
        "#                 tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "\n",
        "#                 with st.spinner(\"답변 생성 중입니다...\"):\n",
        "#                     reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "#                 st.success(\"완료!\")\n",
        "#                 st.write(\"답글을 추천해 드려요. : \")\n",
        "#                 st.write(reply)\n",
        "#             else:\n",
        "#                 st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     # 리뷰 분석 페이지\n",
        "#     elif choice == \"리뷰 분석\":\n",
        "#         analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "#         if analysis_choice == \"부정 리뷰 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "#             # 부정 리뷰 분석 코드\n",
        "#             neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "#             pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "#             plt.rcParams.update(plt.rcParamsDefault)\n",
        "#             plt.rc('font', family='NanumBarunGothic')\n",
        "#             fig, ax = plt.subplots(figsize=(6, 6))\n",
        "#             short_label_counts = neg_short_result['label'].value_counts()\n",
        "#             ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "#             plt.title('리뷰 현황')\n",
        "#             st.pyplot(fig)\n",
        "\n",
        "#         elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "#             # 긍/부 지수의 변화 추이 코드\n",
        "#             merged_df = pd.read_csv(f'{DATA_PATH}merged_df_2months.csv')\n",
        "#             merged_df_3y = pd.read_csv(f'{DATA_PATH}merged_df_3years.csv')\n",
        "#             merged_df_3y = merged_df_3y.dropna()\n",
        "#             plot_review_analysis(merged_df, merged_df_3y)\n",
        "#             st.markdown(\"---\")\n",
        "\n",
        "#         elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "#             df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "#             df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "\n",
        "#             input_id = st.text_input(\"고객 ID 입력: \")\n",
        "#             plot_temperature_analysis(df2, input_id)\n",
        "\n",
        "#         elif choice == \"기타\":\n",
        "#             pass\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWfA5X5NNdQ8",
        "outputId": "92707f2f-8910-4c57-ada7-01bc858f5082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import streamlit as st\n",
        "# from streamlit_option_menu import option_menu\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import re\n",
        "# import time\n",
        "# from PIL import Image\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# from sklearn.metrics.pairwise import pairwise_distances\n",
        "# import seaborn as sns\n",
        "# from scipy.interpolate import make_interp_spline\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "# bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "# model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# # 유사도 평가 함수\n",
        "# def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "#     input_embedding = bert_model.encode(input_text)\n",
        "#     generated_embedding = bert_model.encode(generated_text)\n",
        "#     cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "#     input_tokens = set(input_text.split())\n",
        "#     generated_tokens = set(generated_text.split())\n",
        "#     jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "#     weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "#     return weighted_sim\n",
        "\n",
        "# # 모델 로드\n",
        "# def loaded_model(DATA_PATH):\n",
        "#     model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "#     return model\n",
        "\n",
        "# def load_zero_model(DATA_PATH):\n",
        "#     model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "#     return model_zeroshot\n",
        "\n",
        "# def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "#     new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "#     return new_tokenizer\n",
        "\n",
        "# def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "#     classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "#     return classifier\n",
        "\n",
        "# # 토크나이저 로드\n",
        "# def loaded_tokenizer(DATA_PATH):\n",
        "#     model_name = \"skt/kogpt2-base-v2\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "#                                           bos_token='</s>',\n",
        "#                                           eos_token='</s>',\n",
        "#                                           unk_token='<unk>',\n",
        "#                                           pad_token='<pad>',\n",
        "#                                           mask_token='<mask>',\n",
        "#                                           max_len=1024)\n",
        "#     return tokenizer\n",
        "\n",
        "# # 답변 생성 함수\n",
        "# def generate_response(model, tokenizer, input_text, num_samples):\n",
        "#     text = \"<q>\" + input_text + \"</s><a>\"\n",
        "#     x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "#     q_len = len(text) + 1\n",
        "\n",
        "#     best_generated_text = None\n",
        "#     best_similarity_score = -1.0\n",
        "#     generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "#     for i in range(num_samples):\n",
        "#         result_ids = model.generate(x,\n",
        "#                                         max_length=1024,\n",
        "#                                         repetition_penalty=2.0,\n",
        "#                                         num_beams=1,\n",
        "#                                         num_return_sequences=1,\n",
        "#                                         no_repeat_ngram_size=4,\n",
        "#                                         use_cache=True,\n",
        "#                                         do_sample=True,\n",
        "#                                         temperature=0.8,\n",
        "#                                         top_k=90,\n",
        "#                                         top_p=0.95,\n",
        "#                                         early_stopping=True\n",
        "#                                         )\n",
        "#         generated_text = tokenizer.decode(result_ids[0])\n",
        "#         generated_text = generated_text[q_len:-4]\n",
        "#         generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "#         similarity_score = evaluate_similarity(text, generated_text)\n",
        "#         generated_texts.append((similarity_score,generated_text))\n",
        "#         print(generated_texts[i])\n",
        "#         if similarity_score > best_similarity_score:\n",
        "#             best_similarity_score = similarity_score\n",
        "#             best_generated_text = generated_text\n",
        "#     print(\"Best_similarity_score:\", best_similarity_score)\n",
        "#     return best_generated_text\n",
        "\n",
        "# # 그래프\n",
        "\n",
        "# def plot_review_analysis(merged_df, merged_df_3y):\n",
        "#     fig1, ax1 = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "#     plt.rcParams.update(plt.rcParamsDefault)\n",
        "#     plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "#     # 그래프 그리기\n",
        "#     sns.lineplot(data=merged_df, x='date', y='pos_7D_score', ax=ax1, label='긍정 지수', marker='o', linestyle='-', color='b')\n",
        "#     sns.lineplot(data=merged_df, x='date', y='neg_7D_score', ax=ax1, label='부정 지수', marker='s', linestyle='--', color='r')\n",
        "\n",
        "#     # 그래프 설정\n",
        "#     ax1.set_title('긍부정 지수 변화 (2개월)', fontsize=14)\n",
        "#     ax1.set_xlabel('일자', fontsize=12)\n",
        "#     ax1.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     ax1.legend(fontsize=12)\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig1)\n",
        "\n",
        "\n",
        "#     st.markdown(\"---\")\n",
        "\n",
        "#     x = merged_df_3y['DATE']\n",
        "#     y_pos = merged_df_3y['pos_7D_score']\n",
        "#     y_neg = merged_df_3y['neg_7D_score']\n",
        "\n",
        "#     mask = ~np.isnan(y_pos) & ~np.isnan(y_neg) & ~np.isinf(y_pos) & ~np.isinf(y_neg)\n",
        "#     x = x[mask]\n",
        "#     y_pos = y_pos[mask]\n",
        "#     y_neg = y_neg[mask]\n",
        "\n",
        "#     x_numeric = pd.to_datetime(x).astype(int)\n",
        "\n",
        "#     spline_pos = make_interp_spline(x_numeric, y_pos, k=3)\n",
        "#     spline_neg = make_interp_spline(x_numeric, y_neg, k=3)\n",
        "#     x_new = np.linspace(x_numeric.min(), x_numeric.max(), 300)\n",
        "#     y_pos_smooth = spline_pos(x_new)\n",
        "#     y_neg_smooth = spline_neg(x_new)\n",
        "\n",
        "#     fig2, ax2 = plt.subplots(figsize=(10, 4))\n",
        "#     ax2.plot(pd.to_datetime(x_new), y_pos_smooth, label='긍정 지수', color='b')\n",
        "#     ax2.plot(pd.to_datetime(x_new), y_neg_smooth, label='부정 지수', color='r')\n",
        "#     ax2.set_title('긍부정 지수 변화 (3개년)', fontsize=14)\n",
        "#     ax2.set_xlabel('일자', fontsize=12)\n",
        "#     ax2.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     ax2.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig2)\n",
        "\n",
        "\n",
        "# def plot_temperature_analysis(df2, input_id):\n",
        "#     review_count = len(df2[df2['ID'] == input_id])\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     if not id_df.empty:\n",
        "#         mean_score = id_df['NEW_SCORE'].mean()\n",
        "#         def scale_temperature(score):\n",
        "#             base_temp = 36.5\n",
        "#             ratio = 30\n",
        "#             scaled_temp = base_temp + (score * ratio)\n",
        "#             return scaled_temp\n",
        "#         scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "#         mean_temperature = scaled_scores.mean()\n",
        "#         line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "#         line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "#         ax.set_xlabel('일자')\n",
        "#         ax.set_ylabel('온도 (°C)')\n",
        "#         ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "#         plt.xticks(id_df['DATE'], rotation=45)\n",
        "#         plt.tight_layout()\n",
        "#         plt.ylim(0, 70)\n",
        "#         y_ticks = np.arange(0, 71, 10)\n",
        "#         plt.yticks(y_ticks)\n",
        "#         plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "#         ax.legend()\n",
        "#         st.pyplot(fig)\n",
        "#         st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "#         st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "#         st.write(f'리뷰 횟수: {review_count}')\n",
        "#     else:\n",
        "#         st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "# def main():\n",
        "#     url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "#     st.image(url)\n",
        "\n",
        "#     DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\"],\n",
        "#                              icons=['house', 'kanban', 'bi bi-robot'],\n",
        "#                              menu_icon=\"app-indicator\", default_index=0,\n",
        "#                              styles={\n",
        "#                                  \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "#                                  \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "#                                  \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "#                                  \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "#                              }\n",
        "#         )\n",
        "\n",
        "#     if choice == \"사장님 답글 남기기\":\n",
        "#         candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "#         st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "#         user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "#         submit_button = st.button(\"Submit\")\n",
        "\n",
        "#         if submit_button:\n",
        "#             if user_input:\n",
        "#                 model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "#                 model_zeroshot = load_zero_model(DATA_PATH)\n",
        "#                 new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "#                 classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "#                 inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "#                 input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "#                 with torch.no_grad():\n",
        "#                     outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#                     logits = outputs.logits\n",
        "#                     probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "#                 scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "#                 output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "#                 scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "#                 new_labels = []\n",
        "#                 new_scores = {}\n",
        "#                 service_scores = []\n",
        "#                 for label in scores_from_model1.keys():\n",
        "#                     averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "#                     if label == '맛':\n",
        "#                         new_scores['Quality'] = averaged_score\n",
        "#                         if averaged_score >= 0.35:\n",
        "#                             new_labels.append('Quality')\n",
        "#                     elif label == '양':\n",
        "#                         new_scores['Quantity'] = averaged_score\n",
        "#                         if averaged_score >= 0.35:\n",
        "#                             new_labels.append('Quantity')\n",
        "#                     elif label in ['서비스', '배달', '가격']:\n",
        "#                         service_scores.append(averaged_score)\n",
        "#                 if service_scores:\n",
        "#                     avg_service_score = sum(service_scores) / len(service_scores)\n",
        "#                     new_scores['Service'] = avg_service_score\n",
        "#                     if avg_service_score >= 0.35:\n",
        "#                         new_labels.append('Service')\n",
        "#                 new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "#                 new_predicted_labels = \", \".join(new_labels)\n",
        "#                 st.write(f\"Label Scores: {new_label_scores}\")\n",
        "#                 st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "#                 model = loaded_model(DATA_PATH)\n",
        "#                 tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "#                 with st.spinner(\"답변 생성 중입니다...\"):\n",
        "#                     reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "#                 st.success(\"완료!\")\n",
        "#                 st.write(\"답글을 추천해 드려요. : \")\n",
        "#                 st.write(reply)\n",
        "#             else:\n",
        "#                 st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "#     elif choice == \"리뷰 분석\":\n",
        "#         analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "#         if analysis_choice == \"부정 리뷰 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "#             neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "#             pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "#             plt.rcParams.update(plt.rcParamsDefault)\n",
        "#             plt.rc('font', family='NanumBarunGothic')\n",
        "#             fig, ax = plt.subplots(figsize=(6, 6))\n",
        "#             short_label_counts = neg_short_result['label'].value_counts()\n",
        "#             ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "#             plt.title('리뷰 현황')\n",
        "#             st.pyplot(fig)\n",
        "\n",
        "#         elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "#             merged_df = pd.read_csv(f'{DATA_PATH}merged_df_2months.csv')\n",
        "#             merged_df_3y = pd.read_csv(f'{DATA_PATH}merged_df_3years.csv')\n",
        "#             merged_df_3y = merged_df_3y.dropna()\n",
        "#             plot_review_analysis(merged_df, merged_df_3y)\n",
        "#             st.markdown(\"---\")\n",
        "\n",
        "#         elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "#             df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "#             df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "#             input_id = st.text_input(\"고객 ID 입력: \")\n",
        "#             plot_temperature_analysis(df2, input_id)\n",
        "\n",
        "#             pass\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HipkVzU7DDsJ",
        "outputId": "0939f865-f098-49f0-dd50-acf5eae97074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력순서 변경\n"
      ],
      "metadata": {
        "id": "pY1yz3mhcN8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import streamlit as st\n",
        "# from streamlit_option_menu import option_menu\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import re\n",
        "# import time\n",
        "# from PIL import Image\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# from sklearn.metrics.pairwise import pairwise_distances\n",
        "# import seaborn as sns\n",
        "# from scipy.interpolate import make_interp_spline\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "# bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "# model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# # 유사도 평가 함수\n",
        "# def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "#     input_embedding = bert_model.encode(input_text)\n",
        "#     generated_embedding = bert_model.encode(generated_text)\n",
        "#     cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "#     input_tokens = set(input_text.split())\n",
        "#     generated_tokens = set(generated_text.split())\n",
        "#     jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "#     weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "#     return weighted_sim\n",
        "\n",
        "# # 모델 로드\n",
        "# def loaded_model(DATA_PATH):\n",
        "#     model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "#     return model\n",
        "\n",
        "# def load_zero_model(DATA_PATH):\n",
        "#     model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "#     return model_zeroshot\n",
        "\n",
        "# def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "#     new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "#     return new_tokenizer\n",
        "\n",
        "# def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "#     classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "#     return classifier\n",
        "\n",
        "# # 토크나이저 로드\n",
        "# def loaded_tokenizer(DATA_PATH):\n",
        "#     model_name = \"skt/kogpt2-base-v2\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "#                                           bos_token='</s>',\n",
        "#                                           eos_token='</s>',\n",
        "#                                           unk_token='<unk>',\n",
        "#                                           pad_token='<pad>',\n",
        "#                                           mask_token='<mask>',\n",
        "#                                           max_len=1024)\n",
        "#     return tokenizer\n",
        "\n",
        "# # 답변 생성 함수\n",
        "# def generate_response(model, tokenizer, input_text, num_samples):\n",
        "#     text = \"<q>\" + input_text + \"</s><a>\"\n",
        "#     x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "#     q_len = len(text) + 1\n",
        "\n",
        "#     best_generated_text = None\n",
        "#     best_similarity_score = -1.0\n",
        "#     generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "#     for i in range(num_samples):\n",
        "#         result_ids = model.generate(x,\n",
        "#                                         max_length=1024,\n",
        "#                                         repetition_penalty=2.0,\n",
        "#                                         num_beams=1,\n",
        "#                                         num_return_sequences=1,\n",
        "#                                         no_repeat_ngram_size=4,\n",
        "#                                         use_cache=True,\n",
        "#                                         do_sample=True,\n",
        "#                                         temperature=0.8,\n",
        "#                                         top_k=90,\n",
        "#                                         top_p=0.95,\n",
        "#                                         early_stopping=True\n",
        "#                                         )\n",
        "#         generated_text = tokenizer.decode(result_ids[0])\n",
        "#         generated_text = generated_text[q_len:-4]\n",
        "#         generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "#         similarity_score = evaluate_similarity(text, generated_text)\n",
        "#         generated_texts.append((similarity_score,generated_text))\n",
        "#         print(generated_texts[i])\n",
        "#         if similarity_score > best_similarity_score:\n",
        "#             best_similarity_score = similarity_score\n",
        "#             best_generated_text = generated_text\n",
        "#     print(\"Best_similarity_score:\", best_similarity_score)\n",
        "#     return best_generated_text\n",
        "\n",
        "# # 그래프\n",
        "\n",
        "# def plot_review_analysis(merged_df, merged_df_3y):\n",
        "#     fig1, ax1 = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "#     plt.rcParams.update(plt.rcParamsDefault)\n",
        "#     plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "#     # 그래프 그리기\n",
        "#     sns.lineplot(data=merged_df, x='date', y='pos_7D_score', ax=ax1, label='긍정 지수', marker='o', linestyle='-', color='b')\n",
        "#     sns.lineplot(data=merged_df, x='date', y='neg_7D_score', ax=ax1, label='부정 지수', marker='s', linestyle='--', color='r')\n",
        "\n",
        "#     # 그래프 설정\n",
        "#     ax1.set_title('긍부정 지수 변화 (2개월)', fontsize=14)\n",
        "#     ax1.set_xlabel('일자', fontsize=12)\n",
        "#     ax1.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     ax1.legend(fontsize=12)\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig1)\n",
        "\n",
        "\n",
        "#     st.markdown(\"---\")\n",
        "\n",
        "#     x = merged_df_3y['DATE']\n",
        "#     y_pos = merged_df_3y['pos_7D_score']\n",
        "#     y_neg = merged_df_3y['neg_7D_score']\n",
        "\n",
        "#     mask = ~np.isnan(y_pos) & ~np.isnan(y_neg) & ~np.isinf(y_pos) & ~np.isinf(y_neg)\n",
        "#     x = x[mask]\n",
        "#     y_pos = y_pos[mask]\n",
        "#     y_neg = y_neg[mask]\n",
        "\n",
        "#     x_numeric = pd.to_datetime(x).astype(int)\n",
        "\n",
        "#     spline_pos = make_interp_spline(x_numeric, y_pos, k=3)\n",
        "#     spline_neg = make_interp_spline(x_numeric, y_neg, k=3)\n",
        "#     x_new = np.linspace(x_numeric.min(), x_numeric.max(), 300)\n",
        "#     y_pos_smooth = spline_pos(x_new)\n",
        "#     y_neg_smooth = spline_neg(x_new)\n",
        "\n",
        "#     fig2, ax2 = plt.subplots(figsize=(10, 4))\n",
        "#     ax2.plot(pd.to_datetime(x_new), y_pos_smooth, label='긍정 지수', color='b')\n",
        "#     ax2.plot(pd.to_datetime(x_new), y_neg_smooth, label='부정 지수', color='r')\n",
        "#     ax2.set_title('긍부정 지수 변화 (3개년)', fontsize=14)\n",
        "#     ax2.set_xlabel('일자', fontsize=12)\n",
        "#     ax2.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     ax2.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig2)\n",
        "\n",
        "\n",
        "# def plot_temperature_analysis(df2, input_id):\n",
        "#     review_count = len(df2[df2['ID'] == input_id])\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     if not id_df.empty:\n",
        "#         mean_score = id_df['NEW_SCORE'].mean()\n",
        "#         def scale_temperature(score):\n",
        "#             base_temp = 36.5\n",
        "#             ratio = 30\n",
        "#             scaled_temp = base_temp + (score * ratio)\n",
        "#             return scaled_temp\n",
        "#         scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "#         mean_temperature = scaled_scores.mean()\n",
        "#         line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "#         line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "#         ax.set_xlabel('일자')\n",
        "#         ax.set_ylabel('온도 (°C)')\n",
        "#         ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "#         plt.xticks(id_df['DATE'], rotation=45)\n",
        "#         plt.tight_layout()\n",
        "#         plt.ylim(0, 70)\n",
        "#         y_ticks = np.arange(0, 71, 10)\n",
        "#         plt.yticks(y_ticks)\n",
        "#         plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "#         ax.legend()\n",
        "#         st.pyplot(fig)\n",
        "#         st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "#         st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "#         st.write(f'리뷰 횟수: {review_count}')\n",
        "#     else:\n",
        "#         st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "# def main():\n",
        "#     url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "#     st.image(url)\n",
        "\n",
        "#     DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\"],\n",
        "#                              icons=['house', 'kanban', 'bi bi-robot'],\n",
        "#                              menu_icon=\"app-indicator\", default_index=0,\n",
        "#                              styles={\n",
        "#                                  \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "#                                  \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "#                                  \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "#                                  \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "#                              }\n",
        "#         )\n",
        "\n",
        "#     if choice == \"사장님 답글 남기기\":\n",
        "#         candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "#         st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "#         user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "#         submit_button = st.button(\"Submit\")\n",
        "\n",
        "#         if submit_button:\n",
        "#             if user_input:\n",
        "#                 # 사장님 답변 생성 부분\n",
        "#                 model = loaded_model(DATA_PATH)\n",
        "#                 tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "#                 with st.spinner(\"답변 생성 중입니다...\"):\n",
        "#                     reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "#                 st.success(f\"답글을 추천해 드려요 : \\n\\n{reply}\")\n",
        "\n",
        "#                 # 라벨 예측 부분\n",
        "#                 #st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                 model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "#                 model_zeroshot = load_zero_model(DATA_PATH)\n",
        "#                 new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "#                 classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "#                 inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "#                 input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "#                 with st.spinner(\"라벨 생성 중입니다...\"):\n",
        "#                     with torch.no_grad():\n",
        "#                         outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#                         logits = outputs.logits\n",
        "#                         probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "#                     scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "#                     output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "#                     scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "#                     new_labels = []\n",
        "#                     new_scores = {}\n",
        "#                     service_scores = []\n",
        "#                     for label in scores_from_model1.keys():\n",
        "#                         averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "#                         if label == '맛':\n",
        "#                             new_scores['Quality'] = averaged_score\n",
        "#                             if averaged_score >= 0.35:\n",
        "#                                 new_labels.append('Quality')\n",
        "#                         elif label == '양':\n",
        "#                             new_scores['Quantity'] = averaged_score\n",
        "#                             if averaged_score >= 0.35:\n",
        "#                                 new_labels.append('Quantity')\n",
        "#                         elif label in ['서비스', '배달', '가격']:\n",
        "#                             service_scores.append(averaged_score)\n",
        "#                     if service_scores:\n",
        "#                         avg_service_score = sum(service_scores) / len(service_scores)\n",
        "#                         new_scores['Service'] = avg_service_score\n",
        "#                         if avg_service_score >= 0.35:\n",
        "#                             new_labels.append('Service')\n",
        "#                     new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "#                     new_predicted_labels = \", \".join(new_labels)\n",
        "#                 #st.write(f\"Label Scores: {new_label_scores}\")\n",
        "#                 #st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "#                 #st.write(\" 고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                 st.success(\"고객 리뷰에 대한 라벨은 {} 입니다.\".format(new_predicted_labels))\n",
        "\n",
        "#                 #st.success(\"\"\"\n",
        "#                 #Label Scores: {}\\n\n",
        "#                 #Predicted Labels: {}\n",
        "#                 #\"\"\".format(new_label_scores, new_predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "#             else:\n",
        "#                 st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "#     elif choice == \"리뷰 분석\":\n",
        "#         analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "#         if analysis_choice == \"부정 리뷰 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "#             neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "#             pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "#             plt.rcParams.update(plt.rcParamsDefault)\n",
        "#             plt.rc('font', family='NanumBarunGothic')\n",
        "#             fig, ax = plt.subplots(figsize=(6, 6))\n",
        "#             short_label_counts = neg_short_result['label'].value_counts()\n",
        "#             ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "#             #plt.title('리뷰 현황')\n",
        "#             st.pyplot(fig)\n",
        "\n",
        "#         elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "#             merged_df = pd.read_csv(f'{DATA_PATH}merged_df_2months.csv')\n",
        "#             merged_df_3y = pd.read_csv(f'{DATA_PATH}merged_df_3years.csv')\n",
        "#             merged_df_3y = merged_df_3y.dropna()\n",
        "#             plot_review_analysis(merged_df, merged_df_3y)\n",
        "#             st.markdown(\"---\")\n",
        "\n",
        "#         elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "#             df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "#             df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "#             input_id = st.text_input(\"고객 ID 입력: \")\n",
        "#             plot_temperature_analysis(df2, input_id)\n",
        "\n",
        "#             pass\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOThRCcEcMUX",
        "outputId": "3cbd9b61-3951-4f38-9cf3-138fd1dd499c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import streamlit as st\n",
        "# from streamlit_option_menu import option_menu\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import re\n",
        "# import time\n",
        "# from PIL import Image\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# from sklearn.metrics.pairwise import pairwise_distances\n",
        "# import seaborn as sns\n",
        "# from scipy.interpolate import make_interp_spline\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "# bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "# model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# # 유사도 평가 함수\n",
        "# def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "#     input_embedding = bert_model.encode(input_text)\n",
        "#     generated_embedding = bert_model.encode(generated_text)\n",
        "#     cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "#     input_tokens = set(input_text.split())\n",
        "#     generated_tokens = set(generated_text.split())\n",
        "#     jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "#     weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "#     return weighted_sim\n",
        "\n",
        "# # 모델 로드\n",
        "# def loaded_model(DATA_PATH):\n",
        "#     model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "#     return model\n",
        "\n",
        "# def load_zero_model(DATA_PATH):\n",
        "#     model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "#     return model_zeroshot\n",
        "\n",
        "# def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "#     new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "#     return new_tokenizer\n",
        "\n",
        "# def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "#     classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "#     return classifier\n",
        "\n",
        "# # 토크나이저 로드\n",
        "# def loaded_tokenizer(DATA_PATH):\n",
        "#     model_name = \"skt/kogpt2-base-v2\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "#                                           bos_token='</s>',\n",
        "#                                           eos_token='</s>',\n",
        "#                                           unk_token='<unk>',\n",
        "#                                           pad_token='<pad>',\n",
        "#                                           mask_token='<mask>',\n",
        "#                                           max_len=1024)\n",
        "#     return tokenizer\n",
        "\n",
        "# # 답변 생성 함수\n",
        "# def generate_response(model, tokenizer, input_text, num_samples):\n",
        "#     text = \"<q>\" + input_text + \"</s><a>\"\n",
        "#     x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "#     q_len = len(text) + 1\n",
        "\n",
        "#     best_generated_text = None\n",
        "#     best_similarity_score = -1.0\n",
        "#     generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "#     for i in range(num_samples):\n",
        "#         result_ids = model.generate(x,\n",
        "#                                         max_length=1024,\n",
        "#                                         repetition_penalty=2.0,\n",
        "#                                         num_beams=1,\n",
        "#                                         num_return_sequences=1,\n",
        "#                                         no_repeat_ngram_size=4,\n",
        "#                                         use_cache=True,\n",
        "#                                         do_sample=True,\n",
        "#                                         temperature=0.8,\n",
        "#                                         top_k=90,\n",
        "#                                         top_p=0.95,\n",
        "#                                         early_stopping=True\n",
        "#                                         )\n",
        "#         generated_text = tokenizer.decode(result_ids[0])\n",
        "#         generated_text = generated_text[q_len:-4]\n",
        "#         generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "#         similarity_score = evaluate_similarity(text, generated_text)\n",
        "#         generated_texts.append((similarity_score,generated_text))\n",
        "#         print(generated_texts[i])\n",
        "#         if similarity_score > best_similarity_score:\n",
        "#             best_similarity_score = similarity_score\n",
        "#             best_generated_text = generated_text\n",
        "#     print(\"Best_similarity_score:\", best_similarity_score)\n",
        "#     return best_generated_text\n",
        "\n",
        "# # 그래프\n",
        "\n",
        "# def plot_review_analysis(merged_df):\n",
        "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
        "#     plt.rcParams.update(plt.rcParamsDefault)\n",
        "#     plt.rc('font', family='NanumBarunGothic')\n",
        "#     sns.lineplot(data=merged_df.tail(5), x='DATE', y='pos_7D_score', label='긍정 지수', marker='o', linestyle='-', color='b', ax=ax)\n",
        "#     sns.lineplot(data=merged_df.tail(5), x='DATE', y='neg_7D_score', label='부정 지수', marker='s', linestyle='--', color='r', ax=ax)\n",
        "#     plt.title('긍부정 지수 변화 (1개월)', fontsize=14)\n",
        "#     plt.xlabel('일자', fontsize=12)\n",
        "#     plt.ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig)\n",
        "\n",
        "\n",
        "# def plot_temperature_analysis(df2, input_id):\n",
        "#     review_count = len(df2[df2['ID'] == input_id])\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     if not id_df.empty:\n",
        "#         mean_score = id_df['NEW_SCORE'].mean()\n",
        "#         def scale_temperature(score):\n",
        "#             base_temp = 36.5\n",
        "#             ratio = 30\n",
        "#             scaled_temp = base_temp + (score * ratio)\n",
        "#             return scaled_temp\n",
        "#         scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "#         mean_temperature = scaled_scores.mean()\n",
        "#         line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "#         line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "#         ax.set_xlabel('일자')\n",
        "#         ax.set_ylabel('온도 (°C)')\n",
        "#         ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "#         plt.xticks(id_df['DATE'], rotation=45)\n",
        "#         plt.tight_layout()\n",
        "#         plt.ylim(0, 70)\n",
        "#         y_ticks = np.arange(0, 71, 10)\n",
        "#         plt.yticks(y_ticks)\n",
        "#         plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "#         ax.legend()\n",
        "#         st.pyplot(fig)\n",
        "#         st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "#         st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "#         st.write(f'리뷰 횟수: {review_count}')\n",
        "#     else:\n",
        "#         st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "# def plot_customer_temperature_type(df2, input_id):\n",
        "#     id_index = df2[df2['ID'] == input_id].index\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     # 빨간색 계열의 팔레트 생성\n",
        "#     red_palette = [\"#FF3333\", \"#FF6666\", \"#FF9999\", \"#FFCCCC\"]\n",
        "\n",
        "#     # seaborn의 기본 색상 팔레트를 빨간색 계열로 설정\n",
        "#     sns.set_palette(sns.color_palette(red_palette))\n",
        "\n",
        "#     fig, ax = plt.subplots()\n",
        "#     # 기존 데이터의 산점도 그리기\n",
        "#     sns.scatterplot(x='score_mean', y='id_count', hue='cluster', data=df2, ax=ax)\n",
        "\n",
        "#     # 새로운 데이터 포인트 추가\n",
        "#     sns.scatterplot(x=id_df['score_mean'], y=id_df['id_count'], color='red', label='Data', s=120, ax=ax)\n",
        "\n",
        "#     # 범례 추가\n",
        "#     ax.legend(labels=['뜨거움', '따뜻함', '차가움', '미지근함'])\n",
        "\n",
        "#     # 그래프 제목 설정\n",
        "#     plt.title('고객 온도 유형 분류')\n",
        "\n",
        "#     st.pyplot(fig)\n",
        "\n",
        "\n",
        "# def main():\n",
        "\n",
        "#     DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\"],\n",
        "#                              icons=['house', 'kanban', 'bi bi-robot'],\n",
        "#                              menu_icon=\"app-indicator\", default_index=0,\n",
        "#                              styles={\n",
        "#                                  \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "#                                  \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "#                                  \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "#                                  \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "#                              }\n",
        "#         )\n",
        "\n",
        "#     if choice == \"사장님 답글 남기기\":\n",
        "#         url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "#         st.image(url)\n",
        "#         candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "#         st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "#         user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "#         submit_button = st.button(\"Submit\")\n",
        "\n",
        "#         if submit_button:\n",
        "#             if user_input:\n",
        "#                 # 사장님 답변 생성 부분\n",
        "#                 model = loaded_model(DATA_PATH)\n",
        "#                 tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "#                 with st.spinner(\"답변 생성 중입니다...\"):\n",
        "#                     reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "#                 st.success(f\"답글을 추천해 드려요 : \\n\\n{reply}\")\n",
        "\n",
        "#                 # 라벨 예측 부분\n",
        "\n",
        "#                 with st.spinner(\"고객 리뷰에 대한 예측 라벨 생성 중입니다...\"):\n",
        "\n",
        "#                     #st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                     model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "#                     model_zeroshot = load_zero_model(DATA_PATH)\n",
        "#                     new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "#                     classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "#                     inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "#                     input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "#                     with st.spinner(\"라벨 생성 중입니다...\"):\n",
        "#                         with torch.no_grad():\n",
        "#                             outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#                             logits = outputs.logits\n",
        "#                             probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "#                         scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "#                         output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "#                         scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "#                         new_labels = []\n",
        "#                         new_scores = {}\n",
        "#                         service_scores = []\n",
        "#                         for label in scores_from_model1.keys():\n",
        "#                             averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "#                             if label == '맛':\n",
        "#                                 new_scores['Quality'] = averaged_score\n",
        "#                                 if averaged_score >= 0.35:\n",
        "#                                     new_labels.append('Quality')\n",
        "#                             elif label == '양':\n",
        "#                                 new_scores['Quantity'] = averaged_score\n",
        "#                                 if averaged_score >= 0.35:\n",
        "#                                     new_labels.append('Quantity')\n",
        "#                             elif label in ['서비스', '배달', '가격']:\n",
        "#                                 service_scores.append(averaged_score)\n",
        "#                         if service_scores:\n",
        "#                             avg_service_score = sum(service_scores) / len(service_scores)\n",
        "#                             new_scores['Service'] = avg_service_score\n",
        "#                             if avg_service_score >= 0.35:\n",
        "#                                 new_labels.append('Service')\n",
        "#                         new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "#                         new_predicted_labels = \", \".join(new_labels)\n",
        "#                     #st.write(f\"Label Scores: {new_label_scores}\")\n",
        "#                     #st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "#                     #st.write(\" 고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                 st.success(\"고객 리뷰는 {}에 대한 내용입니다.\".format(new_predicted_labels))\n",
        "\n",
        "#                 #st.success(\"\"\"\n",
        "#                 #Label Scores: {}\\n\n",
        "#                 #Predicted Labels: {}\n",
        "#                 #\"\"\".format(new_label_scores, new_predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "#             else:\n",
        "#                 st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "#     elif choice == \"리뷰 분석\":\n",
        "#         analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "#         if analysis_choice == \"부정 리뷰 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "#             neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "#             pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "#             plt.rcParams.update(plt.rcParamsDefault)\n",
        "#             plt.rc('font', family='NanumBarunGothic')\n",
        "#             fig, ax = plt.subplots(figsize=(6, 6))\n",
        "#             short_label_counts = neg_short_result['label'].value_counts()\n",
        "#             ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "#             st.pyplot(fig)\n",
        "\n",
        "#         elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "#             merged_df = pd.read_csv(f'{DATA_PATH}merged_df.csv')\n",
        "#             plot_review_analysis(merged_df)\n",
        "#             st.markdown(\"---\")\n",
        "\n",
        "#         elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "#             df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "#             tmp_df2 = pd.read_csv(f\"{DATA_PATH}tmp_df2.csv\")\n",
        "#             df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "#             input_id = st.text_input(\"고객 ID 입력: \")\n",
        "\n",
        "#             plot_temperature_analysis(df2, input_id)  # 기존의 온도 지수 그래프 함수\n",
        "#             plot_customer_temperature_type(tmp_df2, input_id)  # 산점도 그래프 함수\n",
        "\n",
        "\n",
        "#             pass\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRrFZ58Sy8k-",
        "outputId": "2663eb9f-d62f-44eb-b3ec-bb0c12efaa20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 고객id 넣었을 때 산점도 출력"
      ],
      "metadata": {
        "id": "5AZEk9mbU-TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import streamlit as st\n",
        "# from streamlit_option_menu import option_menu\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import re\n",
        "# import time\n",
        "# from PIL import Image\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# from sklearn.metrics.pairwise import pairwise_distances\n",
        "# import seaborn as sns\n",
        "# from scipy.interpolate import make_interp_spline\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "# bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "# model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# # 유사도 평가 함수\n",
        "# def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "#     input_embedding = bert_model.encode(input_text)\n",
        "#     generated_embedding = bert_model.encode(generated_text)\n",
        "#     cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "#     input_tokens = set(input_text.split())\n",
        "#     generated_tokens = set(generated_text.split())\n",
        "#     jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "#     weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "#     return weighted_sim\n",
        "\n",
        "# # 모델 로드\n",
        "# def loaded_model(DATA_PATH):\n",
        "#     model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "#     return model\n",
        "\n",
        "# def load_zero_model(DATA_PATH):\n",
        "#     model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "#     return model_zeroshot\n",
        "\n",
        "# def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "#     new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "#     return new_tokenizer\n",
        "\n",
        "# def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "#     classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "#     return classifier\n",
        "\n",
        "# # 토크나이저 로드\n",
        "# def loaded_tokenizer(DATA_PATH):\n",
        "#     model_name = \"skt/kogpt2-base-v2\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "#                                           bos_token='</s>',\n",
        "#                                           eos_token='</s>',\n",
        "#                                           unk_token='<unk>',\n",
        "#                                           pad_token='<pad>',\n",
        "#                                           mask_token='<mask>',\n",
        "#                                           max_len=1024)\n",
        "#     return tokenizer\n",
        "\n",
        "# # 답변 생성 함수\n",
        "# def generate_response(model, tokenizer, input_text, num_samples):\n",
        "#     text = \"<q>\" + input_text + \"</s><a>\"\n",
        "#     x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "#     q_len = len(text) + 1\n",
        "\n",
        "#     best_generated_text = None\n",
        "#     best_similarity_score = -1.0\n",
        "#     generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "#     for i in range(num_samples):\n",
        "#         result_ids = model.generate(x,\n",
        "#                                         max_length=1024,\n",
        "#                                         repetition_penalty=2.0,\n",
        "#                                         num_beams=1,\n",
        "#                                         num_return_sequences=1,\n",
        "#                                         no_repeat_ngram_size=4,\n",
        "#                                         use_cache=True,\n",
        "#                                         do_sample=True,\n",
        "#                                         temperature=0.8,\n",
        "#                                         top_k=90,\n",
        "#                                         top_p=0.95,\n",
        "#                                         early_stopping=True\n",
        "#                                         )\n",
        "#         generated_text = tokenizer.decode(result_ids[0])\n",
        "#         generated_text = generated_text[q_len:-4]\n",
        "#         generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "#         similarity_score = evaluate_similarity(text, generated_text)\n",
        "#         generated_texts.append((similarity_score,generated_text))\n",
        "#         print(generated_texts[i])\n",
        "#         if similarity_score > best_similarity_score:\n",
        "#             best_similarity_score = similarity_score\n",
        "#             best_generated_text = generated_text\n",
        "#     print(\"Best_similarity_score:\", best_similarity_score)\n",
        "#     return best_generated_text\n",
        "\n",
        "# # 그래프\n",
        "\n",
        "# def plot_review_analysis(merged_df):\n",
        "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
        "#     plt.rcParams.update(plt.rcParamsDefault)\n",
        "#     plt.rc('font', family='NanumBarunGothic')\n",
        "#     sns.lineplot(data=merged_df.tail(5), x='DATE', y='pos_7D_score', label='긍정 지수', marker='o', linestyle='-', color='b', ax=ax)\n",
        "#     sns.lineplot(data=merged_df.tail(5), x='DATE', y='neg_7D_score', label='부정 지수', marker='s', linestyle='--', color='r', ax=ax)\n",
        "#     plt.title('긍부정 지수 변화 (1개월)', fontsize=14)\n",
        "#     plt.xlabel('일자', fontsize=12)\n",
        "#     plt.ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig)\n",
        "\n",
        "\n",
        "# def plot_temperature_analysis(df2, input_id):\n",
        "#     review_count = len(df2[df2['ID'] == input_id])\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     if not id_df.empty:\n",
        "#         mean_score = id_df['NEW_SCORE'].mean()\n",
        "#         def scale_temperature(score):\n",
        "#             base_temp = 36.5\n",
        "#             ratio = 30\n",
        "#             scaled_temp = base_temp + (score * ratio)\n",
        "#             return scaled_temp\n",
        "#         scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "#         mean_temperature = scaled_scores.mean()\n",
        "#         line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "#         line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "#         ax.set_xlabel('일자')\n",
        "#         ax.set_ylabel('온도 (°C)')\n",
        "#         ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "#         plt.xticks(id_df['DATE'], rotation=45)\n",
        "#         plt.tight_layout()\n",
        "#         plt.ylim(0, 70)\n",
        "#         y_ticks = np.arange(0, 71, 10)\n",
        "#         plt.yticks(y_ticks)\n",
        "#         plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "#         ax.legend()\n",
        "#         st.pyplot(fig)\n",
        "#         st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "#         st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "#         st.write(f'리뷰 횟수: {review_count}')\n",
        "#     else:\n",
        "#         st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "# def plot_customer_temperature_type(df2, input_id):\n",
        "#     id_index = df2[df2['ID'] == input_id].index\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     # 빨간색 계열의 팔레트 생성\n",
        "#     red_palette = [\"#FF3333\", \"#FF6666\", \"#FF9999\", \"#FFCCCC\"]\n",
        "\n",
        "#     # seaborn의 기본 색상 팔레트를 빨간색 계열로 설정\n",
        "#     sns.set_palette(sns.color_palette(red_palette))\n",
        "\n",
        "#     fig, ax = plt.subplots()\n",
        "#     # 기존 데이터의 산점도 그리기\n",
        "#     sns.scatterplot(x='score_mean', y='id_count', hue='cluster', data=df2, ax=ax)\n",
        "\n",
        "#     # 새로운 데이터 포인트 추가\n",
        "#     sns.scatterplot(x=id_df['score_mean'], y=id_df['id_count'], color='red', label='Data', s=120, ax=ax)\n",
        "\n",
        "#     # 범례 추가\n",
        "#     ax.legend(labels=['뜨거움', '따뜻함', '차가움', '미지근함'])\n",
        "\n",
        "#     # 그래프 제목 설정\n",
        "#     plt.title('고객 온도 유형 분류')\n",
        "\n",
        "#     st.pyplot(fig)\n",
        "\n",
        "\n",
        "# def main():\n",
        "\n",
        "#     DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\"],\n",
        "#                              icons=['house', 'kanban', 'bi bi-robot'],\n",
        "#                              menu_icon=\"app-indicator\", default_index=0,\n",
        "#                              styles={\n",
        "#                                  \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "#                                  \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "#                                  \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "#                                  \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "#                              }\n",
        "#         )\n",
        "\n",
        "#     if choice == \"사장님 답글 남기기\":\n",
        "#         url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "#         st.image(url)\n",
        "#         candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "#         st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "#         user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "#         submit_button = st.button(\"Submit\")\n",
        "\n",
        "#         if submit_button:\n",
        "#             if user_input:\n",
        "#                 # 사장님 답변 생성 부분\n",
        "#                 model = loaded_model(DATA_PATH)\n",
        "#                 tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "#                 with st.spinner(\"답변 생성 중입니다...\"):\n",
        "#                     reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "#                 st.success(f\"답글을 추천해 드려요 : \\n\\n{reply}\")\n",
        "\n",
        "#                 # 라벨 예측 부분\n",
        "\n",
        "#                 with st.spinner(\"고객 리뷰에 대한 예측 라벨 생성 중입니다...\"):\n",
        "\n",
        "#                     #st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                     model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "#                     model_zeroshot = load_zero_model(DATA_PATH)\n",
        "#                     new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "#                     classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "#                     inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "#                     input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "#                     with st.spinner(\"라벨 생성 중입니다...\"):\n",
        "#                         with torch.no_grad():\n",
        "#                             outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#                             logits = outputs.logits\n",
        "#                             probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "#                         scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "#                         output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "#                         scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "#                         new_labels = []\n",
        "#                         new_scores = {}\n",
        "#                         service_scores = []\n",
        "#                         for label in scores_from_model1.keys():\n",
        "#                             averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "#                             if label == '맛':\n",
        "#                                 new_scores['Quality'] = averaged_score\n",
        "#                                 if averaged_score >= 0.35:\n",
        "#                                     new_labels.append('Quality')\n",
        "#                             elif label == '양':\n",
        "#                                 new_scores['Quantity'] = averaged_score\n",
        "#                                 if averaged_score >= 0.35:\n",
        "#                                     new_labels.append('Quantity')\n",
        "#                             elif label in ['서비스', '배달', '가격']:\n",
        "#                                 service_scores.append(averaged_score)\n",
        "#                         if service_scores:\n",
        "#                             avg_service_score = sum(service_scores) / len(service_scores)\n",
        "#                             new_scores['Service'] = avg_service_score\n",
        "#                             if avg_service_score >= 0.35:\n",
        "#                                 new_labels.append('Service')\n",
        "#                         new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "#                         new_predicted_labels = \", \".join(new_labels)\n",
        "#                     #st.write(f\"Label Scores: {new_label_scores}\")\n",
        "#                     #st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "#                     #st.write(\" 고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                 st.success(\"고객 리뷰는 {}에 대한 내용입니다.\".format(new_predicted_labels))\n",
        "\n",
        "#                 #st.success(\"\"\"\n",
        "#                 #Label Scores: {}\\n\n",
        "#                 #Predicted Labels: {}\n",
        "#                 #\"\"\".format(new_label_scores, new_predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "#             else:\n",
        "#                 st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "#     elif choice == \"리뷰 분석\":\n",
        "#         analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "#         if analysis_choice == \"부정 리뷰 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "#             neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "#             pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "#             plt.rcParams.update(plt.rcParamsDefault)\n",
        "#             plt.rc('font', family='NanumBarunGothic')\n",
        "#             fig, ax = plt.subplots(figsize=(6, 6))\n",
        "#             short_label_counts = neg_short_result['label'].value_counts()\n",
        "#             ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "#             st.pyplot(fig)\n",
        "\n",
        "#         elif analysis_choice == \"긍/부정 지수의 변화 추이\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "#             merged_df = pd.read_csv(f'{DATA_PATH}merged_df.csv')\n",
        "#             plot_review_analysis(merged_df)\n",
        "#             st.markdown(\"---\")\n",
        "\n",
        "#         elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "#             df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "#             tmp_df2 = pd.read_csv(f\"{DATA_PATH}tmp_df2.csv\")\n",
        "#             df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "#             input_id = st.text_input(\"고객 ID 입력: \")\n",
        "\n",
        "#             plot_temperature_analysis(df2, input_id)  # 기존의 온도 지수 그래프 함수\n",
        "\n",
        "#             if input_id:  # 고객 ID가 입력되면 산점도 그래프를 출력\n",
        "#                 plot_customer_temperature_type(tmp_df2, input_id)  # 산점도 그래프 함수\n",
        "\n",
        "\n",
        "\n",
        "#             pass\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EBwDjAaU7f_",
        "outputId": "11f70513-9265-4782-b0f4-8a3e210275ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import streamlit as st\n",
        "# from streamlit_option_menu import option_menu\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import re\n",
        "# import time\n",
        "# from PIL import Image\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# from sklearn.metrics.pairwise import pairwise_distances\n",
        "# import seaborn as sns\n",
        "# from scipy.interpolate import make_interp_spline\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "# bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "# model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# # 유사도 평가 함수\n",
        "# def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "#     input_embedding = bert_model.encode(input_text)\n",
        "#     generated_embedding = bert_model.encode(generated_text)\n",
        "#     cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "#     input_tokens = set(input_text.split())\n",
        "#     generated_tokens = set(generated_text.split())\n",
        "#     jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "#     weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "#     return weighted_sim\n",
        "\n",
        "# # 모델 로드\n",
        "# def loaded_model(DATA_PATH):\n",
        "#     model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "#     return model\n",
        "\n",
        "# def load_zero_model(DATA_PATH):\n",
        "#     model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "#     return model_zeroshot\n",
        "\n",
        "# def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "#     new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "#     return new_tokenizer\n",
        "\n",
        "# def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "#     classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "#     return classifier\n",
        "\n",
        "# # 토크나이저 로드\n",
        "# def loaded_tokenizer(DATA_PATH):\n",
        "#     model_name = \"skt/kogpt2-base-v2\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "#                                           bos_token='</s>',\n",
        "#                                           eos_token='</s>',\n",
        "#                                           unk_token='<unk>',\n",
        "#                                           pad_token='<pad>',\n",
        "#                                           mask_token='<mask>',\n",
        "#                                           max_len=1024)\n",
        "#     return tokenizer\n",
        "\n",
        "# # 답변 생성 함수\n",
        "# def generate_response(model, tokenizer, input_text, num_samples):\n",
        "#     text = \"<q>\" + input_text + \"</s><a>\"\n",
        "#     x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "#     q_len = len(text) + 1\n",
        "\n",
        "#     best_generated_text = None\n",
        "#     best_similarity_score = -1.0\n",
        "#     generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "#     for i in range(num_samples):\n",
        "#         result_ids = model.generate(x,\n",
        "#                                         max_length=1024,\n",
        "#                                         repetition_penalty=2.0,\n",
        "#                                         num_beams=1,\n",
        "#                                         num_return_sequences=1,\n",
        "#                                         no_repeat_ngram_size=4,\n",
        "#                                         use_cache=True,\n",
        "#                                         do_sample=True,\n",
        "#                                         temperature=0.8,\n",
        "#                                         top_k=90,\n",
        "#                                         top_p=0.95,\n",
        "#                                         early_stopping=True\n",
        "#                                         )\n",
        "#         generated_text = tokenizer.decode(result_ids[0])\n",
        "#         generated_text = generated_text[q_len:-4]\n",
        "#         generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "#         similarity_score = evaluate_similarity(text, generated_text)\n",
        "#         generated_texts.append((similarity_score,generated_text))\n",
        "#         print(generated_texts[i])\n",
        "#         if similarity_score > best_similarity_score:\n",
        "#             best_similarity_score = similarity_score\n",
        "#             best_generated_text = generated_text\n",
        "#     print(\"Best_similarity_score:\", best_similarity_score)\n",
        "#     return best_generated_text\n",
        "\n",
        "# # 그래프\n",
        "\n",
        "# def plot_review_analysis(merged_df):\n",
        "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
        "#     plt.rcParams.update(plt.rcParamsDefault)\n",
        "#     plt.rc('font', family='NanumBarunGothic')\n",
        "#     sns.lineplot(data=merged_df.tail(5), x='DATE', y='pos_7D_score', label='긍정 지수', marker='o', linestyle='-', color='b', ax=ax)\n",
        "#     sns.lineplot(data=merged_df.tail(5), x='DATE', y='neg_7D_score', label='부정 지수', marker='s', linestyle='--', color='r', ax=ax)\n",
        "#     plt.title('긍부정 지수 변화 (1개월)', fontsize=14)\n",
        "#     plt.xlabel('일자', fontsize=12)\n",
        "#     plt.ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig)\n",
        "\n",
        "\n",
        "# def plot_temperature_analysis(df2, input_id):\n",
        "#     review_count = len(df2[df2['ID'] == input_id])\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     if not id_df.empty:\n",
        "#         mean_score = id_df['NEW_SCORE'].mean()\n",
        "#         def scale_temperature(score):\n",
        "#             base_temp = 36.5\n",
        "#             ratio = 30\n",
        "#             scaled_temp = base_temp + (score * ratio)\n",
        "#             return scaled_temp\n",
        "#         scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "#         mean_temperature = scaled_scores.mean()\n",
        "#         line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "#         line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "#         ax.set_xlabel('일자')\n",
        "#         ax.set_ylabel('온도 (°C)')\n",
        "#         ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "#         plt.xticks(id_df['DATE'], rotation=45)\n",
        "#         plt.tight_layout()\n",
        "#         plt.ylim(0, 70)\n",
        "#         y_ticks = np.arange(0, 71, 10)\n",
        "#         plt.yticks(y_ticks)\n",
        "#         plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "#         ax.legend()\n",
        "#         st.pyplot(fig)\n",
        "#         st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "#         st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "#         st.write(f'리뷰 횟수: {review_count}')\n",
        "#     else:\n",
        "#         st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "# def plot_customer_temperature_type(df2, input_id):\n",
        "#     id_index = df2[df2['ID'] == input_id].index\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     # 빨간색 계열의 팔레트 생성\n",
        "#     red_palette = [\"#FF3333\", \"#FF6666\", \"#FF9999\", \"#FFCCCC\"]\n",
        "\n",
        "#     # seaborn의 기본 색상 팔레트를 빨간색 계열로 설정\n",
        "#     sns.set_palette(sns.color_palette(red_palette))\n",
        "\n",
        "#     fig, ax = plt.subplots()\n",
        "\n",
        "#     # 기존 데이터의 산점도 그리기\n",
        "#     sns.scatterplot(x='score_mean', y='id_count', hue='cluster', data=df2, ax=ax)\n",
        "\n",
        "#     # 새로운 데이터 포인트 추가\n",
        "#     sns.scatterplot(x=id_df['score_mean'], y=id_df['id_count'], color='red', label=input_id, s=120, ax=ax)\n",
        "\n",
        "#     # 범례 추가\n",
        "#     #ax.legend(labels=['뜨거움', '따뜻함', '차가움', '미지근함', input_id])\n",
        "#     # 기존 범례와 추가된 범례를 결합\n",
        "#     handles, labels = ax.get_legend_handles_labels()\n",
        "#     labels[-1] = input_id\n",
        "#     ax.legend(handles=handles, labels=labels)\n",
        "#     # 그래프 제목 설정\n",
        "#     plt.title('고객 온도 유형 분류')\n",
        "\n",
        "#     st.pyplot(fig)\n",
        "\n",
        "\n",
        "# def main():\n",
        "\n",
        "#     DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\"],\n",
        "#                              icons=['house', 'kanban', 'bi bi-robot'],\n",
        "#                              menu_icon=\"app-indicator\", default_index=0,\n",
        "#                              styles={\n",
        "#                                  \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "#                                  \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "#                                  \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "#                                  \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "#                              }\n",
        "#         )\n",
        "\n",
        "#     if choice == \"사장님 답글 남기기\":\n",
        "#         url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "#         st.image(url)\n",
        "#         candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "#         st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "#         user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "#         submit_button = st.button(\"Submit\")\n",
        "\n",
        "#         if submit_button:\n",
        "#             if user_input:\n",
        "#                 # 사장님 답변 생성 부분\n",
        "#                 model = loaded_model(DATA_PATH)\n",
        "#                 tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "#                 with st.spinner(\"답변 생성 중입니다...\"):\n",
        "#                     reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "#                 st.success(f\"답글을 추천해 드려요 : \\n\\n{reply}\")\n",
        "\n",
        "#                 # 라벨 예측 부분\n",
        "\n",
        "#                 with st.spinner(\"고객 리뷰에 대한 예측 라벨 생성 중입니다...\"):\n",
        "\n",
        "#                     #st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                     model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "#                     model_zeroshot = load_zero_model(DATA_PATH)\n",
        "#                     new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "#                     classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "#                     inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "#                     input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "#                     with st.spinner(\"라벨 생성 중입니다...\"):\n",
        "#                         with torch.no_grad():\n",
        "#                             outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#                             logits = outputs.logits\n",
        "#                             probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "#                         scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "#                         output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "#                         scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "#                         new_labels = []\n",
        "#                         new_scores = {}\n",
        "#                         service_scores = []\n",
        "#                         for label in scores_from_model1.keys():\n",
        "#                             averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "#                             if label == '맛':\n",
        "#                                 new_scores['Quality'] = averaged_score\n",
        "#                                 if averaged_score >= 0.35:\n",
        "#                                     new_labels.append('Quality')\n",
        "#                             elif label == '양':\n",
        "#                                 new_scores['Quantity'] = averaged_score\n",
        "#                                 if averaged_score >= 0.35:\n",
        "#                                     new_labels.append('Quantity')\n",
        "#                             elif label in ['서비스', '배달', '가격']:\n",
        "#                                 service_scores.append(averaged_score)\n",
        "#                         if service_scores:\n",
        "#                             avg_service_score = sum(service_scores) / len(service_scores)\n",
        "#                             new_scores['Service'] = avg_service_score\n",
        "#                             if avg_service_score >= 0.35:\n",
        "#                                 new_labels.append('Service')\n",
        "#                         new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "#                         new_predicted_labels = \", \".join(new_labels)\n",
        "#                     #st.write(f\"Label Scores: {new_label_scores}\")\n",
        "#                     #st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "#                     #st.write(\" 고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                 st.success(\"고객 리뷰는 {}에 대한 내용입니다.\".format(new_predicted_labels))\n",
        "\n",
        "#                 #st.success(\"\"\"\n",
        "#                 #Label Scores: {}\\n\n",
        "#                 #Predicted Labels: {}\n",
        "#                 #\"\"\".format(new_label_scores, new_predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "#             else:\n",
        "#                 st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "#     elif choice == \"리뷰 분석\":\n",
        "#         analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "#         if analysis_choice == \"부정 리뷰 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "#             neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "#             pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "#             plt.rcParams.update(plt.rcParamsDefault)\n",
        "#             plt.rc('font', family='NanumBarunGothic')\n",
        "#             fig, ax = plt.subplots(figsize=(6, 6))\n",
        "#             short_label_counts = neg_short_result['label'].value_counts()\n",
        "#             ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "#             st.pyplot(fig)\n",
        "\n",
        "#         elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "#             merged_df = pd.read_csv(f'{DATA_PATH}merged_df.csv')\n",
        "#             plot_review_analysis(merged_df)\n",
        "#             st.markdown(\"---\")\n",
        "\n",
        "#         elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "#             df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "#             tmp_df2 = pd.read_csv(f\"{DATA_PATH}tmp_df2.csv\")\n",
        "#             df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "#             input_id = st.text_input(\"고객 ID 입력: \")\n",
        "\n",
        "#             plot_temperature_analysis(df2, input_id)  # 기존의 온도 지수 그래프 함수\n",
        "\n",
        "#             if input_id:  # 고객 ID가 입력되면 산점도 그래프를 출력\n",
        "#                 plot_customer_temperature_type(tmp_df2, input_id)  # 산점도 그래프 함수\n",
        "\n",
        "\n",
        "\n",
        "#             pass\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1x4Qk4BWe3I",
        "outputId": "79e5c2d1-adc5-4568-ebe9-6c5698ecdb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "최근 3개월 동향"
      ],
      "metadata": {
        "id": "15ZeN7iZDa0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import seaborn as sns\n",
        "from scipy.interpolate import make_interp_spline\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# 유사도 평가 함수\n",
        "def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "    input_embedding = bert_model.encode(input_text)\n",
        "    generated_embedding = bert_model.encode(generated_text)\n",
        "    cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "    input_tokens = set(input_text.split())\n",
        "    generated_tokens = set(generated_text.split())\n",
        "    jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "    weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "    return weighted_sim\n",
        "\n",
        "# 모델 로드\n",
        "def loaded_model(DATA_PATH):\n",
        "    model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "    return model\n",
        "\n",
        "def load_zero_model(DATA_PATH):\n",
        "    model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "    return model_zeroshot\n",
        "\n",
        "def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "    new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "    return new_tokenizer\n",
        "\n",
        "def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "    classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "    return classifier\n",
        "\n",
        "# 토크나이저 로드\n",
        "def loaded_tokenizer(DATA_PATH):\n",
        "    model_name = \"skt/kogpt2-base-v2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          bos_token='</s>',\n",
        "                                          eos_token='</s>',\n",
        "                                          unk_token='<unk>',\n",
        "                                          pad_token='<pad>',\n",
        "                                          mask_token='<mask>',\n",
        "                                          max_len=1024)\n",
        "    return tokenizer\n",
        "\n",
        "# 답변 생성 함수\n",
        "def generate_response(model, tokenizer, input_text, num_samples):\n",
        "    text = \"<q>\" + input_text + \"</s><a>\"\n",
        "    x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    q_len = len(text) + 1\n",
        "\n",
        "    best_generated_text = None\n",
        "    best_similarity_score = -1.0\n",
        "    generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "    for i in range(num_samples):\n",
        "        result_ids = model.generate(x,\n",
        "                                        max_length=1024,\n",
        "                                        repetition_penalty=2.0,\n",
        "                                        num_beams=1,\n",
        "                                        num_return_sequences=1,\n",
        "                                        no_repeat_ngram_size=4,\n",
        "                                        use_cache=True,\n",
        "                                        do_sample=True,\n",
        "                                        temperature=0.8,\n",
        "                                        top_k=90,\n",
        "                                        top_p=0.95,\n",
        "                                        early_stopping=True\n",
        "                                        )\n",
        "        generated_text = tokenizer.decode(result_ids[0])\n",
        "        generated_text = generated_text[q_len:-4]\n",
        "        generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "        similarity_score = evaluate_similarity(text, generated_text)\n",
        "        generated_texts.append((similarity_score,generated_text))\n",
        "        print(generated_texts[i])\n",
        "        if similarity_score > best_similarity_score:\n",
        "            best_similarity_score = similarity_score\n",
        "            best_generated_text = generated_text\n",
        "    print(\"Best_similarity_score:\", best_similarity_score)\n",
        "    return best_generated_text\n",
        "\n",
        "# 그래프\n",
        "def plot_review_analysis(merged_df):\n",
        "\n",
        "    interval = len(merged_df.tail(3 * 5)) // 15\n",
        "    red_ticks_dates = merged_df.tail(3 * 5)['DATE'].iloc[::interval].values\n",
        "\n",
        "    merged_df['DATE'] = pd.to_datetime(merged_df['DATE'])\n",
        "    fig, ax = plt.subplots(figsize=(15, 9))\n",
        "    plt.rcParams.update(plt.rcParamsDefault)\n",
        "    plt.rc('font', family='NanumBarunGothic')\n",
        "    sns.lineplot(data=merged_df.tail(3*5), x='DATE', y='pos_7D_score', label='긍정 지수', marker='o', linestyle='-', color='b', ax=ax)\n",
        "    sns.lineplot(data=merged_df.tail(3*5), x='DATE', y='neg_7D_score', label='부정 지수', marker='s', linestyle='--', color='r', ax=ax)\n",
        "    ax.tick_params(axis='x', labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "    ax.set_xticks(red_ticks_dates)\n",
        "\n",
        "\n",
        "    plt.title('긍부정 지수 변화 (3개월)', fontsize=20)\n",
        "    plt.xlabel('일자', fontsize=20)\n",
        "    plt.ylabel('리뷰 긍부정 지수', fontsize=20)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "def plot_temperature_analysis(df2, input_id):\n",
        "    review_count = len(df2[df2['ID'] == input_id])\n",
        "    id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "    if not id_df.empty:\n",
        "        mean_score = id_df['NEW_SCORE'].mean()\n",
        "        def scale_temperature(score):\n",
        "            base_temp = 36.5\n",
        "            ratio = 30\n",
        "            scaled_temp = base_temp + (score * ratio)\n",
        "            return scaled_temp\n",
        "        scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "        mean_temperature = scaled_scores.mean()\n",
        "        line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "        line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "        ax.set_xlabel('일자')\n",
        "        ax.set_ylabel('온도 (°C)')\n",
        "        ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "        plt.xticks(id_df['DATE'], rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.ylim(0, 70)\n",
        "        y_ticks = np.arange(0, 71, 10)\n",
        "        plt.yticks(y_ticks)\n",
        "        plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "        ax.legend()\n",
        "        st.pyplot(fig)\n",
        "        st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "        st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "        st.write(f'리뷰 횟수: {review_count}')\n",
        "    else:\n",
        "        st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "def plot_customer_temperature_type(df2, input_id):\n",
        "    id_index = df2[df2['ID'] == input_id].index\n",
        "    id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "    # 빨간색 계열의 팔레트 생성\n",
        "    red_palette = [\"#FF3333\", \"#FF6666\", \"#FF9999\", \"#FFCCCC\"]\n",
        "\n",
        "    # seaborn의 기본 색상 팔레트를 빨간색 계열로 설정\n",
        "    sns.set_palette(sns.color_palette(red_palette))\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # 기존 데이터의 산점도 그리기\n",
        "    sns.scatterplot(x='score_mean', y='id_count', hue='cluster', data=df2, ax=ax)\n",
        "\n",
        "    # 새로운 데이터 포인트 추가\n",
        "    sns.scatterplot(x=id_df['score_mean'], y=id_df['id_count'], color='red', label=input_id, s=120, ax=ax)\n",
        "\n",
        "    # 범례 추가\n",
        "    #ax.legend(labels=['뜨거움', '따뜻함', '차가움', '미지근함', input_id])\n",
        "    # 기존 범례와 추가된 범례를 결합\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    labels[-1] = input_id\n",
        "    ax.legend(handles=handles, labels=labels)\n",
        "    # 그래프 제목 설정\n",
        "    plt.title('고객 온도 유형 분류')\n",
        "\n",
        "    st.pyplot(fig)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "    with st.sidebar:\n",
        "        choice = option_menu(\"Menu\", [\"답변 생성 및 리뷰 분석\", \"리뷰 통계\"],\n",
        "                             icons=['house', 'kanban', 'bi bi-robot'],\n",
        "                             menu_icon=\"app-indicator\", default_index=0,\n",
        "                             styles={\n",
        "                                 \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "                                 \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "                                 \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "                                 \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "                             }\n",
        "        )\n",
        "\n",
        "    if choice == \"답변 생성 및 리뷰 분석\":\n",
        "        url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "        st.image(url)\n",
        "        candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "        st.title(\"답변 생성 및 리뷰 분석\")\n",
        "        user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "        submit_button = st.button(\"Submit\")\n",
        "\n",
        "        if submit_button:\n",
        "            if user_input:\n",
        "                # 사장님 답변 생성 부분\n",
        "                model = loaded_model(DATA_PATH)\n",
        "                tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "                with st.spinner(\"답변 생성 중입니다...\"):\n",
        "                    reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "                st.success(f\"답글을 추천해 드려요 : \\n\\n{reply}\")\n",
        "\n",
        "                # 라벨 예측 부분\n",
        "\n",
        "                with st.spinner(\"고객 리뷰에 대한 예측 라벨 생성 중입니다...\"):\n",
        "\n",
        "                    #st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "                    model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "                    model_zeroshot = load_zero_model(DATA_PATH)\n",
        "                    new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "                    classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "                    inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "                    input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "                    with st.spinner(\"라벨 생성 중입니다...\"):\n",
        "                        with torch.no_grad():\n",
        "                            outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                            logits = outputs.logits\n",
        "                            probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "                        scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "                        output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "                        scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "                        new_labels = []\n",
        "                        new_scores = {}\n",
        "                        service_scores = []\n",
        "                        for label in scores_from_model1.keys():\n",
        "                            averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "                            if label == '맛':\n",
        "                                new_scores['Quality'] = averaged_score\n",
        "                                if averaged_score >= 0.35:\n",
        "                                    new_labels.append('Quality')\n",
        "                            elif label == '양':\n",
        "                                new_scores['Quantity'] = averaged_score\n",
        "                                if averaged_score >= 0.35:\n",
        "                                    new_labels.append('Quantity')\n",
        "                            elif label in ['서비스', '배달', '가격']:\n",
        "                                service_scores.append(averaged_score)\n",
        "                        if service_scores:\n",
        "                            avg_service_score = sum(service_scores) / len(service_scores)\n",
        "                            new_scores['Service'] = avg_service_score\n",
        "                            if avg_service_score >= 0.35:\n",
        "                                new_labels.append('Service')\n",
        "                        new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "                        new_predicted_labels = \", \".join(new_labels)\n",
        "                    #st.write(f\"Label Scores: {new_label_scores}\")\n",
        "                    #st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "                    #st.write(\" 고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "                st.success(\"고객 리뷰는 {}에 대한 내용입니다.\".format(new_predicted_labels))\n",
        "\n",
        "                #st.success(\"\"\"\n",
        "                #Label Scores: {}\\n\n",
        "                #Predicted Labels: {}\n",
        "                #\"\"\".format(new_label_scores, new_predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "            else:\n",
        "                st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "    elif choice == \"리뷰 통계\":\n",
        "        analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "        if analysis_choice == \"부정 리뷰 분석\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "            neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "            pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "            plt.rcParams.update(plt.rcParamsDefault)\n",
        "            plt.rc('font', family='NanumBarunGothic')\n",
        "            fig, ax = plt.subplots(figsize=(6, 6))\n",
        "            short_label_counts = neg_short_result['label'].value_counts()\n",
        "            ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "            merged_df = pd.read_csv(f'{DATA_PATH}merged_df.csv')\n",
        "            plot_review_analysis(merged_df)\n",
        "            st.success(\"현 시점 사장님 가게의 긍정지수는 - 부정지수는 - 입니다. \")\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "        elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "            df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "            tmp_df2 = pd.read_csv(f\"{DATA_PATH}tmp_df2.csv\")\n",
        "            df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "            input_id = st.text_input(\"고객 ID 입력: \")\n",
        "\n",
        "            plot_temperature_analysis(df2, input_id)  # 기존의 온도 지수 그래프 함수\n",
        "\n",
        "            if input_id:  # 고객 ID가 입력되면 산점도 그래프를 출력\n",
        "                plot_customer_temperature_type(tmp_df2, input_id)  # 산점도 그래프 함수\n",
        "\n",
        "\n",
        "\n",
        "            pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6cfIiOoDdmj",
        "outputId": "e1cf3f40-9a39-4eae-bd4c-b478deda6838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "        elif analysis_choice == \"긍/부정 지수의 변화 추이\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>긍/부정 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "            merged_df = pd.read_csv(f'{DATA_PATH}merged_df.csv')\n",
        "            plot_review_analysis(merged_df)\n",
        "\n",
        "            # 최근 날짜의 긍정 지수와 부정 지수 가져오기\n",
        "            recent_pos_score = merged_df['pos_7D_score'].iloc[-1]\n",
        "            recent_neg_score = merged_df['neg_7D_score'].iloc[-1]\n",
        "\n",
        "            st.success(f\"현 시점 사장님 가게의 긍정지수는 {recent_pos_score:.2f} - 부정지수는 {recent_neg_score:.2f} 입니다.\")\n",
        "            st.markdown(\"---\")"
      ],
      "metadata": {
        "id": "DbmOPE4jvFaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import seaborn as sns\n",
        "from scipy.interpolate import make_interp_spline\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# 유사도 평가 함수\n",
        "def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "    input_embedding = bert_model.encode(input_text)\n",
        "    generated_embedding = bert_model.encode(generated_text)\n",
        "    cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "    input_tokens = set(input_text.split())\n",
        "    generated_tokens = set(generated_text.split())\n",
        "    jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "    weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "    return weighted_sim\n",
        "\n",
        "# 모델 로드\n",
        "def loaded_model(DATA_PATH):\n",
        "    model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "    return model\n",
        "\n",
        "def load_zero_model(DATA_PATH):\n",
        "    model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "    return model_zeroshot\n",
        "\n",
        "def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "    new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "    return new_tokenizer\n",
        "\n",
        "def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "    classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "    return classifier\n",
        "\n",
        "# 토크나이저 로드\n",
        "def loaded_tokenizer(DATA_PATH):\n",
        "    model_name = \"skt/kogpt2-base-v2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          bos_token='</s>',\n",
        "                                          eos_token='</s>',\n",
        "                                          unk_token='<unk>',\n",
        "                                          pad_token='<pad>',\n",
        "                                          mask_token='<mask>',\n",
        "                                          max_len=1024)\n",
        "    return tokenizer\n",
        "\n",
        "# 답변 생성 함수\n",
        "def generate_response(model, tokenizer, input_text, num_samples):\n",
        "    text = \"<q>\" + input_text + \"</s><a>\"\n",
        "    x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    q_len = len(text) + 1\n",
        "\n",
        "    best_generated_text = None\n",
        "    best_similarity_score = -1.0\n",
        "    generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "    for i in range(num_samples):\n",
        "        result_ids = model.generate(x,\n",
        "                                        max_length=1024,\n",
        "                                        repetition_penalty=2.0,\n",
        "                                        num_beams=1,\n",
        "                                        num_return_sequences=1,\n",
        "                                        no_repeat_ngram_size=4,\n",
        "                                        use_cache=True,\n",
        "                                        do_sample=True,\n",
        "                                        temperature=0.8,\n",
        "                                        top_k=90,\n",
        "                                        top_p=0.95,\n",
        "                                        early_stopping=True\n",
        "                                        )\n",
        "        generated_text = tokenizer.decode(result_ids[0])\n",
        "        generated_text = generated_text[q_len:-4]\n",
        "        generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "        similarity_score = evaluate_similarity(text, generated_text)\n",
        "        generated_texts.append((similarity_score,generated_text))\n",
        "        print(generated_texts[i])\n",
        "        if similarity_score > best_similarity_score:\n",
        "            best_similarity_score = similarity_score\n",
        "            best_generated_text = generated_text\n",
        "    print(\"Best_similarity_score:\", best_similarity_score)\n",
        "    return best_generated_text\n",
        "\n",
        "# 그래프\n",
        "def plot_review_analysis(merged_df):\n",
        "    merged_df['DATE'] = pd.to_datetime(merged_df['DATE'])\n",
        "\n",
        "    # 3개월치 데이터\n",
        "    interval_3months = len(merged_df.tail(3 * 5)) // 15\n",
        "    red_ticks_dates_3months = merged_df.tail(3 * 5)['DATE'].iloc[::interval_3months].values\n",
        "    fig1, ax1 = plt.subplots(figsize=(15, 9))\n",
        "    sns.lineplot(data=merged_df.tail(3*5), x='DATE', y='pos_7D_score', label='긍정 지수', marker='o', linestyle='-', color='b', ax=ax1)\n",
        "    sns.lineplot(data=merged_df.tail(3*5), x='DATE', y='neg_7D_score', label='부정 지수', marker='s', linestyle='--', color='r', ax=ax1)\n",
        "    ax1.tick_params(axis='x', labelsize=12)\n",
        "    ax1.tick_params(axis='y', labelsize=12)\n",
        "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "    ax1.set_xticks(red_ticks_dates_3months)\n",
        "    ax1.set_title('긍부정 지수 변화 (3개월)', fontsize=20)\n",
        "    ax1.set_xlabel('일자', fontsize=20)\n",
        "    ax1.set_ylabel('리뷰 긍부정 지수', fontsize=20)\n",
        "    ax1.legend()\n",
        "    st.pyplot(fig1)\n",
        "    # 최근 날짜의 긍정 지수와 부정 지수 가져오기\n",
        "    recent_pos_score = merged_df['pos_7D_score'].iloc[-1]\n",
        "    recent_neg_score = merged_df['neg_7D_score'].iloc[-1]\n",
        "    st.success(f\"현시점 사장님 가게의 긍정지수는 {recent_pos_score:.2f}, 부정지수는 {recent_neg_score:.2f} 입니다.\")\n",
        "\n",
        "\n",
        "    # 3년치 데이터\n",
        "    fig2, ax2 = plt.subplots(figsize=(15, 9))\n",
        "    interval_3years = len(merged_df.tail(3 * 365)) // 9  # 4개월 간격\n",
        "    red_ticks_dates_3years = merged_df.tail(3 * 365)['DATE'].iloc[::interval_3years].values\n",
        "    sns.lineplot(data=merged_df.tail(3*365), x='DATE', y='pos_7D_score', label='긍정 지수', marker='o', linestyle='-', color='b', ax=ax2)\n",
        "    sns.lineplot(data=merged_df.tail(3*365), x='DATE', y='neg_7D_score', label='부정 지수', marker='s', linestyle='--', color='r', ax=ax2)\n",
        "    ax2.tick_params(axis='x', labelsize=12)\n",
        "    ax2.tick_params(axis='y', labelsize=12)\n",
        "    ax2.xaxis.set_major_locator(mdates.MonthLocator(interval=4))\n",
        "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "    ax2.set_title('긍부정 지수 변화 (3년)', fontsize=20)\n",
        "    ax2.set_xlabel('일자', fontsize=20)\n",
        "    ax2.set_ylabel('리뷰 긍부정 지수', fontsize=20)\n",
        "    ax2.legend()\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "    if recent_pos_score > recent_neg_score:\n",
        "        st.success(f\"긍정 지수가 더 높습니다. 지금처럼 관리해주세요😀\")\n",
        "    else:\n",
        "        st.warning(f\"부정 지수가 더 높습니다. 서비스 개선이 필요합니다.\")\n",
        "    st.markdown(\"---\")\n",
        "    return recent_pos_score, recent_neg_score\n",
        "\n",
        "\n",
        "def plot_temperature_analysis(df2, input_id):\n",
        "    review_count = len(df2[df2['ID'] == input_id])\n",
        "    id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "    if not id_df.empty:\n",
        "        mean_score = id_df['NEW_SCORE'].mean()\n",
        "        def scale_temperature(score):\n",
        "            base_temp = 36.5\n",
        "            ratio = 30\n",
        "            scaled_temp = base_temp + (score * ratio)\n",
        "            return scaled_temp\n",
        "        scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "        mean_temperature = scaled_scores.mean()\n",
        "        line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "        line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "        ax.set_xlabel('일자')\n",
        "        ax.set_ylabel('온도 (°C)')\n",
        "        ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "        plt.xticks(id_df['DATE'], rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.ylim(0, 70)\n",
        "        y_ticks = np.arange(0, 71, 10)\n",
        "        plt.yticks(y_ticks)\n",
        "        plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "        ax.legend()\n",
        "        st.pyplot(fig)\n",
        "        st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "        st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "        st.write(f'리뷰 횟수: {review_count}')\n",
        "    else:\n",
        "        st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "def plot_customer_temperature_type(df2, input_id):\n",
        "    id_index = df2[df2['ID'] == input_id].index\n",
        "    id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "    # 빨간색 계열의 팔레트 생성\n",
        "    red_palette = [\"#FF3333\", \"#FF6666\", \"#FF9999\", \"#FFCCCC\"]\n",
        "\n",
        "    # seaborn의 기본 색상 팔레트를 빨간색 계열로 설정\n",
        "    sns.set_palette(sns.color_palette(red_palette))\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # 기존 데이터의 산점도 그리기\n",
        "    sns.scatterplot(x='score_mean', y='id_count', hue='cluster', data=df2, ax=ax)\n",
        "\n",
        "    # 새로운 데이터 포인트 추가\n",
        "    sns.scatterplot(x=id_df['score_mean'], y=id_df['id_count'], color='red', label=input_id, s=120, ax=ax)\n",
        "\n",
        "    # 범례 변경\n",
        "    cluster_labels = ['따뜻한', '차가운', '미지근한', '뜨거운']\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    new_labels = []\n",
        "    for label in labels:\n",
        "        if label in ['0', '1', '2', '3']:\n",
        "            new_labels.append(cluster_labels[int(label)])\n",
        "        else:\n",
        "            new_labels.append(label)\n",
        "    ax.legend(handles=handles, labels=new_labels)\n",
        "    plt.title('고객 온도 유형 분류')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # 고객 유형 메시지 출력\n",
        "    customer_cluster = id_df['cluster'].iloc[0]\n",
        "    cluster_messages = {\n",
        "        0: '따뜻한 고객에 해당합니다. 따뜻한 고객일 수록 관리를 소홀히 하면 안되겠죠?😉',\n",
        "        1: '차가운 고객에 해당합니다. 고객의 마음을 녹이기 위한 노력이 필요해 보입니다!!😡',\n",
        "        2: '미지근한 고객에 해당합니다. 고객의 관심을 얻기 위한 다양한 전략을 고려해보세요🌊',\n",
        "        3: '뜨거운 고객에 해당합니다. 더 나은 서비스를 제공하여 고객의 열정을 유지해보세요🔥'\n",
        "    }\n",
        "    st.success(f\"검색하신 고객은 {cluster_messages[customer_cluster]}\")\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "    with st.sidebar:\n",
        "        choice = option_menu(\"Menu\", [\"답변 생성 및 리뷰 분석\", \"리뷰 통계\"],\n",
        "                             icons=['house', 'kanban', 'bi bi-robot'],\n",
        "                             menu_icon=\"app-indicator\", default_index=0,\n",
        "                             styles={\n",
        "                                 \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "                                 \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "                                 \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "                                 \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "                             }\n",
        "        )\n",
        "\n",
        "    if choice == \"답변 생성 및 리뷰 분석\":\n",
        "        url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "        st.image(url)\n",
        "        candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "        st.title(\"답변 생성 및 리뷰 분석\")\n",
        "        user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "        submit_button = st.button(\"Submit\")\n",
        "\n",
        "        if submit_button:\n",
        "            if user_input:\n",
        "                # 사장님 답변 생성 부분\n",
        "                model = loaded_model(DATA_PATH)\n",
        "                tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "                with st.spinner(\"답변 생성 중입니다...\"):\n",
        "                    reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "                st.success(f\"답글을 추천해 드려요 : \\n\\n{reply}\")\n",
        "\n",
        "                # 라벨 예측 부분\n",
        "\n",
        "                with st.spinner(\"고객 리뷰에 대한 예측 라벨 생성 중입니다...\"):\n",
        "\n",
        "                    #st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "                    model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "                    model_zeroshot = load_zero_model(DATA_PATH)\n",
        "                    new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "                    classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "                    inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "                    input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "                    with st.spinner(\"라벨 생성 중입니다...\"):\n",
        "                        with torch.no_grad():\n",
        "                            outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                            logits = outputs.logits\n",
        "                            probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "                        scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "                        output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "                        scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "                        new_labels = []\n",
        "                        new_scores = {}\n",
        "                        service_scores = []\n",
        "                        for label in scores_from_model1.keys():\n",
        "                            averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "                            if label == '맛':\n",
        "                                new_scores['Quality'] = averaged_score\n",
        "                                if averaged_score >= 0.35:\n",
        "                                    new_labels.append('Quality')\n",
        "                            elif label == '양':\n",
        "                                new_scores['Quantity'] = averaged_score\n",
        "                                if averaged_score >= 0.35:\n",
        "                                    new_labels.append('Quantity')\n",
        "                            elif label in ['서비스', '배달', '가격']:\n",
        "                                service_scores.append(averaged_score)\n",
        "                        if service_scores:\n",
        "                            avg_service_score = sum(service_scores) / len(service_scores)\n",
        "                            new_scores['Service'] = avg_service_score\n",
        "                            if avg_service_score >= 0.35:\n",
        "                                new_labels.append('Service')\n",
        "                        new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "                        new_predicted_labels = \", \".join(new_labels)\n",
        "                    #st.write(f\"Label Scores: {new_label_scores}\")\n",
        "                    #st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "                    #st.write(\" 고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "                st.success(\"고객 리뷰는 {}에 대한 내용입니다.\".format(new_predicted_labels))\n",
        "\n",
        "                #st.success(\"\"\"\n",
        "                #Label Scores: {}\\n\n",
        "                #Predicted Labels: {}\n",
        "                #\"\"\".format(new_label_scores, new_predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "            else:\n",
        "                st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "    elif choice == \"리뷰 통계\":\n",
        "        analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부정 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "        if analysis_choice == \"부정 리뷰 분석\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "            neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "            pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "            plt.rcParams.update(plt.rcParamsDefault)\n",
        "            plt.rc('font', family='NanumBarunGothic')\n",
        "            fig, ax = plt.subplots(figsize=(6, 6))\n",
        "            short_label_counts = neg_short_result['label'].value_counts()\n",
        "            ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        elif analysis_choice == \"긍/부정 지수의 변화 추이\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>긍/부정 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "            merged_df = pd.read_csv(f'{DATA_PATH}merged_df.csv')\n",
        "\n",
        "            plot_review_analysis(merged_df)\n",
        "            #st.markdown(\"---\")\n",
        "\n",
        "\n",
        "        elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "            df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "            tmp_df2 = pd.read_csv(f\"{DATA_PATH}tmp_df2.csv\")\n",
        "            df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "            input_id = st.text_input(\"고객 ID 입력: \")\n",
        "\n",
        "            plot_temperature_analysis(df2, input_id)  # 기존의 온도 지수 그래프 함수\n",
        "\n",
        "            if input_id:  # 고객 ID가 입력되면 산점도 그래프를 출력\n",
        "                plot_customer_temperature_type(tmp_df2, input_id)  # 산점도 그래프 함수\n",
        "\n",
        "\n",
        "\n",
        "            pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcycBY6ZlJVi",
        "outputId": "99ec0c24-f105-4e0c-8e27-4be94385dd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i2g-Wp2qIC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b92529-5957-499e-f451-c1f3e2316315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.27.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.37)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4FPFQuNqd-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4b5c7f-673d-4d07-e8c3-e15097730c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit_option_menu in /usr/local/lib/python3.10/dist-packages (0.3.6)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit_option_menu) (1.27.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (5.0.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.1.37)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_option_menu) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit_option_menu) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit_option_menu) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit_option_menu) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_option_menu) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_option_menu) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_option_menu) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_option_menu) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_option_menu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_option_menu) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_option_menu) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (0.10.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit_option_menu) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit_option_menu\n",
        "from streamlit_option_menu import option_menu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhgwGKEDfgld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5393aa2-ef19-45e7-879f-1f5f2147500c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.204.157.152\n"
          ]
        }
      ],
      "source": [
        "# 3\n",
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "\n",
        "# \"Password/Enpoint IP for localtunnel is:\" 우측에 xx.xxx.xx.xxx 혹은 xx.xxx.xxx.xxx 형식의 숫자가 나온다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYLso3nPfj3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e72ea0e-7bc4-4b3e-fc9d-a8c4438011e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.428s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRUzqWCafm_0"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph-wJzRmfoVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ec96ab-ba19-4855-ae33-0196265463fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.1s\n",
            "your url is: https://brown-rockets-fetch.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501\n",
        "\n",
        "# \"your url is:\" 우측에 사이트 주소가 생성된다."
      ]
    }
  ]
}