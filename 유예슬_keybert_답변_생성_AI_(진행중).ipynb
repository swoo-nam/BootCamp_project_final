{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP0bXCpMfmSe3QkY6ueB5oe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swoo-nam/project_final_team1/blob/main/%EC%9C%A0%EC%98%88%EC%8A%AC_keybert_%EB%8B%B5%EB%B3%80_%EC%83%9D%EC%84%B1_AI_(%EC%A7%84%ED%96%89%EC%A4%91).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 특성 추출 사전학습 모델\n",
        "\n",
        "- skt/kobert-base-v1 (131k download)\n",
        "- BM-K/KoSimCSE-roberta (87k download)\n"
      ],
      "metadata": {
        "id": "TtopWHmw4Z-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "8e25a3b6-36aa-4f8d-c539-a7b848b2196a",
        "id": "syYXKegU4dav"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "uKisGqmQ4daw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import os\n",
        "\n",
        "def reset_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/생성 AI 모델링/data/\"\n",
        "DATA_PATH = \"/content/drive/MyDrive/멀티캠퍼스 자료/Machine Learning/data/\"\n",
        "SEED = 42\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LUVPi5v44dax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ApNJ9n4day"
      },
      "outputs": [],
      "source": [
        "yogiyo =pd.read_csv(f\"{DATA_PATH}yogiyo_reviews_jsi_all.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_food = pd.read_csv(f\"{DATA_PATH}playstore_food_reply_0904.csv\")"
      ],
      "metadata": {
        "id": "zx0wMQpC4da0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# yogiyo_added =pd.read_csv(f\"{DATA_PATH}yogiyo_reviews_0905.csv\")\n"
      ],
      "metadata": {
        "id": "tfYixqgZpCW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train= yogiyo[['고객리뷰','사장댓글']]\n",
        "\n",
        "rename_cols = ['review', 'reply']\n",
        "train.columns = rename_cols\n",
        "train.head()"
      ],
      "metadata": {
        "id": "MZvImnqd4da0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_list = []\n",
        "for review in train['review']:\n",
        "    if isinstance(review, str):\n",
        "\n",
        "        pat = re.compile(\"[^a-zA-Z가-힣0-9.,~?!]\")\n",
        "        result = pat.sub(\" \", review)\n",
        "\n",
        "        result = re.sub(r'\\.{2,}', '.', result)\n",
        "        result = re.sub(r'\\,{2,}', ',', result)\n",
        "        result = re.sub(r'\\~{2,}', '~', result)\n",
        "        result = re.sub(r'\\!{2,}', '!', result)\n",
        "        result = re.sub(r'\\?{2,}', '?', result)\n",
        "        result = re.sub(\" +\", \" \", result)\n",
        "        review_list.append(result)\n",
        "    else:\n",
        "        review_list.append(\"\")\n",
        "\n",
        "train['review'] = review_list\n",
        "train.head()"
      ],
      "metadata": {
        "id": "s4Z-jPa24da1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCouLh_o3Atn"
      },
      "outputs": [],
      "source": [
        "reply_list = []\n",
        "for reply in train['reply']:\n",
        "    if isinstance(reply, str):\n",
        "\n",
        "        pat = re.compile(\"[^a-zA-Z가-힣0-9.,~?!]\")\n",
        "        result = pat.sub(\" \", reply)\n",
        "\n",
        "        result = re.sub(r'\\.{2,}', '.', result)\n",
        "        result = re.sub(r'\\,{2,}', ',', result)\n",
        "        result = re.sub(r'\\~{2,}', '~', result)\n",
        "        result = re.sub(r'\\!{2,}', '!', result)\n",
        "        result = re.sub(r'\\?{2,}', '?', result)\n",
        "        result = re.sub(\" +\", \" \", result)\n",
        "        reply_list.append(result)\n",
        "    else:\n",
        "        reply_list.append(\"\")\n",
        "\n",
        "train['reply'] = reply_list\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GONx0LK7CPbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 긍부정지수 추가"
      ],
      "metadata": {
        "id": "NZkseWgHEhR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_posneg = pd.read_csv(f\"{DATA_PATH}train_posneg.csv\")"
      ],
      "metadata": {
        "id": "SyrHIyfwEj2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['review','Unnamed: 0']\n",
        "train_posneg = train_posneg.drop(columns=cols)\n",
        "train_posneg"
      ],
      "metadata": {
        "id": "V-jUof3dFXSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.concat([train,train_posneg],axis=1,ignore_index=True)\n",
        "train.columns = ['review','reply','sentiment','score']"
      ],
      "metadata": {
        "id": "ylGWOE5CFb1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 임시 3000개 추출"
      ],
      "metadata": {
        "id": "uw-eQ66_GbH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = train['sentiment'] =='부정'\n",
        "train_neg = train[mask] #893개\n",
        "train_neg"
      ],
      "metadata": {
        "id": "b-SGfm7YbyqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = train['sentiment'] =='긍정'\n",
        "train_pos = train[mask] #17793개\n",
        "train_pos"
      ],
      "metadata": {
        "id": "4veZVJvxcBhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_neg = train_neg.sample(frac=1)"
      ],
      "metadata": {
        "id": "YhGX_i2Mc5_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_pos = train_pos.sample(frac=1)[:3000-shuffled_neg.shape[0]]"
      ],
      "metadata": {
        "id": "J0R_DjbWcSVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_train = pd.concat([shuffled_neg, shuffled_pos],axis=0)\n",
        "shuffled_train = shuffled_train.sample(frac=1)\n",
        "shuffled_train.shape"
      ],
      "metadata": {
        "id": "QTx82kS5dBjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_train"
      ],
      "metadata": {
        "id": "LQIgOxeBGdBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_train.isna().sum()"
      ],
      "metadata": {
        "id": "RyYu5hBYGE_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_train.shape"
      ],
      "metadata": {
        "id": "2XHn0CS5GK-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keybert (skt kobert)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zyXw5PmUGVAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keybert"
      ],
      "metadata": {
        "id": "lbjnPYllelcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT\n",
        "# from transformers import XLNetTokenizer, BertTokenizer, BertModel\n",
        "from tqdm import tqdm  # tqdm 추가\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "# keybert에 사용할 Kobert 모델 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n",
        "model = AutoModel.from_pretrained(\"skt/kobert-base-v1\")\n",
        "\n",
        "# KeyBERT 모델 초기화\n",
        "keybert_model = KeyBERT(model=model)\n",
        "\n",
        "# 리뷰 데이터 (train['review']로 가정)\n",
        "reviews = shuffled_train['review'] # 셔플로 섞은 3000개에 대해서 키워드 추출함\n",
        "keywords_list = []\n",
        "\n",
        "# tqdm을 사용하여 진행 상황 표시\n",
        "for text in tqdm(reviews):\n",
        "    keywords = keybert_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=10)\n",
        "    keywords = [keyword[0] for keyword in keywords]\n",
        "    keywords_list.append(keywords)\n",
        "\n",
        "# # 결과 출력\n",
        "# for idx, keywords in enumerate(keywords_list):\n",
        "#     print(f\"Review {idx + 1} Keywords:\", keywords)\n",
        "\n",
        "result_df = pd.DataFrame({'Keywords': keywords_list})\n",
        "result_df\n"
      ],
      "metadata": {
        "id": "P6k0f-6UDm6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv(f\"{DATA_PATH}train_3000_keyword_kobert.csv\",index=False,encoding='utf-8')"
      ],
      "metadata": {
        "id": "8mlD3gWuvIAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv(f\"{DATA_PATH}train_3000_keyword_kobert.csv\")"
      ],
      "metadata": {
        "id": "CtU-01OFH3Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = result_df.reset_index()[['Keywords']]\n",
        "tmp"
      ],
      "metadata": {
        "id": "OLjU4qlxKVZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp.isna().sum()"
      ],
      "metadata": {
        "id": "EbBcVfkFGQxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp['Keywords'] = tmp['Keywords'].apply(lambda x: ', '.join(x))"
      ],
      "metadata": {
        "id": "00KnSvevzCtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(f\"{DATA_PATH}train_3000_keyword_kobert.csv\")"
      ],
      "metadata": {
        "id": "bDO26Y_Nxenf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = pd.DataFrame(tmp)\n",
        "tmp"
      ],
      "metadata": {
        "id": "CICg-dGKyGPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = shuffled_train.reset_index()[['review','reply','sentiment','score']]\n",
        "train"
      ],
      "metadata": {
        "id": "DMUwpBg8J4BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = pd.concat([train, tmp],axis=1,ignore_index=True)"
      ],
      "metadata": {
        "id": "F8-l6EcOJmB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp"
      ],
      "metadata": {
        "id": "1etxBxzerr_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Keyword shuffled train 3000"
      ],
      "metadata": {
        "id": "_jJPfNLJK1ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isna().sum()"
      ],
      "metadata": {
        "id": "SrNwLKOkHNVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_keyword = tmp[[4,1,2,3]]\n",
        "train_keyword.columns = ['review','reply','sentiment','score']\n",
        "train_keyword.isna().sum()\n"
      ],
      "metadata": {
        "id": "EiReUwOSK9gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_keyword.to_csv(f'{DATA_PATH}keyword_shuffled_train_3000_0904.csv',index=False,encoding='utf-8')"
      ],
      "metadata": {
        "id": "Gu1MXP44Lfie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sentence shuffled train 3000"
      ],
      "metadata": {
        "id": "epnvNUHJrtFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_original = tmp[[0,1,2,3]]\n",
        "train_original\n",
        "train_keyword.isna().sum()"
      ],
      "metadata": {
        "id": "UDuDJCi9LaWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_original.to_csv(f'{DATA_PATH}original_shuffled_train_3000_0904.csv',index=False,encoding='utf-8')"
      ],
      "metadata": {
        "id": "0wGUYBKWLty6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------학습, 검증, 추론"
      ],
      "metadata": {
        "id": "Hp1FJ09Yr0QC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyword shuffled train 3000"
      ],
      "metadata": {
        "id": "zpNrf__jr9AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv(f'{DATA_PATH}keyword_shuffled_train_3000_0904.csv',encoding='utf-8')"
      ],
      "metadata": {
        "id": "pgyuHpezsEEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_keyword.info()"
      ],
      "metadata": {
        "id": "eJTi_BIKMzC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.info()"
      ],
      "metadata": {
        "id": "oAyRYoeeLyxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.isna().sum() # 저장시에는 review에 결측치 없었는데, 불러오니까 결측치 생김. 인코딩 문제는 아님.형식문제? 확인 필요"
      ],
      "metadata": {
        "id": "6SLR108nznPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리"
      ],
      "metadata": {
        "id": "qCV4tuA9HnJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_keyword.copy()\n",
        "train.isnull().sum()"
      ],
      "metadata": {
        "id": "4IFFXF2qNcz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 고객 id 처리"
      ],
      "metadata": {
        "id": "YANEak0DHps2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.DataFrame(train)\n",
        "# train['reply'] = train['reply'].str.replace(r'\\w+\\s*님', '고객님', regex=True)\n",
        "train['reply'] = train['reply'].str.replace(r'\\w+\\s*님|\\w+\\s*고객님', '고객님', regex=True)"
      ],
      "metadata": {
        "id": "TadRDf_5HkzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IEOtmZ-Tg1F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 가게명 처리"
      ],
      "metadata": {
        "id": "sW8yxhkmHrTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ygy_store_lst = [\"1988응답하라추억의옛날도시락-방이점\", \"워커스커피 로스터스\", \"떡깨비-가락점\", \"당치땡-헬리오시티점\", \"우시장국밥-석촌점\",  \"고돼지-송파점\",  \"마라의신마라탕&마라샹궈\",  \"춘리마라탕-송파점\",  \"손수경의육회담은연어-가락점\",  \"무국적식탁-송파점\",  \"청년치킨-삼전점\",  \"송파만다린\",  \"배달의쌀국수-송파점\",  \"닭강점-헬리오시티점\",  \"토핑폭탄김치찜&김치찌개-송파점\",  \"조형훈족발보쌈\",  \"여왕의브런치\",  \"모어댄버터\",  \"플러스82-송파점\",  \"더티베지\",  \"잭아저씨족발보쌈-본점\",  \"육회&연어-미아본점\",  \"갈비민족-본점\",  \"구구족-성신여대역점\",  \"피자보이시나-대학로점\",  \"왕빈자삼파전-미아본점\",  \"행복한찜닭-성북점\",  \"스시사소우\",  \"저팔계&중국&마라탕&덮밥&요리&전문점\",  \"명작파스타-성북점\",  \"올데이파스타-동대문구점\",  \"대한냉면-성북점\",  \"인생제육\",  \"고기듬뿍미트박스-성북점\",  \"피자스웨그-성북점\",  \"청춘식당묵은지김치찜\",  \"삽교원조두리곱창\",  \"뜸들이다-북서울꿈의숲점\",  \"더팔당매운오징어&닭발 김치찜\",  \"우리집반찬도시락-혜화막내딸지점\",  \"수피자\",  \"마라쿡\",  \"김포불닭발\",  \"헬로팬닭갈비&마약볶음밥\",  \"대찌 대파생고기김치찌개&정육왕국물두루치기\",  \"구래상회\",  \"승도리네곱도리탕\",  \"자성당\",  \"수락\",  \"나인곱창\",  \"어시장\",  \"돈까스회관\",  \"호랑이초밥\",  \"땡초곱창막창\",  \"피자이탈리\",  \"텐텐마라탕\",  \"과일에반하다\",  \"삼다수\",  \"병천토속순대\",  \"최고남제육명가\",  \"짱닭치킨\",  \"걸작떡볶이\",  \"직화삼겹직구삼\",  \"짜글이가돼었소\",  \"부대찌개자신있는집\",  \"토핑폭탄김치찜&김치찌개-부천점\",  \"1989마라탕-부천점\",  \"미친피자-부평점\",  \"천년닭강정-부천부평점\",  \"수상한삼겹살-부천점\",  \"수제죽전문점-본가진죽-본점\",  \"오늘은 분식\",  \"이끌림마라탕\",  \"탐나는피자-부평점\",  \"고기혁명-부천점\",  \"라화방마라탕-신중동점\",  \"전금례닭볶음탕-부천점\",  \"큰아들백순대\",  \"공주닭발-부천시청점\",  \"신자매김치찜&김치찌개\",  \"짱닭치킨-도촌점\",  \"이태리면가게-야탑점\",  \"폴트버거-판교점\",  \"랜돌프뉴욕페페로니-야탑점\",  \"홍싸롱-수제돈까스&파스타\",  \"쇼부덮밥\",  \"카산도-정자본점\",  \"부성초밥-미금본점\",  \"닭장수섭삼계탕&전기구이통닭\",  \"깨돌이김밥-미금점\",  \"울진죽변항\",  \"GTS버거-분당정자점\",  \"코브라독스-분당미금역점\",  \"마라하오-죽전점\",  \"땅끝수산\",  \"초밥대통령-용인수지점\",  \"올데이케밥&샐러드\",  \"야키토리 카마쿠라\",  \"비오키친-서현본점\",  \"부산오빠1인국밥-분당점\",  \"알촌\",  \"밈피자\",  \"고씨네카레\",  \"홍스족발\",  \"뜸들이다\",  \"감성커피\",  \"짚신스시\",  \"떡형\",  \"39도시락\",  \"피제이피자\",  \"황궁쟁반짜장\",  \"OK반점\",  \"모모타코야키&카페\",  \"꼬알라파이\",  \"진지덮밥\",  \"피자프라텔로\",  \"한식세끼1인김치찜&김치찌개\",  \"윤희횟집\",  \"시민보쌈족발&감자탕\",  \"카페봄봄\",  \"킹프레소빅와플\",  \"최가네한쌈\",  \"창타이누들\",  \"보돌미역\",  \"홍대개미\"  ]\n"
      ],
      "metadata": {
        "id": "4x-I6Qs0pSy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_name = []\n",
        "\n",
        "for store in ygy_store_lst:\n",
        "    pat = re.split(r'[- &]', store)\n",
        "    store_name.append(pat[0])\n",
        "\n",
        "len(store_name)"
      ],
      "metadata": {
        "id": "UsT1KELBqesw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_name[:10]"
      ],
      "metadata": {
        "id": "DjMbK9M2qtbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['store'] = \"\"  # full store name을 칼럼에 담기\n",
        "# for name in store_name:\n",
        "#     train[name] = train['reply'].apply(lambda x: name if name in x else '') # 우선 각 가게명 컬럼 생성(그렇게해야 덮어쓰기가 안됨)\n",
        "#     train['store'] = train.apply(lambda row: row['store'] + ',' + row[name] if row[name] else row['store'], axis=1) # 하나로 합치기(맨 앞에 콤마가 생김)\n",
        "\n",
        "# train['store'] = train['store'].apply(lambda x: x[1:] if x.startswith(',') else x) # 맨 앞에 콤마 제거\n",
        "# train = train.drop(columns=store_name) # 각 가게명 컬럼 삭제\n",
        "\n",
        "# train.head()"
      ],
      "metadata": {
        "id": "GZaQqjKQ1tcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1차 : store 이름이 풀로 들어간 경우 <store>로 대체"
      ],
      "metadata": {
        "id": "Ck1z7q_KjOR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_store_names1(text):\n",
        "    for name1 in store_name:\n",
        "        if name1 in text:\n",
        "            # 가게 이름의 일부가 텍스트에 포함되어 있다면 대체\n",
        "            pattern = re.compile(re.escape(name1), re.IGNORECASE)\n",
        "            text = pattern.sub(\"<store>\", text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "RS3W_EcZZIDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_store_names1(\"1988응답하라추억의옛날도시락에서 먹은 음식은 정말 맛있었습니다.\")"
      ],
      "metadata": {
        "id": "N3XrXOjwMTv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_store_names1(\"우시장에서 먹은 음식은 정말 맛있었습니다.\") # 부분이름은 안바뀜"
      ],
      "metadata": {
        "id": "m2VGX-h7jK0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2차 : store 이름이 부분적으로 들어간 경우 store로 대체"
      ],
      "metadata": {
        "id": "4wCUNJdrjWF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#예시\n",
        "\n",
        "name1 = '손수경의육회담은연어'\n",
        "for i in range(len(name1)-1, 1, -1):\n",
        "    part = name1[:i]  # 가게 이름에서 처음부터 i 글자까지의 부분\n",
        "    print(part)"
      ],
      "metadata": {
        "id": "vErux2cEhNLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 뒤에서 앞으로\n",
        "# for i in range(2, len(name1) + 1):\n",
        "#     part = name1[-i:]\n",
        "#     print(part)"
      ],
      "metadata": {
        "id": "T74cQq6oh0-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_store_names2(text):\n",
        "    for name1 in tqdm(store_name, desc=\"Processing\"):\n",
        "        for i in range(len(name1)-1, 1, -1):\n",
        "            part = name1[:i]  # 가게 이름에서 처음부터 i 글자까지의 부분. 글자 긴경우 부터 적용됨\n",
        "            if part in text:\n",
        "                # 가게 이름의 일부가 텍스트에 포함되어 있다면 대체\n",
        "                pattern = re.compile(re.escape(part), re.IGNORECASE)\n",
        "                text = pattern.sub(\"<store>\", text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "R_O1LnEaj4Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_store_names2(\"텐텐에서 먹은 음식은 정말 맛있었습니다.\") # 텐텐마라탕"
      ],
      "metadata": {
        "id": "clFy-xMJj9q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_store_names2(\"손수경에서 먹은 음식은 정말 맛있었습니다.\") # 손수경의육회담은연어"
      ],
      "metadata": {
        "id": "ZjMcvbvAmAQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 3차 : 일반명사/형용사 등은 제외하고 대체해야 함"
      ],
      "metadata": {
        "id": "EQ46knhCpgt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kiwipiepy"
      ],
      "metadata": {
        "id": "Z04GoNrbpvrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # short_name 에서 가게명 이외 일상용어로 사용되는 키워드는 제거\n",
        "# drop_name = ['고기','OK','감성','걸작','공주','과일','김포','대한','땡초','명작','미친','배달','병천','부대','부산','비오','삽교',\n",
        "#              '손수','송파','쇼부','수상','수제','시민','오늘', '오늘은', '우리', '울진', '이끌', '이끌림', '인생', '직화', '진지',\n",
        "#              '천년', '청년', '청춘', '최고', '큰아', '큰아들', '탐나', '토핑', '행복', '행복한', '헬로', '홍대',\n",
        "#              '육회','수락','호랑','갈비','무국','닭장','한식','마라','스시','여왕','돈까','초밥','카페','피자','부대찌','이태리','플러','플러스']\n",
        "# # drop_name = ['과일','오늘', '오늘은','우리', '이끌', '이끌림', '인생','진지','최고''토핑', '행복', '행복한', '한식', '감성','걸작']"
      ],
      "metadata": {
        "id": "m_32ZVq1ptFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kiwipiepy\n",
        "kiwi = kiwipiepy.Kiwi()"
      ],
      "metadata": {
        "id": "zVIKP55yp4HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#가게명의 앞 두글자들 중에서 명사, 형용사, 부사 확인함\n",
        "\n",
        "short_word2 = []\n",
        "\n",
        "for store in store_name:\n",
        "    word = store[:2]\n",
        "    print(word)\n",
        "    short_word2.append(word)"
      ],
      "metadata": {
        "id": "XkxLOMqdnEeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = kiwi.analyze(short_word2)\n",
        "\n",
        "remove_words = []\n",
        "\n",
        "for token in tokens :\n",
        "  word = token[0][0][0].form\n",
        "  pos = token[0][0][0].tag\n",
        "  if pos in ('VA','NNG','MAG','MAJ','VV','XR') and len(word) ==2 :\n",
        "    remove_words.append(word)\n",
        "\n",
        "remove_words"
      ],
      "metadata": {
        "id": "jjJPxcRKY2w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(short_word2), len(remove_words)"
      ],
      "metadata": {
        "id": "8gFqVvpQXrG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_words = set(remove_words)\n",
        "remove_words = list(remove_words)\n",
        "len(remove_words)"
      ],
      "metadata": {
        "id": "-32lptw7Yh58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = kiwi.analyze(store_name)\n",
        "\n",
        "for token in tokens :\n",
        "  word = token[0][0][0].form\n",
        "  pos = token[0][0][0].tag\n",
        "  if pos in ('NNG') and len(word) ==3 :\n",
        "    print(word)\n",
        "\n",
        "# 3글자 일반명사 단어들은 가게명으로 포함해도될듯"
      ],
      "metadata": {
        "id": "nJLAn4h_tqRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = kiwi.analyze(store_name)\n",
        "\n",
        "for token in tokens :\n",
        "  word = token[0][0][0].form\n",
        "  pos = token[0][0][0].tag\n",
        "  if pos in ('NNG') and len(word) ==4 :\n",
        "    print(word)\n",
        "\n",
        "# 4글자 일반명사 단어들은 가게명으로 포함해도될듯"
      ],
      "metadata": {
        "id": "kA3F1EtguNV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_words[:10]"
      ],
      "metadata": {
        "id": "QlU7pu5BzVLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "korean_particles = ['은', '는', '이', '가', '을', '를', '의', '한', '로', '으로', '까지', '이며', '며', '와', '과']\n",
        "\n",
        "#위 일반명사에, 조사를 합친 경우도 제외함"
      ],
      "metadata": {
        "id": "hS1gvHVsw6Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_withparticles = []\n",
        "\n",
        "for word in remove_words :\n",
        "  for particle in korean_particles:\n",
        "    new_word = word + particle\n",
        "    remove_withparticles.append(new_word)"
      ],
      "metadata": {
        "id": "-jiF4oK3znPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 메뉴에 들어있는 명사 제외"
      ],
      "metadata": {
        "id": "qT0YUsBhcLMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ygy_menu_list = ['양식','일식','중식','중국집','태국음식','한식','분식','도시락','카레','커피','국밥','마라탕','마라샹궈','우동','나가사키','연어','치킨','쌀국수','닭강정','김치찜','김치찌개',\n",
        "                '족발','보쌈','육회','갈비','피자','찜닭','파스타','냉면','곱창','닭발','막창','반찬','곱도리탕','순대','떡볶이','부대찌개'\n",
        "                '삼겹살','분식','라면','버거','덮밥','초밥','통닭','짜장','짬뽕','탕수육','카페','와플','누들','김치','온면','디저트','라떼','고기','덮밥',\n",
        "                '새우','돼지','닭','찌개','밥','타코야키','탕',\n",
        "                 '양파','숙주','고수'] # 재료명 제거"
      ],
      "metadata": {
        "id": "HLEGrN2XbVO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menu_for_store = []\n",
        "\n",
        "for name1 in tqdm(ygy_menu_list, desc=\"Processing\"):\n",
        "        for i in range(len(name1), 1, -1):\n",
        "            part = name1[:i]  # 가게 이름에서 처음부터 i 글자까지의 부분. 글자 긴경우 부터 적용됨\n",
        "            menu_for_store.append(part)"
      ],
      "metadata": {
        "id": "tMikb2pvbcff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menu_for_store = set(menu_for_store)\n",
        "menu_for_store = list(menu_for_store)"
      ],
      "metadata": {
        "id": "3W9Jn_atb5XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 최종 함수"
      ],
      "metadata": {
        "id": "jY37HABslEpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_store_names(text):\n",
        "    for name1 in store_name:\n",
        "        # 먼저 가게 이름 전체가 텍스트에 포함되어 있는지 확인\n",
        "        if name1 in text:\n",
        "            # 가게 이름 전체가 텍스트에 포함되어 있다면 대체\n",
        "            pattern = re.compile(re.escape(name1), re.IGNORECASE)\n",
        "            text = pattern.sub(\"<store>\", text)\n",
        "        else:\n",
        "            # 가게 이름의 일부가 텍스트에 포함되어 있는 경우를 확인\n",
        "            for i in range(len(name1), 1, -1):\n",
        "                part = name1[:i]  # 가게 이름에서 처음부터 i 글자까지의 부분\n",
        "                if part in text:\n",
        "                    # 가게 이름의 일부가 텍스트에 포함되어 있고, 해당 부분이 remove_words에 없으며,\n",
        "                    # 해당 부분 뒤에 조사가 붙지 않은 경우에만 대체\n",
        "                    if part not in (remove_words + remove_withparticles + menu_for_store) :\n",
        "                        pattern = re.compile(re.escape(part), re.IGNORECASE)\n",
        "                        text = pattern.sub(\"<store>\", text)\n",
        "                      # 가게 이름 일부를 대체했으면 루프 종료\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "49nevLXYwf4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_store_names('행복한 라화방마라탕에서 맛있게 식사했어요') #행복 부분이 대체안됨"
      ],
      "metadata": {
        "id": "HeCgdjXtuuOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['reply']의 답변들에 함수 적용하기 / 18000개 7분 정도 걸림\n",
        "\n",
        "for i, review in tqdm(enumerate(train['reply']), desc=\"Processing\", ncols=100):\n",
        "    train['reply'][i] = replace_store_names(review)"
      ],
      "metadata": {
        "id": "CVj_9WYaNDtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_rows = train[train['reply'].str.contains(\"<store>\")]\n",
        "changed_rows"
      ],
      "metadata": {
        "id": "paCiFUSISQgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['review']의 리뷰들에 함수 적용하기 / 7분 정도 걸림\n",
        "\n",
        "for i, review in tqdm(enumerate(train['review']), desc=\"Processing\", ncols=100):\n",
        "    train['review'][i] = replace_store_names(review)"
      ],
      "metadata": {
        "id": "i3mEe6nfSE66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_rows = train[train['review'].str.contains(\"<store>\")]"
      ],
      "metadata": {
        "id": "GKpJoyDWSSUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['review'] = train['review'].replace('<store><store> | <store> <store>','<store>')\n",
        "train['reply'] = train['reply'].replace('<store><store> | <store> <store>','<store>')"
      ],
      "metadata": {
        "id": "RpJnIEW9loxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 지점명 처리"
      ],
      "metadata": {
        "id": "ZIsu_pxfIvTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규 표현식을 사용하여 \"~호점\" 패턴을 찾아서 삭제하는 함수\n",
        "def remove_hojum(text):\n",
        "    return re.sub(r'\\w+\\s*호점','', text)\n",
        "\n",
        "# train 데이터프레임의 'reply' 열에 적용하여 \"~호점\"을 삭제\n",
        "train['reply'] = train['reply'].apply(remove_hojum)\n",
        "train['review'] = train['review'].apply(remove_hojum)\n"
      ],
      "metadata": {
        "id": "_m3AFBpgKETe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_list = pd.read_csv(f\"{DATA_PATH}fulldata_07_24_04_P_일반음식점.csv\",encoding='cp949')"
      ],
      "metadata": {
        "id": "6ZJSXCchRRxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_list['소재지전체주소']"
      ],
      "metadata": {
        "id": "4paT6kQ7RrO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address_parts=[] #소재지 데이터에서 서울, 부산 동, 구, 리 등을\n",
        "\n",
        "for address in restaurant_list['소재지전체주소'].astype(str):\n",
        "    if address.startswith('서울'or '부산' or '청주'):\n",
        "        parts = address.split(' ')\n",
        "        for _ in range(0, min(4, len(parts))):  # 최대 5개 또는 주소 부분 개수만큼 반복\n",
        "          part = parts[_]\n",
        "          address_parts.append(part)\n",
        "\n",
        "address_parts = set(address_parts)\n",
        "address_parts = list(address_parts)\n",
        "\n",
        "address_parts = [name for name in address_parts if all(char.isalpha() for char in name)] #알파벳으로만 (한글) 구성된 경우남김. 숫자, 특수문자 지움\n",
        "address_parts.remove('')"
      ],
      "metadata": {
        "id": "BAISn74lARdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가게명에서 지점명 추출하기\n",
        "\n",
        "store_etc_name = []\n",
        "\n",
        "for store in ygy_store_lst:\n",
        "    pat = re.split(r'[- &]', store)\n",
        "    for name in pat[1:]:\n",
        "        if name != '':\n",
        "            store_etc_name.append(name)\n",
        "\n",
        "ygy_region_name = []\n",
        "\n",
        "for region in store_etc_name:\n",
        "  if region[-1] =='점':\n",
        "    ygy_region_name.append(region)"
      ],
      "metadata": {
        "id": "M_z9DZzYUmce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address_parts2 = [] # 추출된 지역명을 지점명으로 변경\n",
        "\n",
        "for address in address_parts :\n",
        "  if len(address) < 3  :\n",
        "    address = address + '점'\n",
        "    address_parts2.append(address)\n",
        "  else :\n",
        "    address = address[:-1] + '점'\n",
        "    address_parts2.append(address)"
      ],
      "metadata": {
        "id": "T3-yQEk8EUp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(address_parts2)"
      ],
      "metadata": {
        "id": "x6wqTY6ouKto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_name = ygy_region_name + address_parts2"
      ],
      "metadata": {
        "id": "EA5GLm7jquol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_name = set(region_name)\n",
        "region_name = list(region_name)"
      ],
      "metadata": {
        "id": "vpppbl8oFGrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_name[:10]"
      ],
      "metadata": {
        "id": "NIKeOwnNGAvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name1 = '성북미아점'\n",
        "\n",
        "for i in range(len(name1), 1, -1):\n",
        "    part = name1[:i]\n",
        "    print(part)"
      ],
      "metadata": {
        "id": "sB17KORWdjXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_region_names(text):\n",
        "    for name1 in region_name:\n",
        "        if name1 in text:\n",
        "            # 지점 이름이 텍스트에 포함되어 있다면 대체\n",
        "            pattern = re.compile(re.escape(name1), re.IGNORECASE)\n",
        "            text = pattern.sub(\"<region>\", text)\n",
        "        else :\n",
        "          for i in range(len(name1), 1, -1):\n",
        "              part = name1[:i]  # 지점 이름에서 처음부터 i 글자까지의 부분\n",
        "              if part in text:\n",
        "                  # 지점 이름의 일부가 텍스트에 포함되어 있다면 대체\n",
        "                  pattern = re.compile(re.escape(part), re.IGNORECASE)\n",
        "                  text = pattern.sub(\"<region>\", text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "rH54BgrJrrr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_region_names('오랜만에 헬리오시티점에서 맛있게 식사했어요')"
      ],
      "metadata": {
        "id": "2fVgh5-T349d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_region_names('성북점이 강북점보다 더 맛있어요')"
      ],
      "metadata": {
        "id": "Gow0zNCcdNyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_region_names('성북구가 강북구보다 더 맛있어요')"
      ],
      "metadata": {
        "id": "vYAEVK0ydx8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, review in tqdm(enumerate(train['reply']), desc=\"Processing\", ncols=100):\n",
        "    train['reply'][i] = replace_region_names(review)"
      ],
      "metadata": {
        "id": "xQoF_Ajaa-6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_rows = train[train['reply'].str.contains(\"<region>\")]\n",
        "changed_rows"
      ],
      "metadata": {
        "id": "zHUwPvlaa-zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, review in tqdm(enumerate(train['review']), desc=\"Processing\", ncols=100):\n",
        "    train['review'][i] = replace_region_names(review)"
      ],
      "metadata": {
        "id": "pHAOOpxWa-uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_rows = train[train['review'].str.contains(\"<region>\")]\n",
        "changed_rows"
      ],
      "metadata": {
        "id": "alopRvLHccRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 메뉴명 처리"
      ],
      "metadata": {
        "id": "_3t3s9V56bmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_list = pd.read_csv(f'{DATA_PATH}전국통합식품영양성분정보(음식)표준데이터.csv', encoding='cp949')"
      ],
      "metadata": {
        "id": "dsUvVP8dUf-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_list = set(food_list['대표식품명'].tolist())"
      ],
      "metadata": {
        "id": "0QH5euNRUtHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_list = list(food_list)"
      ],
      "metadata": {
        "id": "Na14Qp0ZV0tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ygy_menu_list = ['양식','일식','중식','중국집','태국음식','한식','분식','도시락','카레','커피','국밥','마라탕','마라샹궈','우동','나가사키','연어','치킨','쌀국수','닭강정','김치찜','김치찌개',\n",
        "                '족발','보쌈','육회','갈비','피자','찜닭','파스타','냉면','곱창','닭발','막창','반찬','곱도리탕','순대','떡볶이','부대찌개'\n",
        "                '삼겹살','분식','라면','버거','덮밥','초밥','통닭','짜장','짬뽕','탕수육','카페','와플','누들','김치','온면','디저트','라떼','고기','덮밥',\n",
        "             '새우','돼지','닭','찌개','밥','타코야키','탕','밥','국','항정살',\n",
        "                 '양파','숙주','고수'] # 재료명 제거"
      ],
      "metadata": {
        "id": "zXkwQWGZLVre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menu_name = food_list + ygy_menu_list"
      ],
      "metadata": {
        "id": "g_hyhHx8VOOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(menu_name)"
      ],
      "metadata": {
        "id": "t3I7wsfKjhF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_food_list = []  # 새로운 음식을 담을 리스트\n",
        "\n",
        "for food in food_list:\n",
        "    if '(' in food:\n",
        "        food1, food2 = food.split('(')\n",
        "        new_food_list.append(food1.strip())  # 공백 제거 후 리스트에 추가\n",
        "        new_food_list.append(food2.rstrip(')'))\n",
        "    else:\n",
        "        new_food_list.append(food)\n",
        "\n",
        "food_list = new_food_list"
      ],
      "metadata": {
        "id": "OkQbw5gmX3Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menu_name = set(menu_name)\n",
        "menu_name = list(menu_name)\n",
        "\n",
        "menu_name = [name for name in menu_name if all(char.isalpha() for char in name)] #알파벳으로만 (한글) 구성된 경우남김. 숫자, 특수문자 지움\n"
      ],
      "metadata": {
        "id": "EVHiimZMiyp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1차 : 풀로 이름 들어간 것 대체"
      ],
      "metadata": {
        "id": "QuRhM_7J8XeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_menu_names1(text):\n",
        "    # 메뉴 이름을 긴 것부터 짧은 것 순으로 정렬\n",
        "    sorted_menu_names = sorted(menu_name, key=len, reverse=True)\n",
        "\n",
        "    for name1 in sorted_menu_names:\n",
        "        if name1 in text:\n",
        "            # 메뉴 이름이 텍스트에 포함되어 있다면 대체\n",
        "            pattern = re.compile(re.escape(name1), re.IGNORECASE)\n",
        "            text = pattern.sub(\"<menu>\", text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "BwHs85XTbnM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_menu_names1('부대찌개 정말 맛있었어요')"
      ],
      "metadata": {
        "id": "YLyj_wI38bQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_menu_names1('탕, 국, 마라탕, 밥 정말 맛있었어요')"
      ],
      "metadata": {
        "id": "2S4q1c8aiG25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2차 : 부분 이름 들어간 것 대체"
      ],
      "metadata": {
        "id": "ZsNlNwoj8fxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name1='허니브레드'\n",
        "\n",
        "for i in range(len(name1),1,-1):\n",
        "    part = name1[:i]\n",
        "    print(part)"
      ],
      "metadata": {
        "id": "2y30m-ey-Dcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_menu_names2(text):\n",
        "\n",
        "    for name1 in menu_name:\n",
        "        for i in range(len(name1), 1, -1):\n",
        "            part = name1[:i]  # 가게 이름에서 처음부터 i 글자까지의 부분\n",
        "            if part in text:\n",
        "                # 가게 이름의 일부가 텍스트에 포함되어 있다면 대체\n",
        "                pattern = re.compile(re.escape(part), re.IGNORECASE)\n",
        "                text = pattern.sub(\"<menu>\", text)\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "uA4kW6Yr8a7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_menu_names2('부대 정말 맛있었어요')"
      ],
      "metadata": {
        "id": "a-4Xfw-485RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_menu_names2('떡볶 정말 맛있었어요')"
      ],
      "metadata": {
        "id": "0t3CzpNuh0zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 3차 : 일반명사 제외 안해도됨. 재료명 모두 일반명사"
      ],
      "metadata": {
        "id": "zGNlz8x-_ysc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 최종 함수"
      ],
      "metadata": {
        "id": "Ve5CHzTC_h8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_menu_names(text):\n",
        "    # 메뉴 이름을 긴 것부터 짧은 것 순으로 정렬\n",
        "    sorted_menu_names = sorted(menu_name, key=len, reverse=True)\n",
        "\n",
        "    for name1 in sorted_menu_names:\n",
        "        if name1 in text:\n",
        "            # 메뉴 이름이 텍스트에 포함되어 있다면 대체\n",
        "            pattern = re.compile(re.escape(name1), re.IGNORECASE)\n",
        "            text = pattern.sub(\"<menu>\", text)\n",
        "        else:\n",
        "            for i in range(len(name1), 1, -1):\n",
        "                part = name1[:i]  # 가게 이름에서 처음부터 i 글자까지의 부분\n",
        "                if part in text:\n",
        "                    # 가게 이름의 일부가 텍스트에 포함되어 있다면 대체\n",
        "                    pattern = re.compile(re.escape(part), re.IGNORECASE)\n",
        "                    text = pattern.sub(\"<menu>\", text)\n",
        "                     # 대체를 하고 나서는 루프를 종료합니다.\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "gM2CF58VP6eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def replace_menu_names(text):\n",
        "#     # 메뉴 이름을 긴 것부터 짧은 것 순으로 정렬\n",
        "#     if text is not None:\n",
        "#         sorted_menu_names = sorted(menu_name, key=len, reverse=True)\n",
        "\n",
        "#         for name1 in sorted_menu_names:\n",
        "#             if name1 in text:\n",
        "#                 # 메뉴 이름이 텍스트에 포함되어 있다면 대체\n",
        "#                 pattern = re.compile(re.escape(name1), re.IGNORECASE)\n",
        "#                 text = pattern.sub(\"<menu>\", text)\n",
        "#             else:\n",
        "#                 for name1 in menu_name:\n",
        "#                     for i in range(len(name1), 1, -1):\n",
        "#                         part = name1[:i]  # 가게 이름에서 처음부터 i 글자까지의 부분\n",
        "#                         if part in text:\n",
        "#                             # 가게 이름의 일부가 텍스트에 포함되어 있다면 대체\n",
        "#                             pattern = re.compile(re.escape(part), re.IGNORECASE)\n",
        "#                             text = pattern.sub(\"<menu>\", text)\n",
        "#                         break"
      ],
      "metadata": {
        "id": "w7_1mpdm_kGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, review in tqdm(enumerate(train['reply']), desc=\"Processing\", ncols=100):\n",
        "    train['reply'][i] = replace_menu_names(review)"
      ],
      "metadata": {
        "id": "FyG6vOGWbnM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_rows = train[train['reply'].str.contains(\"<menu>\")]\n",
        "changed_rows"
      ],
      "metadata": {
        "id": "2Yms2284S4TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for menu in menu_name:\n",
        "    for i, review in enumerate(train['review']):\n",
        "        if menu in review:\n",
        "            train['review'][i] = replace_menu_names(review)"
      ],
      "metadata": {
        "id": "z9k-l8DIkLn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_rows = train[train['review'].str.contains(\"<menu>\")]\n",
        "changed_rows"
      ],
      "metadata": {
        "id": "rya7tSTpkLZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.replace(['<menu><menu>','<menu> <menu>'], '<menu>')"
      ],
      "metadata": {
        "id": "Cvmo-MDVpqBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 기타표현 처리\n",
        "\n",
        "- 영어, 오타, 띄어쓰기 청.춘.식.당 / 100g / 이벤트 / 24시간 / 장소 / 영업시간 등"
      ],
      "metadata": {
        "id": "9mJa0prEC386"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['reply'] = train['reply'].str.replace(r'[0-9ㄱ-ㅎ]|이벤트|24시간|영업시간', '', regex=True)\n",
        "train['review'] = train['review'].str.replace(r'[0-9ㄱ-ㅎ]|이벤트|24시간|영업시간', '', regex=True)\n"
      ],
      "metadata": {
        "id": "Zb1zMdTgC3CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['reply']"
      ],
      "metadata": {
        "id": "iejmhhkPlW7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 증강"
      ],
      "metadata": {
        "id": "55YyiX2oIl4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "minority_class = train[train['sentiment'] == '부정']\n"
      ],
      "metadata": {
        "id": "kjaq6CZtIk7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_neg = train['sentiment'] == '부정'\n",
        "train[mask_neg].shape[0]"
      ],
      "metadata": {
        "id": "IZ9SFg3yVRQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_pos = train['sentiment'] == '긍정'\n",
        "train[mask_pos].shape[0]"
      ],
      "metadata": {
        "id": "5HQsDhvaVUhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_food = pd.read_csv(f\"{DATA_PATH}playstore_food_reply_0904.csv\")"
      ],
      "metadata": {
        "id": "_w_6oihEVyBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_food"
      ],
      "metadata": {
        "id": "8WSjHaKgV16L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desired_samples = train[mask_pos].shape[0] - train[mask_neg].shape[0] #pos, neg개수 동일하게 하기 위해서\n",
        "oversampled_data = resample(minority_class, replace=True, n_samples=desired_samples, random_state=42)\n"
      ],
      "metadata": {
        "id": "zzXiFMBzIkx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_train = pd.concat([train,oversampled_data],axis=0)\n",
        "aug_train.shape"
      ],
      "metadata": {
        "id": "JOdJ6vAs4FMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "iTu6skOBSUzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ft = aug_train"
      ],
      "metadata": {
        "id": "SajXqS7w4FEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"skt/kogpt2-base-v2\"\n",
        "# model_name = \"EasthShin/Youth_Chatbot_Kogpt2-base\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "vWWnh_bMc1ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          bos_token='</s>',\n",
        "                                          eos_token='</s>',\n",
        "                                          unk_token='<unk>',\n",
        "                                          pad_token='<pad>',\n",
        "                                          mask_token='<mask>',\n",
        "                                          max_len=1024)\n",
        "\n",
        "tokenizer.eos_token_id # eos 토큰의 idx 반환"
      ],
      "metadata": {
        "id": "rWcW2urXc84r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(train['review'][0])"
      ],
      "metadata": {
        "id": "aWNVeb-XdDqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터셋 만들기"
      ],
      "metadata": {
        "id": "Toqr2vsIDuVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ft = train_ft[['review','reply']]"
      ],
      "metadata": {
        "id": "0nnzCztwFrOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.review = df[\"review\"].tolist()\n",
        "        self.reply = df[\"reply\"].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.review)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return \"<w>\" + \"</s><q>\" + self.review[idx] + \"</s><a>\" + self.reply[idx] + \"</s>\""
      ],
      "metadata": {
        "id": "yN8pqSqdgzqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    x = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
        "    return {\"x\":x}"
      ],
      "metadata": {
        "id": "BQlFZhQBcM2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dt = ChatDataset(train_ft)"
      ],
      "metadata": {
        "id": "a1kL3BK7FRZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = torch.utils.data.DataLoader(train_dt,batch_size=2,collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "Yrnf0uAxcNpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dl))\n",
        "batch"
      ],
      "metadata": {
        "id": "PbnQMfU9FWZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id # 패딩토큰인 3번 빼고 계산해야겠군"
      ],
      "metadata": {
        "id": "U4OUR5rScR3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습 loop함수화"
      ],
      "metadata": {
        "id": "hLnigTHADwSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader,model,optimizer,loss_fn,device):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        x = batch[\"x\"].to(device)\n",
        "        pred = model(**x).logits # batch, seq, 단어별 실수값\n",
        "        n_class = pred.shape[-1] # 클래스 개수\n",
        "        pred = pred[:,:-1] # eos 토큰 제외\n",
        "        pred = pred.reshape(-1,n_class) # 2차원 형태로 변환\n",
        "\n",
        "        tgt = x[\"input_ids\"][:,1:]\n",
        "        tgt = tgt.flatten() # 1차원 벡터 형태로 변환\n",
        "\n",
        "        mask = tgt != 3 # 패딩토큰인 3번 빼고 계산해야겠군\n",
        "        tgt = tgt[mask]\n",
        "        pred = pred[mask]\n",
        "        loss = loss_fn(pred,tgt)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(dataloader)\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "jEUl3slscTFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습하기"
      ],
      "metadata": {
        "id": "DNbhtNsScaUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "epochs = 10\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "kgf1EsI7cWou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ft['review'] = train_ft['review'].astype(str)\n",
        "train_ft['reply'] = train_ft['reply'].astype(str)\n",
        "# train_ft['store'] = train_ft['store'].astype(str)"
      ],
      "metadata": {
        "id": "HIub7KPEGdei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 총 5750개의 데이터 학습 (증강)"
      ],
      "metadata": {
        "id": "7Ht4IU6uiW45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_holdout = False\n",
        "reset_seeds(SEED)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=3e-5)\n",
        "\n",
        "train_dt = ChatDataset(train_ft)\n",
        "train_dl = torch.utils.data.DataLoader(train_dt,batch_size=batch_size,shuffle=True,collate_fn=collate_fn)\n",
        "\n",
        "for i in range(epochs):\n",
        "    train_loss = train_loop(train_dl, model, optimizer, loss_fn, device)\n",
        "    print(train_loss)\n",
        "\n",
        "    if is_holdout:\n",
        "        break\n",
        "\n",
        "\n",
        "# 0.18275894721305888"
      ],
      "metadata": {
        "id": "Imc1XsINcc-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 저장하기"
      ],
      "metadata": {
        "id": "gWkU514iDzfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(f\"{DATA_PATH}koGPT2_keybert_masktoken_0905_2\") #0"
      ],
      "metadata": {
        "id": "FNHNH5XNchFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t5iHSfQfMuky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 답변 생성"
      ],
      "metadata": {
        "id": "wbKS-xuTvUMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 맞춤법 처리"
      ],
      "metadata": {
        "id": "A8IUdaqqxYN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ssut/py-hanspell.git"
      ],
      "metadata": {
        "id": "3yxWjbA4wERP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd py-hanspell"
      ],
      "metadata": {
        "id": "ZQBY1FLewK-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py-hanspell/"
      ],
      "metadata": {
        "id": "F5Dw3Mr9xOOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hanspell import spell_checker\n",
        "\n",
        "# def correct_spell(text):\n",
        "#     if isinstance(text, str):  # 입력 데이터가 문자열인 경우에만 맞춤법 검사 수행\n",
        "#         corrected_text = spell_checker.check(text).checked\n",
        "#         return corrected_text\n",
        "#     else:\n",
        "#         return text"
      ],
      "metadata": {
        "id": "I5vN8IhaxSRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 불러오기"
      ],
      "metadata": {
        "id": "CAXSMPBlxV3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# model_name = 'MLOpsEngineer/review-rate-prediction'\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}ygy_cont3000_youth_ver1\")\n",
        "model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}koGPT2_keybert_masktoken_0905_2\")"
      ],
      "metadata": {
        "id": "IiB5eS7oYweH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"skt/kogpt2-base-v2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, #해당 모델의 토크나이저\n",
        "                                          bos_token='</s>',\n",
        "                                          eos_token='</s>',\n",
        "                                          unk_token='<unk>',\n",
        "                                          pad_token='<pad>',\n",
        "                                          mask_token='<mask>',\n",
        "                                          max_len=1024,\n",
        "                                          padding_side='left')"
      ],
      "metadata": {
        "id": "mD19Lbf-yw3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_spell(text):\n",
        "    if isinstance(text, str):  # 입력 데이터가 문자열인 경우에만 맞춤법 검사 수행\n",
        "        corrected_text = spell_checker.check(text).checked\n",
        "        return corrected_text\n",
        "    else:\n",
        "        return text"
      ],
      "metadata": {
        "id": "kYOxa1SBHiyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @torch.no_grad()\n",
        "# def chatbot(model,tokenizer,max_len,device):\n",
        "#     model.eval()\n",
        "#     while True:\n",
        "#         text = input(\"소비자 > \").strip()\n",
        "#         if text == \"quit\":\n",
        "#             break\n",
        "#         text = \"<q>\" + text + \"</s><a>\"\n",
        "#         x = tokenizer.encode(text,return_tensors=\"pt\").to(device) # batch, seq\n",
        "\n",
        "#         result_ids = model.generate(x,\n",
        "#                             max_length=max_len,\n",
        "#                             repetition_penalty=2.0,\n",
        "#                             use_cache=True,\n",
        "#                             do_sample=True, # 확률적 샘플링 여부(False = greedy 방식)\n",
        "#                             temperature=0.2, # 소프트맥스 온도(확률적 샘플링일 때만 작동)\n",
        "#                             top_k=5) # 상위 확률 k개 기준으로 확률적 샘플링 하겠다(확률적 샘플링일 때만 작동)\n",
        "#         q_len = len(text) + 1\n",
        "#         text = tokenizer.decode(result_ids[0])\n",
        "\n",
        "#         from hanspell import spell_checker\n",
        "\n",
        "#         text = correct_spell(text)\n",
        "\n",
        "#         # if len(text) > max_len:\n",
        "#         #     text = text[:max_len]\n",
        "\n",
        "#         print(\"사장님 > \",text[q_len:-4])"
      ],
      "metadata": {
        "id": "UkaA6iybdsX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# chatbot 함수 정의\n",
        "def chatbot(model, tokenizer, max_len, review_list, store, menu, region):\n",
        "    responses = []  # 결과를 저장할 리스트 초기화\n",
        "\n",
        "    for review in tqdm(review_list):\n",
        "\n",
        "        review = review.replace('<store>',store)\n",
        "        review = review.replace('<menu>',menu)\n",
        "        review = review.replace('<region>',region)\n",
        "\n",
        "\n",
        "        # 대화 시작 및 종료 토큰 추가\n",
        "        text = \"<q>\" + review + \"</s><a>\"\n",
        "\n",
        "        # 입력 텍스트를 인코딩\n",
        "        x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "        # max_len = 10000, max_length=max_len\n",
        "\n",
        "        # 모델로부터 응답 생성\n",
        "        result_ids = model.generate(x,\n",
        "                                    max_length=max_len,\n",
        "                                    num_return_sequences=1,\n",
        "                                    repetition_penalty=0.9, # 1보다 낮으면 반복 허용, 1보다 클수록 창의적\n",
        "                                    use_cache=True,\n",
        "                                    do_sample=True, # 확률적 샘플링 여부(False = greedy 방식)\n",
        "                                    temperature=1, # softmax. 1보다 낮으면 결정적, 1보다 클수록 창의적\n",
        "                                    top_k=5) # 상위 확률 k개 기준으로 확률적 샘플링 하겠다(확률적 샘플링일 때만 작동)\n",
        "\n",
        "\n",
        "        # 응답을 텍스트로 디코딩하여 저장\n",
        "        response = tokenizer.decode(result_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        response = response.replace('<store>',store)\n",
        "        response = response.replace('<menu>',menu)\n",
        "        response = response.replace('<region>',region)\n",
        "\n",
        "        response = response.split(\"<a>\", 1)[1]\n",
        "        response = correct_spell(response)\n",
        "        responses.append(response)\n",
        "\n",
        "    # 결과를 데이터프레임으로 변환\n",
        "    result_df = pd.DataFrame({\"Review\": review_list, \"Response\": responses})\n",
        "    return result_df\n"
      ],
      "metadata": {
        "id": "htUDb2HX5GS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_list = [\n",
        "\n",
        "    '맛이 있어요',\n",
        "    '최고에요',\n",
        "    '사장님이 친절하시네요',\n",
        "    '맛은 있는데 배달이 식어서 왔어요ㅠㅠ',\n",
        "    '맛이 없어요',\n",
        "    '이 머리카락 들어있는거 뭔가요?',\n",
        "    '배달이 너무 불친절해요',\n",
        "    '최악이에요'\n",
        "\n",
        "]\n",
        "\n",
        "# chatbot 실행 및 결과 출력\n",
        "result_df = chatbot(model, tokenizer, 512, review_list,'최가네','덮밥','서초점')\n",
        "\n",
        "pd.DataFrame(result_df)"
      ],
      "metadata": {
        "id": "fE8LRS_l5TT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_list = [\n",
        "\n",
        "    '맛이 있어요',\n",
        "    '최고에요',\n",
        "    '사장님이 친절하시네요',\n",
        "    '맛은 있는데 배달이 식어서 왔어요ㅠㅠ',\n",
        "    '맛이 없어요',\n",
        "    '이 머리카락 들어있는거 뭔가요?',\n",
        "    '배달이 너무 불친절해요',\n",
        "    '최악이에요'\n",
        "\n",
        "]\n",
        "\n",
        "# chatbot 실행 및 결과 출력\n",
        "result_df = chatbot(model, tokenizer, 512, review_list,'비비큐','치킨','양재점')\n",
        "\n",
        "pd.DataFrame(result_df)"
      ],
      "metadata": {
        "id": "CHUBdkgw8GB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ft.shape # 2800-900개"
      ],
      "metadata": {
        "id": "rUQF1lq5-m49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv(f'{DATA_PATH}[response]koGPT2_keybert_masktoken_0905_2a.csv',index=False)"
      ],
      "metadata": {
        "id": "FK1w1Bf06z8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_list = [\n",
        "    # 특정 메뉴명 포함 (맛)\n",
        "    '이집 피자 최애 넘나 맛있어요',\n",
        "    '치킨이 바삭바삭하니 맛있네요',\n",
        "    '마라샹궈 넘넘 맛있고 양도 푸짐해용! 감사합니다!',\n",
        "    '간만에 술한잔생각나서 연어 주문해서 먹는데 맛있네요^^ 양이 좀적어진거같은데 다음에는 추가로 시켜야 겠어요^^ 잘먹었습니당^^',\n",
        "    '짜장면 배달이 너무 느리게 와서 음식이 다 불었네요..사장님 신경좀 써주세요',\n",
        "    '쌀국수 먹는데 비닐 나왔네요 반품 이런건 안하지만 청결에 신경 써주세요',\n",
        "    '요기 김치찜 맛있는데 가끔 좀 짜요ㅠㅠ다음엔 육수 추가로 주심 좋겠어요',\n",
        "\n",
        "    # 메뉴의 특성 포함 (맛)\n",
        "    '닭도 쫄깃하니 맛있고 떡볶이도 맛나요👍',\n",
        "    '오늘은 비계가 많은거 같아요.. 양이 상대적으로 적어서 아쉬웠어요.',\n",
        "    '크림이 너무 부드럽고 맛있어요, 또 시켜먹을게요!!',\n",
        "    '맛있게 먹었어요 4단계로 해도 맵지는 않아요',\n",
        "\n",
        "\n",
        "    # 배달 및 기타 코멘트\n",
        "    '배달 빠르게 와서 맛있게 먹었습니다!',\n",
        "    '완전 만족했어요 전문 블로거인데요 양쪼끔만 더 많았으면! 종종 시켜먹을게요',\n",
        "    '맛은 정말 좋았지만, 편의점가려다 배달 도착한걸 발견 못해다면 다 상한 음식 먹을뻔했네요. 노크도 없고 문자도 안주시면 음식이 온지 어떻게 알으라는건지....',\n",
        "    '.................',\n",
        "    '벌레 나왔어요.. 다신 안시켜먹을 것 같아요',\n",
        "]\n",
        "\n",
        "result_df = chatbot(model, tokenizer, 1024, review_list,'비비큐','치킨','서초점')\n",
        "\n",
        "pd.DataFrame(result_df)"
      ],
      "metadata": {
        "id": "AGReONUi5mVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chatbot(model,tokenizer,128,device) # quit"
      ],
      "metadata": {
        "id": "wH1ZSx9cdvTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv(f'{DATA_PATH}[response]koGPT2_keybert_masktoken_0905_2b.csv',index=False)"
      ],
      "metadata": {
        "id": "TahQdzmFqWNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------참고. 리뷰 키워드 사전학습모델"
      ],
      "metadata": {
        "id": "HFKZMGG_5-tJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Keybert로 키워드 추출"
      ],
      "metadata": {
        "id": "FTdBS4_D7lHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keybert"
      ],
      "metadata": {
        "id": "ghOlUZAI7ovR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) skt/kobert-base-v1"
      ],
      "metadata": {
        "id": "WdLr210D8Jjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keybert import KeyBERT\n",
        "# # from transformers import XLNetTokenizer, BertTokenizer, BertModel\n",
        "# from tqdm import tqdm  # tqdm 추가\n",
        "# from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "# # keybert에 사용할 Kobert 모델 로드\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n",
        "# model = AutoModel.from_pretrained(\"skt/kobert-base-v1\")\n",
        "\n",
        "# # KeyBERT 모델 초기화\n",
        "# keybert_model = KeyBERT(model=model)\n",
        "\n",
        "# # 리뷰 데이터 (train['review']로 가정)\n",
        "# reviews = train['review'][:50]  # train['review']에 리뷰 데이터를 넣으세요\n",
        "# keywords_list = []\n",
        "\n",
        "# # tqdm을 사용하여 진행 상황 표시\n",
        "# for text in tqdm(reviews):\n",
        "#     keywords = keybert_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=10)\n",
        "#     keywords_list.append(keywords)\n",
        "\n",
        "# # # 결과 출력\n",
        "# # for idx, keywords in enumerate(keywords_list):\n",
        "# #     print(f\"Review {idx + 1} Keywords:\", keywords)\n",
        "\n",
        "# result_df = pd.DataFrame({'Review': reviews, 'Keywords': keywords_list})\n",
        "# result_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RlaUfu3-7oo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) BM-K/KoSimCSE-roberta"
      ],
      "metadata": {
        "id": "8QQSAq149Iok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from keybert import KeyBERT\n",
        "# from tqdm import tqdm\n",
        "# # from transformers import BertTokenizer, RobertaTokenizer, RobertaModel\n",
        "# from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "\n",
        "# # BM-K/KoSimCSE-roberta 모델 로드\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"BM-K/KoSimCSE-roberta\")\n",
        "# model = AutoModel.from_pretrained(\"BM-K/KoSimCSE-roberta\")\n",
        "\n",
        "# # KeyBERT 모델 초기화\n",
        "# keybert_model = KeyBERT(model=model)\n",
        "\n",
        "# # 리뷰 데이터 (train['review']로 가정)\n",
        "# reviews = train['review'][:50]  # train['review']에 리뷰 데이터를 넣으세요\n",
        "# keywords_list = []\n",
        "\n",
        "# # tqdm을 사용하여 진행 상황 표시\n",
        "# for text in tqdm(reviews):\n",
        "#     keywords = keybert_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=5)\n",
        "#     keywords_list.append(keywords)\n",
        "\n",
        "# # 데이터 프레임으로 변환\n",
        "# result_df = pd.DataFrame({'Review': reviews, 'Keywords': keywords_list})\n",
        "# result_df\n"
      ],
      "metadata": {
        "id": "vhDeLY917oeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) distilbert-base-nli-mean-tokens\n",
        "- 이 모델이 Keybert의 디폴트 모델인거 같음"
      ],
      "metadata": {
        "id": "4JOVEfOF9iOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keybert import KeyBERT\n",
        "# from tqdm import tqdm\n",
        "\n",
        "\n",
        "# # KeyBERT 모델 초기화 (distilbert-base-nli-mean-tokens 사용)\n",
        "# keybert_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "# # 리뷰 데이터 (train['review']로 가정)\n",
        "# reviews = train['review'][:50]  # train['review']에 리뷰 데이터를 넣으세요\n",
        "# keywords_list = []\n",
        "\n",
        "# # tqdm을 사용하여 진행 상황 표시\n",
        "# for text in tqdm(reviews):\n",
        "#     keywords = keybert_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=5)\n",
        "#     keywords_list.append(keywords)\n",
        "\n",
        "# # 결과 출력\n",
        "# result_df = pd.DataFrame({'Review': reviews, 'Keywords': keywords_list})\n",
        "# result_df\n"
      ],
      "metadata": {
        "id": "-6Swi1Pw7oXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) monologg/kobert"
      ],
      "metadata": {
        "id": "moiSCyMpBzub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from keybert import KeyBERT\n",
        "# from tqdm import tqdm\n",
        "# # from transformers import BertTokenizer, RobertaTokenizer, RobertaModel\n",
        "# from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "\n",
        "# # BM-K/KoSimCSE-roberta 모델 로드\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
        "# model = AutoModel.from_pretrained(\"monologg/kobert\")\n",
        "\n",
        "# # KeyBERT 모델 초기화\n",
        "# keybert_model = KeyBERT(model=model)\n",
        "\n",
        "# # 리뷰 데이터 (train['review']로 가정)\n",
        "# reviews = train['review'][:50]  # train['review']에 리뷰 데이터를 넣으세요\n",
        "# keywords_list = []\n",
        "\n",
        "# # tqdm을 사용하여 진행 상황 표시\n",
        "# for text in tqdm(reviews):\n",
        "#     keywords = keybert_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=10)\n",
        "#     keywords_list.append(keywords)\n",
        "\n",
        "# # 데이터 프레임으로 변환\n",
        "# result_df = pd.DataFrame({'Review': reviews, 'Keywords': keywords_list})\n",
        "# result_df\n",
        "\n"
      ],
      "metadata": {
        "id": "jVFCkRt76Egw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. 키위로 키워드 추출"
      ],
      "metadata": {
        "id": "MwJ8WHGpC5aW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t8lP-OWdOTmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sNRR8kikZU9e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xLHJ8Xm84EiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_27JVVY4EaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXF8KF7G4ESt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cG6xrDZl4ELS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDmJU9Hk4EEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mBEfUG3l4D62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sI3CDsUh4Dun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D2gNDO9M4Dm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2soDfRQ4DeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o1XjTuK24DVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZFGUgW534aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocX4qK_B4DKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JazX4td34C6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbXgY2hLJQGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z6LcjHu8ZkPa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}