{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzv8gfSuyjfcsE1rxJgZBD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swoo-nam/project_final_team1/blob/main/%EC%9D%B4%EC%9A%A9%EB%AF%BC_%EC%9D%B4%EC%86%8C%ED%98%84_Streamlit_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYmsmShTIc0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1rK4_sDAYGxG",
        "outputId": "451d95fd-608b-483b-c51a-1add1056812e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def reset_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "SEED = 42\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n",
        "\n",
        "# df = pd.read_csv(f\"{DATA_PATH}yogiyo_reviews_0905_clean.csv\")\n",
        "# df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtfVkODe5yFb",
        "outputId": "14393bb3-0b22-434f-8521-b21e47804d98"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20200506-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kExxxHu5YI4_",
        "outputId": "df9c1b1b-c3ea-416b-f305-2a9ba848e0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMiWe8MfaXcK"
      },
      "source": [
        "# 제로샷 \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\" 토크나이저 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVI0xts-Ya7l",
        "outputId": "c14aab9a-6938-4035-9d4d-ac62a8d98b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "# 토크나이저 초기화\n",
        "model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=tokenizer, device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqu60Qa5bB2y"
      },
      "source": [
        "# fine-tuning한 제로샷 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "dpBulX8RYkeL"
      },
      "outputs": [],
      "source": [
        "model_zeroshot = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/프로젝트/final project/data/42000_5라벨_3\").to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "7FPurwQ--ux6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "hhalYGl-JG5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b2782e-9a10-438a-b24c-a7d98c9d0f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.27.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.5.3)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.37)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "2t9KLOrWJCry"
      },
      "outputs": [],
      "source": [
        "model_name = \"skt/kogpt2-base-v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "ZfmnJIx6JIhh"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "Leaqh2X6JL1M"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          bos_token='</s>',\n",
        "                                          eos_token='</s>',\n",
        "                                          unk_token='<unk>',\n",
        "                                          pad_token='<pad>',\n",
        "                                          mask_token='<mask>',\n",
        "                                          max_len=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "MZ7EMG5xMtvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09e44eb-df12-4559-b550-ca561e24be20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/프로젝트/final project/data/tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/vocab.json',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/merges.txt',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/added_tokens.json',\n",
              " '/content/drive/MyDrive/프로젝트/final project/data/tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "tokenizer.save_pretrained(f'{DATA_PATH}tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "boUvQqzpJCCm"
      },
      "outputs": [],
      "source": [
        "loaded_model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "p5iUzcPiSJfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40d58c5-54ca-48a3-d6dd-60e1339283f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.34.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (17.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "XYNce24Bb-2X"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "opTB8HZirVwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c29ef13-87c0-43e4-9c65-1b2d033971b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit-option-menu in /usr/local/lib/python3.10/dist-packages (0.3.6)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit-option-menu) (1.27.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (13.5.3)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (5.0.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (3.1.37)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-option-menu) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-option-menu) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit-option-menu) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-option-menu) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit-option-menu) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-option-menu) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-option-menu) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-option-menu) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-option-menu) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-option-menu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-option-menu) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-option-menu) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-option-menu) (0.10.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-option-menu) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit-option-menu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "WYXbmstnmEHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8949838-b476-48c2-eb14-faad50ba1170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)  # 변수명을 new_tokenizer로 변경\n",
        "classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "# import matplotlib.pyplot as plt\n",
        "# import streamlit as st\n",
        "# from streamlit_option_menu import option_menu\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import re\n",
        "# import time\n",
        "# from PIL import Image\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# from sklearn.metrics.pairwise import pairwise_distances\n",
        "# from sklearn.metrics import jaccard_score\n",
        "# import seaborn as sns\n",
        "# from scipy.interpolate import make_interp_spline\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "# bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "# model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# # 유사도 평가 함수\n",
        "# def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "#     input_embedding = bert_model.encode(input_text)\n",
        "#     generated_embedding = bert_model.encode(generated_text)\n",
        "\n",
        "#     # 코사인 유사도\n",
        "#     cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "\n",
        "#     # 자카드 유사도\n",
        "#     input_tokens = set(input_text.split())\n",
        "#     generated_tokens = set(generated_text.split())\n",
        "#     jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "#     # jaccard_sim = jaccard_score(input_tokens, generated_tokens)\n",
        "\n",
        "#     # 가중 평균 내보기\n",
        "#     weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "\n",
        "#     return weighted_sim\n",
        "\n",
        "# # 모델 로드\n",
        "# def loaded_model(DATA_PATH):\n",
        "#     model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_33_loss_0.2015\", local_files_only=True)\n",
        "#     return model\n",
        "\n",
        "# def load_zero_model(DATA_PATH):\n",
        "#     model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "#     return model_zeroshot\n",
        "\n",
        "# def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "#     new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "#     return new_tokenizer\n",
        "\n",
        "\n",
        "# def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "#     classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "#     return classifier\n",
        "\n",
        "# # 토크나이저 로드\n",
        "# def loaded_tokenizer(DATA_PATH):\n",
        "#     model_name = \"skt/kogpt2-base-v2\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "#                                           bos_token='</s>',\n",
        "#                                           eos_token='</s>',\n",
        "#                                           unk_token='<unk>',\n",
        "#                                           pad_token='<pad>',\n",
        "#                                           mask_token='<mask>',\n",
        "#                                           max_len=1024)\n",
        "#     return tokenizer\n",
        "\n",
        "# # 답변 생성 함수\n",
        "# def generate_response(model, tokenizer, input_text, num_samples):\n",
        "#     text = \"<q>\" + input_text + \"</s><a>\"\n",
        "#     x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "#     q_len = len(text) + 1\n",
        "\n",
        "#     best_generated_text = None\n",
        "#     best_similarity_score = -1.0\n",
        "#     generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "#     for i in range(num_samples):\n",
        "#         result_ids = model.generate(x,\n",
        "#                                         max_length=max_len,\n",
        "#                                         repetition_penalty=2.0,\n",
        "#                                         num_beams=1,\n",
        "#                                         num_return_sequences=1,\n",
        "#                                         no_repeat_ngram_size=4,\n",
        "#                                         use_cache=True,\n",
        "#                                         do_sample=True,\n",
        "#                                         temperature=0.8,\n",
        "#                                         top_k=90,\n",
        "#                                         top_p=0.95,\n",
        "#                                         early_stopping=True\n",
        "#                                         )\n",
        "\n",
        "\n",
        "#         generated_text = tokenizer.decode(result_ids[0])\n",
        "#         generated_text = generated_text[q_len:-4]\n",
        "#         generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "\n",
        "#         similarity_score = evaluate_similarity(text, generated_text)\n",
        "#         generated_texts.append((similarity_score,generated_text))\n",
        "#         print(generated_texts[i])\n",
        "\n",
        "#         if similarity_score > best_similarity_score:\n",
        "#             best_similarity_score = similarity_score\n",
        "#             best_generated_text = generated_text\n",
        "\n",
        "#     print(\"Best_similarity_score:\", best_similarity_score)\n",
        "\n",
        "#     return best_generated_text\n",
        "\n",
        "# # 그래프\n",
        "# def plot_review_analysis(merged_df, merged_df_3y):\n",
        "#     # 2개월 그래프\n",
        "#     fig1, ax1 = plt.subplots(figsize=(10, 4))\n",
        "#     sns.set(style=\"whitegrid\")\n",
        "#     sns.lineplot(data=merged_df, x='date', y='pos_7D_score', label='긍정 지수', marker='o', linestyle='-', color='b')\n",
        "#     sns.lineplot(data=merged_df, x='date', y='neg_7D_score', label='부정 지수', marker='s', linestyle='--', color='r')\n",
        "#     plt.title('긍부정 지수 변화 (2개월)')\n",
        "#     plt.xlabel('일자')\n",
        "#     plt.ylabel('리뷰 긍부정 지수')\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig1)\n",
        "\n",
        "#     st.markdown(\"---\")\n",
        "\n",
        "#     # 3개년 그래프 보간 부분\n",
        "#     x = merged_df_3y['DATE']\n",
        "#     y_pos = merged_df_3y['pos_7D_score']\n",
        "#     y_neg = merged_df_3y['neg_7D_score']\n",
        "\n",
        "#     mask = ~np.isnan(y_pos) & ~np.isnan(y_neg) & ~np.isinf(y_pos) & ~np.isinf(y_neg)\n",
        "#     x = x[mask]\n",
        "#     y_pos = y_pos[mask]\n",
        "#     y_neg = y_neg[mask]\n",
        "\n",
        "#     x_numeric = pd.to_datetime(x).astype(int)\n",
        "\n",
        "#     spline_pos = make_interp_spline(x_numeric, y_pos, k=3)\n",
        "#     spline_neg = make_interp_spline(x_numeric, y_neg, k=3)\n",
        "#     x_new = np.linspace(x_numeric.min(), x_numeric.max(), 300)\n",
        "#     y_pos_smooth = spline_pos(x_new)\n",
        "#     y_neg_smooth = spline_neg(x_new)\n",
        "\n",
        "#     fig2, ax2 = plt.subplots(figsize=(12, 6))\n",
        "#     plt.plot(pd.to_datetime(x_new), y_pos_smooth, label='긍정 지수', color='b')\n",
        "#     plt.plot(pd.to_datetime(x_new), y_neg_smooth, label='부정 지수', color='r')\n",
        "#     plt.title('긍부정 지수 변화 (3개년)')\n",
        "#     plt.xlabel('일자')\n",
        "#     plt.ylabel('리뷰 긍부정 지수')\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig2)\n",
        "\n",
        "\n",
        "# def plot_temperature_analysis(df2, input_id):\n",
        "#     review_count = len(df2[df2['ID'] == input_id])\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     if not id_df.empty:\n",
        "#         # 평균 점수 계산\n",
        "#         mean_score = id_df['NEW_SCORE'].mean()\n",
        "\n",
        "#         # 스케일링 함수 정의\n",
        "#         def scale_temperature(score):\n",
        "#             base_temp = 36.5\n",
        "#             ratio = 30\n",
        "#             scaled_temp = base_temp + (score * ratio)\n",
        "#             return scaled_temp\n",
        "\n",
        "#         # 스케일링된 온도값 계산\n",
        "#         scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "\n",
        "#         # 평균 온도 계산\n",
        "#         mean_temperature = scaled_scores.mean()\n",
        "\n",
        "#         # 그래프 선의 색깔을 조건에 따라 지정\n",
        "#         line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "#         line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "#         ax.set_xlabel('일자')\n",
        "#         ax.set_ylabel('온도 (°C)')\n",
        "#         ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "#         plt.xticks(id_df['DATE'], rotation=45)\n",
        "#         plt.tight_layout()\n",
        "#         plt.ylim(0, 70)\n",
        "#         y_ticks = np.arange(0, 71, 10)\n",
        "#         plt.yticks(y_ticks)\n",
        "#         plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "#         ax.legend()\n",
        "#         st.pyplot(fig)\n",
        "\n",
        "#         st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "#         st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "#         st.write(f'리뷰 횟수: {review_count}')\n",
        "#     else:\n",
        "#         st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def main():\n",
        "#     # 이미지 추가\n",
        "#     url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "#     st.image(url)\n",
        "\n",
        "#     DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "#     # 사이드바(옵션)\n",
        "#     with st.sidebar:\n",
        "#         choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\", \"기타\"],\n",
        "#                              icons=['house', 'kanban', 'bi bi-robot'],\n",
        "#                              menu_icon=\"app-indicator\", default_index=0,\n",
        "#                              styles={\n",
        "#                                  \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "#                                  \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "#                                  \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "#                                  \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "#                              }\n",
        "#         )\n",
        "\n",
        "#     # 사장님 답글 페이지\n",
        "#     if choice == \"사장님 답글 남기기\":\n",
        "\n",
        "#         candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "\n",
        "#         st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "#         user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "#         submit_button = st.button(\"Submit\")\n",
        "\n",
        "#         if submit_button:\n",
        "#             if user_input:\n",
        "#                 model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "#                 model_zeroshot = load_zero_model(DATA_PATH)\n",
        "#                 new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "#                 classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "\n",
        "#                 # 모델 1 예측\n",
        "#                 inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "#                 input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "#                 with torch.no_grad():\n",
        "#                     outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#                     logits = outputs.logits\n",
        "#                     probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "#                 scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "\n",
        "#                 # 모델 2 예측\n",
        "#                 output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "#                 scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "#                 # 두 모델의 점수 평균내기\n",
        "#                 new_labels = []\n",
        "#                 new_scores = {}\n",
        "#                 service_scores = []\n",
        "\n",
        "#                 for label in scores_from_model1.keys():\n",
        "#                     averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "\n",
        "#                     if label == '맛':\n",
        "#                         new_scores['Quality'] = averaged_score\n",
        "#                         if averaged_score >= 0.35:\n",
        "#                             new_labels.append('quality')\n",
        "\n",
        "#                     elif label == '양':\n",
        "#                         new_scores['Quantity'] = averaged_score\n",
        "#                         if averaged_score >= 0.35:\n",
        "#                             new_labels.append('quantity')\n",
        "\n",
        "#                     elif label in ['서비스', '배달', '가격']:\n",
        "#                         service_scores.append(averaged_score)\n",
        "\n",
        "#                 if service_scores:\n",
        "#                     avg_service_score = sum(service_scores) / len(service_scores)\n",
        "#                     new_scores['Service'] = avg_service_score\n",
        "#                     if avg_service_score >= 0.35:\n",
        "#                         new_labels.append('service')\n",
        "\n",
        "#                 new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "#                 new_predicted_labels = \", \".join(new_labels)\n",
        "\n",
        "#                 st.write(f\"Label Scores: {new_label_scores}\")\n",
        "#                 st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "\n",
        "#                 # 답변 생성 부분\n",
        "#                 model = loaded_model(DATA_PATH)\n",
        "#                 tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "\n",
        "#                 with st.spinner(\"답변 생성 중입니다...\"):\n",
        "#                     reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "#                 st.success(\"완료!\")\n",
        "#                 st.write(\"답글을 추천해 드려요. : \")\n",
        "#                 st.write(reply)\n",
        "#             else:\n",
        "#                 st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     # 리뷰 분석 페이지\n",
        "#     elif choice == \"리뷰 분석\":\n",
        "#         analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "#         if analysis_choice == \"부정 리뷰 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "#             # 부정 리뷰 분석 코드\n",
        "#             neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "#             pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "#             plt.rcParams.update(plt.rcParamsDefault)\n",
        "#             plt.rc('font', family='NanumBarunGothic')\n",
        "#             fig, ax = plt.subplots(figsize=(6, 6))\n",
        "#             short_label_counts = neg_short_result['label'].value_counts()\n",
        "#             ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "#             plt.title('리뷰 현황')\n",
        "#             st.pyplot(fig)\n",
        "\n",
        "#         elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "#             # 긍/부 지수의 변화 추이 코드\n",
        "#             merged_df = pd.read_csv(f'{DATA_PATH}merged_df_2months.csv')\n",
        "#             merged_df_3y = pd.read_csv(f'{DATA_PATH}merged_df_3years.csv')\n",
        "#             merged_df_3y = merged_df_3y.dropna()\n",
        "#             plot_review_analysis(merged_df, merged_df_3y)\n",
        "#             st.markdown(\"---\")\n",
        "\n",
        "#         elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "#             df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "#             df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "\n",
        "#             input_id = st.text_input(\"고객 ID 입력: \")\n",
        "#             plot_temperature_analysis(df2, input_id)\n",
        "\n",
        "#         elif choice == \"기타\":\n",
        "#             pass\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWfA5X5NNdQ8",
        "outputId": "92707f2f-8910-4c57-ada7-01bc858f5082"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import seaborn as sns\n",
        "from scipy.interpolate import make_interp_spline\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# 유사도 평가 함수\n",
        "def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "    input_embedding = bert_model.encode(input_text)\n",
        "    generated_embedding = bert_model.encode(generated_text)\n",
        "    cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "    input_tokens = set(input_text.split())\n",
        "    generated_tokens = set(generated_text.split())\n",
        "    jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "    weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "    return weighted_sim\n",
        "\n",
        "# 모델 로드\n",
        "def loaded_model(DATA_PATH):\n",
        "    model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "    return model\n",
        "\n",
        "def load_zero_model(DATA_PATH):\n",
        "    model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "    return model_zeroshot\n",
        "\n",
        "def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "    new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "    return new_tokenizer\n",
        "\n",
        "def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "    classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "    return classifier\n",
        "\n",
        "# 토크나이저 로드\n",
        "def loaded_tokenizer(DATA_PATH):\n",
        "    model_name = \"skt/kogpt2-base-v2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          bos_token='</s>',\n",
        "                                          eos_token='</s>',\n",
        "                                          unk_token='<unk>',\n",
        "                                          pad_token='<pad>',\n",
        "                                          mask_token='<mask>',\n",
        "                                          max_len=1024)\n",
        "    return tokenizer\n",
        "\n",
        "# 답변 생성 함수\n",
        "def generate_response(model, tokenizer, input_text, num_samples):\n",
        "    text = \"<q>\" + input_text + \"</s><a>\"\n",
        "    x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    q_len = len(text) + 1\n",
        "\n",
        "    best_generated_text = None\n",
        "    best_similarity_score = -1.0\n",
        "    generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "    for i in range(num_samples):\n",
        "        result_ids = model.generate(x,\n",
        "                                        max_length=1024,\n",
        "                                        repetition_penalty=2.0,\n",
        "                                        num_beams=1,\n",
        "                                        num_return_sequences=1,\n",
        "                                        no_repeat_ngram_size=4,\n",
        "                                        use_cache=True,\n",
        "                                        do_sample=True,\n",
        "                                        temperature=0.8,\n",
        "                                        top_k=90,\n",
        "                                        top_p=0.95,\n",
        "                                        early_stopping=True\n",
        "                                        )\n",
        "        generated_text = tokenizer.decode(result_ids[0])\n",
        "        generated_text = generated_text[q_len:-4]\n",
        "        generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "        similarity_score = evaluate_similarity(text, generated_text)\n",
        "        generated_texts.append((similarity_score,generated_text))\n",
        "        print(generated_texts[i])\n",
        "        if similarity_score > best_similarity_score:\n",
        "            best_similarity_score = similarity_score\n",
        "            best_generated_text = generated_text\n",
        "    print(\"Best_similarity_score:\", best_similarity_score)\n",
        "    return best_generated_text\n",
        "\n",
        "# 그래프\n",
        "\n",
        "def plot_review_analysis(merged_df, merged_df_3y):\n",
        "    fig1, ax1 = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "    plt.rcParams.update(plt.rcParamsDefault)\n",
        "    plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "    # 그래프 그리기\n",
        "    sns.lineplot(data=merged_df, x='date', y='pos_7D_score', ax=ax1, label='긍정 지수', marker='o', linestyle='-', color='b')\n",
        "    sns.lineplot(data=merged_df, x='date', y='neg_7D_score', ax=ax1, label='부정 지수', marker='s', linestyle='--', color='r')\n",
        "\n",
        "    # 그래프 설정\n",
        "    ax1.set_title('긍부정 지수 변화 (2개월)', fontsize=14)\n",
        "    ax1.set_xlabel('일자', fontsize=12)\n",
        "    ax1.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "    ax1.legend(fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    x = merged_df_3y['DATE']\n",
        "    y_pos = merged_df_3y['pos_7D_score']\n",
        "    y_neg = merged_df_3y['neg_7D_score']\n",
        "\n",
        "    mask = ~np.isnan(y_pos) & ~np.isnan(y_neg) & ~np.isinf(y_pos) & ~np.isinf(y_neg)\n",
        "    x = x[mask]\n",
        "    y_pos = y_pos[mask]\n",
        "    y_neg = y_neg[mask]\n",
        "\n",
        "    x_numeric = pd.to_datetime(x).astype(int)\n",
        "\n",
        "    spline_pos = make_interp_spline(x_numeric, y_pos, k=3)\n",
        "    spline_neg = make_interp_spline(x_numeric, y_neg, k=3)\n",
        "    x_new = np.linspace(x_numeric.min(), x_numeric.max(), 300)\n",
        "    y_pos_smooth = spline_pos(x_new)\n",
        "    y_neg_smooth = spline_neg(x_new)\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 4))\n",
        "    ax2.plot(pd.to_datetime(x_new), y_pos_smooth, label='긍정 지수', color='b')\n",
        "    ax2.plot(pd.to_datetime(x_new), y_neg_smooth, label='부정 지수', color='r')\n",
        "    ax2.set_title('긍부정 지수 변화 (3개년)', fontsize=14)\n",
        "    ax2.set_xlabel('일자', fontsize=12)\n",
        "    ax2.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "    ax2.legend()\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "\n",
        "def plot_temperature_analysis(df2, input_id):\n",
        "    review_count = len(df2[df2['ID'] == input_id])\n",
        "    id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "    if not id_df.empty:\n",
        "        mean_score = id_df['NEW_SCORE'].mean()\n",
        "        def scale_temperature(score):\n",
        "            base_temp = 36.5\n",
        "            ratio = 30\n",
        "            scaled_temp = base_temp + (score * ratio)\n",
        "            return scaled_temp\n",
        "        scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "        mean_temperature = scaled_scores.mean()\n",
        "        line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "        line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "        ax.set_xlabel('일자')\n",
        "        ax.set_ylabel('온도 (°C)')\n",
        "        ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "        plt.xticks(id_df['DATE'], rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.ylim(0, 70)\n",
        "        y_ticks = np.arange(0, 71, 10)\n",
        "        plt.yticks(y_ticks)\n",
        "        plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "        ax.legend()\n",
        "        st.pyplot(fig)\n",
        "        st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "        st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "        st.write(f'리뷰 횟수: {review_count}')\n",
        "    else:\n",
        "        st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "def main():\n",
        "    url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "    st.image(url)\n",
        "\n",
        "    DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "    with st.sidebar:\n",
        "        choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\"],\n",
        "                             icons=['house', 'kanban', 'bi bi-robot'],\n",
        "                             menu_icon=\"app-indicator\", default_index=0,\n",
        "                             styles={\n",
        "                                 \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "                                 \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "                                 \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "                                 \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "                             }\n",
        "        )\n",
        "\n",
        "    if choice == \"사장님 답글 남기기\":\n",
        "        candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "        st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "        user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "        submit_button = st.button(\"Submit\")\n",
        "\n",
        "        if submit_button:\n",
        "            if user_input:\n",
        "                model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "                model_zeroshot = load_zero_model(DATA_PATH)\n",
        "                new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "                classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "                inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "                input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "                with torch.no_grad():\n",
        "                    outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "                scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "                output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "                scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "                new_labels = []\n",
        "                new_scores = {}\n",
        "                service_scores = []\n",
        "                for label in scores_from_model1.keys():\n",
        "                    averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "                    if label == '맛':\n",
        "                        new_scores['Quality'] = averaged_score\n",
        "                        if averaged_score >= 0.35:\n",
        "                            new_labels.append('Quality')\n",
        "                    elif label == '양':\n",
        "                        new_scores['Quantity'] = averaged_score\n",
        "                        if averaged_score >= 0.35:\n",
        "                            new_labels.append('Quantity')\n",
        "                    elif label in ['서비스', '배달', '가격']:\n",
        "                        service_scores.append(averaged_score)\n",
        "                if service_scores:\n",
        "                    avg_service_score = sum(service_scores) / len(service_scores)\n",
        "                    new_scores['Service'] = avg_service_score\n",
        "                    if avg_service_score >= 0.35:\n",
        "                        new_labels.append('Service')\n",
        "                new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "                new_predicted_labels = \", \".join(new_labels)\n",
        "                st.write(f\"Label Scores: {new_label_scores}\")\n",
        "                st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "                model = loaded_model(DATA_PATH)\n",
        "                tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "                with st.spinner(\"답변 생성 중입니다...\"):\n",
        "                    reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "                st.success(\"완료!\")\n",
        "                st.write(\"답글을 추천해 드려요. : \")\n",
        "                st.write(reply)\n",
        "            else:\n",
        "                st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "    elif choice == \"리뷰 분석\":\n",
        "        analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "        if analysis_choice == \"부정 리뷰 분석\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "            neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "            pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "            plt.rcParams.update(plt.rcParamsDefault)\n",
        "            plt.rc('font', family='NanumBarunGothic')\n",
        "            fig, ax = plt.subplots(figsize=(6, 6))\n",
        "            short_label_counts = neg_short_result['label'].value_counts()\n",
        "            ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "            plt.title('리뷰 현황')\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "            merged_df = pd.read_csv(f'{DATA_PATH}merged_df_2months.csv')\n",
        "            merged_df_3y = pd.read_csv(f'{DATA_PATH}merged_df_3years.csv')\n",
        "            merged_df_3y = merged_df_3y.dropna()\n",
        "            plot_review_analysis(merged_df, merged_df_3y)\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "        elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "            df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "            df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "            input_id = st.text_input(\"고객 ID 입력: \")\n",
        "            plot_temperature_analysis(df2, input_id)\n",
        "\n",
        "            pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HipkVzU7DDsJ",
        "outputId": "0939f865-f098-49f0-dd50-acf5eae97074"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력순서 변경\n"
      ],
      "metadata": {
        "id": "pY1yz3mhcN8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import seaborn as sns\n",
        "from scipy.interpolate import make_interp_spline\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# 유사도 평가 함수\n",
        "def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "    input_embedding = bert_model.encode(input_text)\n",
        "    generated_embedding = bert_model.encode(generated_text)\n",
        "    cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "    input_tokens = set(input_text.split())\n",
        "    generated_tokens = set(generated_text.split())\n",
        "    jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "    weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "    return weighted_sim\n",
        "\n",
        "# 모델 로드\n",
        "def loaded_model(DATA_PATH):\n",
        "    model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "    return model\n",
        "\n",
        "def load_zero_model(DATA_PATH):\n",
        "    model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "    return model_zeroshot\n",
        "\n",
        "def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "    new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "    return new_tokenizer\n",
        "\n",
        "def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "    classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "    return classifier\n",
        "\n",
        "# 토크나이저 로드\n",
        "def loaded_tokenizer(DATA_PATH):\n",
        "    model_name = \"skt/kogpt2-base-v2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          bos_token='</s>',\n",
        "                                          eos_token='</s>',\n",
        "                                          unk_token='<unk>',\n",
        "                                          pad_token='<pad>',\n",
        "                                          mask_token='<mask>',\n",
        "                                          max_len=1024)\n",
        "    return tokenizer\n",
        "\n",
        "# 답변 생성 함수\n",
        "def generate_response(model, tokenizer, input_text, num_samples):\n",
        "    text = \"<q>\" + input_text + \"</s><a>\"\n",
        "    x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    q_len = len(text) + 1\n",
        "\n",
        "    best_generated_text = None\n",
        "    best_similarity_score = -1.0\n",
        "    generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "    for i in range(num_samples):\n",
        "        result_ids = model.generate(x,\n",
        "                                        max_length=1024,\n",
        "                                        repetition_penalty=2.0,\n",
        "                                        num_beams=1,\n",
        "                                        num_return_sequences=1,\n",
        "                                        no_repeat_ngram_size=4,\n",
        "                                        use_cache=True,\n",
        "                                        do_sample=True,\n",
        "                                        temperature=0.8,\n",
        "                                        top_k=90,\n",
        "                                        top_p=0.95,\n",
        "                                        early_stopping=True\n",
        "                                        )\n",
        "        generated_text = tokenizer.decode(result_ids[0])\n",
        "        generated_text = generated_text[q_len:-4]\n",
        "        generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "        similarity_score = evaluate_similarity(text, generated_text)\n",
        "        generated_texts.append((similarity_score,generated_text))\n",
        "        print(generated_texts[i])\n",
        "        if similarity_score > best_similarity_score:\n",
        "            best_similarity_score = similarity_score\n",
        "            best_generated_text = generated_text\n",
        "    print(\"Best_similarity_score:\", best_similarity_score)\n",
        "    return best_generated_text\n",
        "\n",
        "# 그래프\n",
        "\n",
        "def plot_review_analysis(merged_df, merged_df_3y):\n",
        "    fig1, ax1 = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "    plt.rcParams.update(plt.rcParamsDefault)\n",
        "    plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "    # 그래프 그리기\n",
        "    sns.lineplot(data=merged_df, x='date', y='pos_7D_score', ax=ax1, label='긍정 지수', marker='o', linestyle='-', color='b')\n",
        "    sns.lineplot(data=merged_df, x='date', y='neg_7D_score', ax=ax1, label='부정 지수', marker='s', linestyle='--', color='r')\n",
        "\n",
        "    # 그래프 설정\n",
        "    ax1.set_title('긍부정 지수 변화 (2개월)', fontsize=14)\n",
        "    ax1.set_xlabel('일자', fontsize=12)\n",
        "    ax1.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "    ax1.legend(fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    x = merged_df_3y['DATE']\n",
        "    y_pos = merged_df_3y['pos_7D_score']\n",
        "    y_neg = merged_df_3y['neg_7D_score']\n",
        "\n",
        "    mask = ~np.isnan(y_pos) & ~np.isnan(y_neg) & ~np.isinf(y_pos) & ~np.isinf(y_neg)\n",
        "    x = x[mask]\n",
        "    y_pos = y_pos[mask]\n",
        "    y_neg = y_neg[mask]\n",
        "\n",
        "    x_numeric = pd.to_datetime(x).astype(int)\n",
        "\n",
        "    spline_pos = make_interp_spline(x_numeric, y_pos, k=3)\n",
        "    spline_neg = make_interp_spline(x_numeric, y_neg, k=3)\n",
        "    x_new = np.linspace(x_numeric.min(), x_numeric.max(), 300)\n",
        "    y_pos_smooth = spline_pos(x_new)\n",
        "    y_neg_smooth = spline_neg(x_new)\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 4))\n",
        "    ax2.plot(pd.to_datetime(x_new), y_pos_smooth, label='긍정 지수', color='b')\n",
        "    ax2.plot(pd.to_datetime(x_new), y_neg_smooth, label='부정 지수', color='r')\n",
        "    ax2.set_title('긍부정 지수 변화 (3개년)', fontsize=14)\n",
        "    ax2.set_xlabel('일자', fontsize=12)\n",
        "    ax2.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "    ax2.legend()\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "\n",
        "def plot_temperature_analysis(df2, input_id):\n",
        "    review_count = len(df2[df2['ID'] == input_id])\n",
        "    id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "    if not id_df.empty:\n",
        "        mean_score = id_df['NEW_SCORE'].mean()\n",
        "        def scale_temperature(score):\n",
        "            base_temp = 36.5\n",
        "            ratio = 30\n",
        "            scaled_temp = base_temp + (score * ratio)\n",
        "            return scaled_temp\n",
        "        scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "        mean_temperature = scaled_scores.mean()\n",
        "        line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "        line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "        ax.set_xlabel('일자')\n",
        "        ax.set_ylabel('온도 (°C)')\n",
        "        ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "        plt.xticks(id_df['DATE'], rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.ylim(0, 70)\n",
        "        y_ticks = np.arange(0, 71, 10)\n",
        "        plt.yticks(y_ticks)\n",
        "        plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "        ax.legend()\n",
        "        st.pyplot(fig)\n",
        "        st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "        st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "        st.write(f'리뷰 횟수: {review_count}')\n",
        "    else:\n",
        "        st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "def main():\n",
        "    url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "    st.image(url)\n",
        "\n",
        "    DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "    with st.sidebar:\n",
        "        choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\"],\n",
        "                             icons=['house', 'kanban', 'bi bi-robot'],\n",
        "                             menu_icon=\"app-indicator\", default_index=0,\n",
        "                             styles={\n",
        "                                 \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "                                 \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "                                 \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "                                 \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "                             }\n",
        "        )\n",
        "\n",
        "    if choice == \"사장님 답글 남기기\":\n",
        "        candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "        st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "        user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "        submit_button = st.button(\"Submit\")\n",
        "\n",
        "        if submit_button:\n",
        "            if user_input:\n",
        "                # 사장님 답변 생성 부분\n",
        "                model = loaded_model(DATA_PATH)\n",
        "                tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "                with st.spinner(\"답변 생성 중입니다...\"):\n",
        "                    reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "                st.success(f\"답글을 추천해 드려요 : \\n\\n{reply}\")\n",
        "\n",
        "                # 라벨 예측 부분\n",
        "                #st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "                model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "                model_zeroshot = load_zero_model(DATA_PATH)\n",
        "                new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "                classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "                inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "                input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "                with st.spinner(\"라벨 생성 중입니다...\"):\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                        logits = outputs.logits\n",
        "                        probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "                    scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "                    output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "                    scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "\n",
        "                    new_labels = []\n",
        "                    new_scores = {}\n",
        "                    service_scores = []\n",
        "                    for label in scores_from_model1.keys():\n",
        "                        averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "                        if label == '맛':\n",
        "                            new_scores['Quality'] = averaged_score\n",
        "                            if averaged_score >= 0.35:\n",
        "                                new_labels.append('Quality')\n",
        "                        elif label == '양':\n",
        "                            new_scores['Quantity'] = averaged_score\n",
        "                            if averaged_score >= 0.35:\n",
        "                                new_labels.append('Quantity')\n",
        "                        elif label in ['서비스', '배달', '가격']:\n",
        "                            service_scores.append(averaged_score)\n",
        "                    if service_scores:\n",
        "                        avg_service_score = sum(service_scores) / len(service_scores)\n",
        "                        new_scores['Service'] = avg_service_score\n",
        "                        if avg_service_score >= 0.35:\n",
        "                            new_labels.append('Service')\n",
        "                    new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "                    new_predicted_labels = \", \".join(new_labels)\n",
        "                #st.write(f\"Label Scores: {new_label_scores}\")\n",
        "                #st.write(f\"Predicted Labels: {new_predicted_labels}\")\n",
        "                #st.write(\" 고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "                st.success(\"고객 리뷰에 대한 라벨은 {} 입니다.\".format(new_predicted_labels))\n",
        "\n",
        "                #st.success(\"\"\"\n",
        "                #Label Scores: {}\\n\n",
        "                #Predicted Labels: {}\n",
        "                #\"\"\".format(new_label_scores, new_predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "            else:\n",
        "                st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "    elif choice == \"리뷰 분석\":\n",
        "        analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "        if analysis_choice == \"부정 리뷰 분석\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "            neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "            pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "            plt.rcParams.update(plt.rcParamsDefault)\n",
        "            plt.rc('font', family='NanumBarunGothic')\n",
        "            fig, ax = plt.subplots(figsize=(6, 6))\n",
        "            short_label_counts = neg_short_result['label'].value_counts()\n",
        "            ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "            #plt.title('리뷰 현황')\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "            merged_df = pd.read_csv(f'{DATA_PATH}merged_df_2months.csv')\n",
        "            merged_df_3y = pd.read_csv(f'{DATA_PATH}merged_df_3years.csv')\n",
        "            merged_df_3y = merged_df_3y.dropna()\n",
        "            plot_review_analysis(merged_df, merged_df_3y)\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "        elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "            st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "            df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "            df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "            input_id = st.text_input(\"고객 ID 입력: \")\n",
        "            plot_temperature_analysis(df2, input_id)\n",
        "\n",
        "            pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOThRCcEcMUX",
        "outputId": "3cbd9b61-3951-4f38-9cf3-138fd1dd499c"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import streamlit as st\n",
        "# from streamlit_option_menu import option_menu\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import re\n",
        "# import time\n",
        "# from PIL import Image\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSequenceClassification\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# from sklearn.metrics.pairwise import pairwise_distances\n",
        "# import seaborn as sns\n",
        "# from scipy.interpolate import make_interp_spline\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "# bert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "# model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "\n",
        "# # 유사도 평가 함수\n",
        "# def evaluate_similarity(input_text, generated_text, alpha=0.9):\n",
        "#     input_embedding = bert_model.encode(input_text)\n",
        "#     generated_embedding = bert_model.encode(generated_text)\n",
        "#     cosine_sim = 1 - pairwise_distances([input_embedding], [generated_embedding], metric='cosine')[0][0]\n",
        "#     input_tokens = set(input_text.split())\n",
        "#     generated_tokens = set(generated_text.split())\n",
        "#     jaccard_sim = len(input_tokens.intersection(generated_tokens)) / len(input_tokens.union(generated_tokens))\n",
        "#     weighted_sim = alpha*cosine_sim + (1 - alpha)*jaccard_sim\n",
        "#     return weighted_sim\n",
        "\n",
        "# # 모델 로드\n",
        "# def loaded_model(DATA_PATH):\n",
        "#     model = AutoModelForCausalLM.from_pretrained(f\"{DATA_PATH}sohyun_23762_21_loss_0.2512\", local_files_only=True)\n",
        "#     return model\n",
        "\n",
        "# def load_zero_model(DATA_PATH):\n",
        "#     model_zeroshot = AutoModelForSequenceClassification.from_pretrained(f\"{DATA_PATH}42000_5라벨_3\").to('cuda')\n",
        "#     return model_zeroshot\n",
        "\n",
        "# def loaded_zeroshot_tokenizer(DATA_PATH, model_M):\n",
        "#     new_tokenizer = AutoTokenizer.from_pretrained(model_M, use_fast=False)\n",
        "#     return new_tokenizer\n",
        "\n",
        "# def zero_classifier(DATA_PATH, model_M, new_tokenizer):\n",
        "#     classifier = pipeline(\"zero-shot-classification\", model=model_M, tokenizer=new_tokenizer, device=0)\n",
        "#     return classifier\n",
        "\n",
        "# # 토크나이저 로드\n",
        "# def loaded_tokenizer(DATA_PATH):\n",
        "#     model_name = \"skt/kogpt2-base-v2\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "#                                           bos_token='</s>',\n",
        "#                                           eos_token='</s>',\n",
        "#                                           unk_token='<unk>',\n",
        "#                                           pad_token='<pad>',\n",
        "#                                           mask_token='<mask>',\n",
        "#                                           max_len=1024)\n",
        "#     return tokenizer\n",
        "\n",
        "# # 답변 생성 함수\n",
        "# def generate_response(model, tokenizer, input_text, num_samples):\n",
        "#     text = \"<q>\" + input_text + \"</s><a>\"\n",
        "#     x = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "#     q_len = len(text) + 1\n",
        "\n",
        "#     best_generated_text = None\n",
        "#     best_similarity_score = -1.0\n",
        "#     generated_texts = []  # 답변 후보군을 담을 리스트\n",
        "#     for i in range(num_samples):\n",
        "#         result_ids = model.generate(x,\n",
        "#                                         max_length=1024,\n",
        "#                                         repetition_penalty=2.0,\n",
        "#                                         num_beams=1,\n",
        "#                                         num_return_sequences=1,\n",
        "#                                         no_repeat_ngram_size=4,\n",
        "#                                         use_cache=True,\n",
        "#                                         do_sample=True,\n",
        "#                                         temperature=0.8,\n",
        "#                                         top_k=90,\n",
        "#                                         top_p=0.95,\n",
        "#                                         early_stopping=True\n",
        "#                                         )\n",
        "#         generated_text = tokenizer.decode(result_ids[0])\n",
        "#         generated_text = generated_text[q_len:-4]\n",
        "#         generated_text = re.sub(r'[^가-힣.]', ' ', generated_text)\n",
        "#         similarity_score = evaluate_similarity(text, generated_text)\n",
        "#         generated_texts.append((similarity_score,generated_text))\n",
        "#         print(generated_texts[i])\n",
        "#         if similarity_score > best_similarity_score:\n",
        "#             best_similarity_score = similarity_score\n",
        "#             best_generated_text = generated_text\n",
        "#     print(\"Best_similarity_score:\", best_similarity_score)\n",
        "#     return best_generated_text\n",
        "\n",
        "# # 그래프\n",
        "\n",
        "# def plot_review_analysis(merged_df, merged_df_3y):\n",
        "#     fig1, ax1 = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "#     plt.rcParams.update(plt.rcParamsDefault)\n",
        "#     plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "#     # 그래프 그리기\n",
        "#     sns.lineplot(data=merged_df, x='date', y='pos_7D_score', ax=ax1, label='긍정 지수', marker='o', linestyle='-', color='b')\n",
        "#     sns.lineplot(data=merged_df, x='date', y='neg_7D_score', ax=ax1, label='부정 지수', marker='s', linestyle='--', color='r')\n",
        "\n",
        "#     # 그래프 설정\n",
        "#     ax1.set_title('긍부정 지수 변화 (2개월)', fontsize=14)\n",
        "#     ax1.set_xlabel('일자', fontsize=12)\n",
        "#     ax1.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     ax1.legend(fontsize=12)\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig1)\n",
        "\n",
        "\n",
        "#     st.markdown(\"---\")\n",
        "\n",
        "#     x = merged_df_3y['DATE']\n",
        "#     y_pos = merged_df_3y['pos_7D_score']\n",
        "#     y_neg = merged_df_3y['neg_7D_score']\n",
        "\n",
        "#     mask = ~np.isnan(y_pos) & ~np.isnan(y_neg) & ~np.isinf(y_pos) & ~np.isinf(y_neg)\n",
        "#     x = x[mask]\n",
        "#     y_pos = y_pos[mask]\n",
        "#     y_neg = y_neg[mask]\n",
        "\n",
        "#     x_numeric = pd.to_datetime(x).astype(int)\n",
        "\n",
        "#     spline_pos = make_interp_spline(x_numeric, y_pos, k=3)\n",
        "#     spline_neg = make_interp_spline(x_numeric, y_neg, k=3)\n",
        "#     x_new = np.linspace(x_numeric.min(), x_numeric.max(), 300)\n",
        "#     y_pos_smooth = spline_pos(x_new)\n",
        "#     y_neg_smooth = spline_neg(x_new)\n",
        "\n",
        "#     fig2, ax2 = plt.subplots(figsize=(10, 4))\n",
        "#     ax2.plot(pd.to_datetime(x_new), y_pos_smooth, label='긍정 지수', color='b')\n",
        "#     ax2.plot(pd.to_datetime(x_new), y_neg_smooth, label='부정 지수', color='r')\n",
        "#     ax2.set_title('긍부정 지수 변화 (3개년)', fontsize=14)\n",
        "#     ax2.set_xlabel('일자', fontsize=12)\n",
        "#     ax2.set_ylabel('리뷰 긍부정 지수', fontsize=12)\n",
        "#     ax2.legend()\n",
        "#     plt.tight_layout()\n",
        "#     st.pyplot(fig2)\n",
        "\n",
        "\n",
        "# def plot_temperature_analysis(df2, input_id):\n",
        "#     review_count = len(df2[df2['ID'] == input_id])\n",
        "#     id_df = df2[df2['ID'] == input_id]\n",
        "\n",
        "#     if not id_df.empty:\n",
        "#         mean_score = id_df['NEW_SCORE'].mean()\n",
        "#         def scale_temperature(score):\n",
        "#             base_temp = 36.5\n",
        "#             ratio = 30\n",
        "#             scaled_temp = base_temp + (score * ratio)\n",
        "#             return scaled_temp\n",
        "#         scaled_scores = id_df['NEW_SCORE'].apply(scale_temperature)\n",
        "#         mean_temperature = scaled_scores.mean()\n",
        "#         line_color = 'red' if mean_score >= 0 else 'blue'\n",
        "#         line_label = 'NEW_SCORE (Above 36.5°C)' if mean_score >= 0 else 'NEW_SCORE (Below 36.5°C)'\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.plot(id_df['DATE'], scaled_scores, color=line_color, label=line_label)\n",
        "#         ax.set_xlabel('일자')\n",
        "#         ax.set_ylabel('온도 (°C)')\n",
        "#         ax.set_title(f'고객 온도 지수: {input_id}')\n",
        "#         plt.xticks(id_df['DATE'], rotation=45)\n",
        "#         plt.tight_layout()\n",
        "#         plt.ylim(0, 70)\n",
        "#         y_ticks = np.arange(0, 71, 10)\n",
        "#         plt.yticks(y_ticks)\n",
        "#         plt.axhline(y=36.5, color='black', linestyle='--', linewidth=1)\n",
        "#         ax.legend()\n",
        "#         st.pyplot(fig)\n",
        "#         st.write(f'평균 점수: {mean_score.round(2)}')\n",
        "#         st.write(f'평균 온도: {mean_temperature.round(1)}°C')\n",
        "#         st.write(f'리뷰 횟수: {review_count}')\n",
        "#     else:\n",
        "#         st.write(f\"{input_id} : 없는 ID 입니다.\")\n",
        "\n",
        "# def main():\n",
        "#     url = \"https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/6a9B/image/e-6NavAQbiquCnZ1ANdRGunwUek.png\"\n",
        "#     st.image(url)\n",
        "\n",
        "#     DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         choice = option_menu(\"Menu\", [\"사장님 답글 남기기\", \"리뷰 분석\"],\n",
        "#                              icons=['house', 'kanban', 'bi bi-robot'],\n",
        "#                              menu_icon=\"app-indicator\", default_index=0,\n",
        "#                              styles={\n",
        "#                                  \"container\": {\"padding\": \"4!important\", \"background-color\": \"#fafafa\"},\n",
        "#                                  \"icon\": {\"color\": \"black\", \"font-size\": \"25px\"},\n",
        "#                                  \"nav-link\": {\"font-size\": \"16px\", \"color\": \"black\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#cae8e6\"},\n",
        "#                                  \"nav-link-selected\": {\"background-color\": \"#08c7b4\"},\n",
        "#                              }\n",
        "#         )\n",
        "\n",
        "#     if choice == \"사장님 답글 남기기\":\n",
        "#         candidate_labels = [\"맛\", \"양\", \"서비스\", \"배달\", \"가격\"]\n",
        "#         st.title(\"사장님을 위한 답변 추천 공간\")\n",
        "#         user_input = st.text_input(label=\"고객 리뷰\", value=\"\")\n",
        "#         submit_button = st.button(\"Submit\")\n",
        "\n",
        "#         if submit_button:\n",
        "#             if user_input:\n",
        "#                 # 사장님 답변 생성 부분\n",
        "#                 model = loaded_model(DATA_PATH)\n",
        "#                 tokenizer = loaded_tokenizer(DATA_PATH)\n",
        "#                 with st.spinner(\"답변 생성 중입니다...\"):\n",
        "#                     reply = generate_response(model, tokenizer, user_input, num_samples=3)\n",
        "#                 st.success(f\"답글을 추천해 드려요 : \\n\\n{reply}\")\n",
        "\n",
        "#                 # 라벨 예측 부분\n",
        "#                 #st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "\n",
        "#                 model_M = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "#                 model_zeroshot = load_zero_model(DATA_PATH)\n",
        "#                 new_tokenizer = loaded_zeroshot_tokenizer(DATA_PATH, model_M)\n",
        "#                 classifier = zero_classifier(DATA_PATH, model_M, new_tokenizer)\n",
        "#                 inputs = new_tokenizer([user_input], truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n",
        "#                 input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "\n",
        "#                 new_labels = []\n",
        "#                 new_scores = {}\n",
        "#                 service_scores = []\n",
        "#                 with st.spinner(\"라벨 생성 중입니다...\"):\n",
        "#                     with torch.no_grad():\n",
        "#                         outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#                         logits = outputs.logits\n",
        "#                         probs1 = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "#                     scores_from_model1 = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(probs1)}\n",
        "#                     output = classifier(user_input, candidate_labels, multi_label=True)\n",
        "#                     scores_from_model2 = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n",
        "#                     for label in scores_from_model1.keys():\n",
        "#                         averaged_score = (float(scores_from_model1[label]) + float(scores_from_model2[label])) / 2\n",
        "#                         if label == '맛':\n",
        "#                             new_scores['Quality'] = averaged_score\n",
        "#                             if averaged_score >= 0.35:\n",
        "#                                 new_labels.append('Quality')\n",
        "#                         elif label == '양':\n",
        "#                             new_scores['Quantity'] = averaged_score\n",
        "#                             if averaged_score >= 0.35:\n",
        "#                                 new_labels.append('Quantity')\n",
        "#                         elif label in ['서비스', '배달', '가격']:\n",
        "#                             service_scores.append(averaged_score)\n",
        "#                     if service_scores:\n",
        "#                         avg_service_score = sum(service_scores) / len(service_scores)\n",
        "#                         new_scores['Service'] = avg_service_score\n",
        "#                         if avg_service_score >= 0.35:\n",
        "#                             new_labels.append('Service')\n",
        "#                     new_label_scores = \", \".join([f\"{k}: {v:.2f}\" for k, v in new_scores.items()])\n",
        "#                     new_predicted_labels = \", \".join(new_labels)\n",
        "\n",
        "#                 st.write(\"고객 리뷰에 대한 예측 라벨 입니다!\")\n",
        "#                 st.success(\"\"\"\n",
        "#                 Label Scores: {}\\n\n",
        "#                 Predicted Labels: {}\n",
        "#                 \"\"\".format(new_label_scores, new_predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "#             else:\n",
        "#                 st.warning(\"고객 리뷰를 확인하세요.\")\n",
        "\n",
        "#     elif choice == \"리뷰 분석\":\n",
        "#         analysis_choice = st.sidebar.radio(\"분석 선택\", [\"부정 리뷰 분석\", \"긍/부 지수의 변화 추이\", \"고객별 온도 지수 및 유형 분석\"])\n",
        "\n",
        "#         if analysis_choice == \"부정 리뷰 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>부정 리뷰 분석</h2>\", unsafe_allow_html=True)\n",
        "#             neg_short_result = pd.read_csv(f\"{DATA_PATH}neg_short_result.csv\")\n",
        "#             pastel_colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FFD700']\n",
        "#             plt.rcParams.update(plt.rcParamsDefault)\n",
        "#             plt.rc('font', family='NanumBarunGothic')\n",
        "#             fig, ax = plt.subplots(figsize=(6, 6))\n",
        "#             short_label_counts = neg_short_result['label'].value_counts()\n",
        "#             ax.pie(short_label_counts[:], labels=short_label_counts[:].index, autopct='%1.1f%%', startangle=140, colors=pastel_colors)\n",
        "#             plt.title('리뷰 현황')\n",
        "#             st.pyplot(fig)\n",
        "\n",
        "#         elif analysis_choice == \"긍/부 지수의 변화 추이\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>긍/부 지수의 변화 추이</h2>\", unsafe_allow_html=True)\n",
        "#             merged_df = pd.read_csv(f'{DATA_PATH}merged_df_2months.csv')\n",
        "#             merged_df_3y = pd.read_csv(f'{DATA_PATH}merged_df_3years.csv')\n",
        "#             merged_df_3y = merged_df_3y.dropna()\n",
        "#             plot_review_analysis(merged_df, merged_df_3y)\n",
        "#             st.markdown(\"---\")\n",
        "\n",
        "#         elif analysis_choice == \"고객별 온도 지수 및 유형 분석\":\n",
        "#             st.markdown(\"<h2 style='text-align: center;'>고객별 온도 지수 및 유형 분석</h2>\", unsafe_allow_html=True)\n",
        "#             df2 = pd.read_csv(f\"{DATA_PATH}ygy_df2_sorted_2037.csv\")\n",
        "#             df2['NEW_SCORE'] = df2.apply(lambda row: row['SCORE'] if row['SENTIMENT'] == 1 else - row['SCORE'], axis=1)\n",
        "#             input_id = st.text_input(\"고객 ID 입력: \")\n",
        "#             plot_temperature_analysis(df2, input_id)\n",
        "\n",
        "#             pass\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GL_a5gMlWi-",
        "outputId": "90e4acb2-2d68-42e4-ad76-919d6224050f"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4i2g-Wp2qIC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44282070-24d3-4c97-f6ba-f16c7162082f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.27.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.5.3)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.37)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c4FPFQuNqd-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aadf05ba-84da-4516-d90e-018620050321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit_option_menu in /usr/local/lib/python3.10/dist-packages (0.3.6)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit_option_menu) (1.27.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (13.5.3)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (5.0.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.1.37)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_option_menu) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit_option_menu) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit_option_menu) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit_option_menu) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_option_menu) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_option_menu) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_option_menu) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_option_menu) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_option_menu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_option_menu) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_option_menu) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_option_menu) (0.10.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit_option_menu) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit_option_menu\n",
        "from streamlit_option_menu import option_menu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "PhgwGKEDfgld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d00b20b8-5ba3-4768-9f4a-ae36ab24aaf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.230.40.249\n"
          ]
        }
      ],
      "source": [
        "# 3\n",
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "\n",
        "# \"Password/Enpoint IP for localtunnel is:\" 우측에 xx.xxx.xx.xxx 혹은 xx.xxx.xxx.xxx 형식의 숫자가 나온다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "fYLso3nPfj3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deedb986-040d-4cb9-8be7-53f5364f6111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.68s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "iRUzqWCafm_0"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "Ph-wJzRmfoVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d222841-38e0-45a7-f3fa-31784d66ceeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.117s\n",
            "your url is: https://major-pants-greet.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501\n",
        "\n",
        "# \"your url is:\" 우측에 사이트 주소가 생성된다."
      ]
    }
  ]
}